{
    "visionos_docs_PDFs": {
        "https://developer.apple.com/documentation/visionos/bot-anist": "visionOS\nBOT-anist\nBOT-anist\nBOT-anist\nBOT-anist\nOverview\nBOT-anist is a game-like experience where you build a custom robot botanist by selecting from a variety of color and shape options, and then guide your robot around a futuristic greenhouse to plant alien flowers. This app demonstrates how to build an app for iOS, iPadOS, macOS, and visionOS using a single shared Xcode target and a shared Reality Composer Pro project.\nThis sample shows off a number of RealityKit and visionOS features, including volume ornaments, dynamic lights and shadows, animation library components, and vertex animation using blend shapes. It also demonstrates how to set a volume\u2019s default size and enable user resizing of volumes.\nCustomize the robot and explore\nWhen the app launches, you see a window that contains your robot and a number of different user interface elements you can use to customize it. You can change the shape of your robot\u2019s head, backpack, and body, as well as the material and color scheme for each part. You can also change the color of the lights for each piece.\nTo get a better look at your robot while customizing it, spin it using a drag gesture on iOS and visionOS, or by dragging it with your mouse in macOS.\nWhen you\u2019re happy with the look of your robot botanist, tap or click the Start Planting button to send the robot to explore its futuristic greenhouse. In visionOS, BOT-anist displays the greenhouse in a resizable 3D volume. In iOS and macOS, it appears in the same window as the customization tools. There are three illuminated planters in different colors on the floor of the greenhouse. Move your robot around using drag gestures or keyboard controls to plant flowers in each one. When using the keyboard to control the robot, you have the option to use the traditionalWASDkey combination on QWERTY keyboards, as well as the right-handed equivalent (IJKL). You can also use the arrow keys and, if using an extended keyboard, the numeric keypad (8456). You can find the key bindings inRealityView+KeyboardControls.swiftif you want to change them to an alternative scheme.\n\nMake the project multiplatform\nYou can now use RealityKit to create multiplatform apps that run in iOS, iPadOS, macOS, and visionOS usingRealityView. As long as your Xcode project uses only SwiftUI for its user interface, you can convert it to a multiplatform app by navigating to your app target in Xcode and adding the platforms you want to support. You don\u2019t need to add a new target or scheme. When you\u2019re developing your app, Xcode compiles the right code for the selected destination. When you build your app for distribution, it builds it for all the platforms you select.\n\nThere are, however, platform differences you need to take into account in some apps. For example, visionOS uses a different unit scale for RealityKit scenes than other platforms do. Also, different devices have different screen sizes and aspect ratios. To account for these differences, you may want to set the scale and position of the root entity in theRealityViewusing different values.\nIn BOT-anist on visionOS, you use aGeometryReader3Dto position and resize the robot view to fill 80% of the available space\nSet up the window groups\nBOT-anist sets up two window groups because it uses both a window and a volume in visionOS, but runs the entire app in a single window on its other supported platforms. The first window group uses the default platform window style, which creates a standard window for the platform it\u2019s running on. In visionOS only, the app configures this window group to dismiss the other window group, which holds the 3D volume, when this window appears. That ensures the window and volume are never visible at the same time.\nThe app class contains a second window group with avolumetricstyle to hold the greenhouse in visionOS. This second window group uses platform conditionals to ensure that it only compiles for visionOS. The default window style behavior in visionOS for 2D windows isdynamic, which means the window changes its size as it changes its distance to the player to ensure the window is always a good size for them to interact with.\nVolumes, on the other hand, default to a fixed window style, which means the farther away from the player the volume is, the smaller it appears. This is often the desired behavior for volumes because you want the virtual contents to blend in with real-world perspective. In this case, however, the player needs to interact with the greenhouse features much like they do with the UI elements in a 2D window. BOT-anist changes the default scaling of the volume todynamicso it stays usable even if the player moves away from it.\nShow the volume\u2019s baseplate\nvisionOS volumes are, by default, user resizable. People can resize them by looking at one of the four bottom corners of the volume, and then pinching and dragging the control that appears.\nBOT-anist uses the default behavior for the volume that displays the greenhouse. To make it more obvious to the player that they can resize the volume, and to give them better visual feedback when doing it, BOT-anist makes the volume\u2019s baseplate visible. Thebaseplateis a white, rounded rectangle on the bottom plane of the volume that the app enables by callingvolumeBaseplateVisibility(_:)on the volume\u2019s root view.\nBOT-anist also sets the default size of the volume to make sure it starts large enough for the player to interact with.\nNote\nTo create a volume with fixed style, don\u2019t specify a default size. Instead, useframe(minDepth:idealDepth:maxDepth:alignment:)on the volume\u2019s root view and pass the same value forminDepth,idealDepth, andmaxDepth.\nBy default, when a volume changes size, the size of its contents don\u2019t scale with it. BOT-anist\u2019s contents do resize with the volume, which it accomplishes using thescaleEffect(_:anchor:)modifier.\nWhen the contents resize relative to the real-world surroundings, it affects the robot\u2019s speed of movement, causing it to move too fast when you make the volume smaller and move too slow when you make it larger. To make sure the robot moves at a consistent speed no matter the size of the volume, the window group uses anonChange(of:initial:_:)modifier to update the robot\u2019s speed based on the volume\u2019s size.\nSpecify the volume\u2019s ornament view\nStarting with visionOS 2, you can place ornaments in different locations in the 3D space of a volume. BOT-anist uses an ornament view to display the score, along with buttons for re-starting and for going back to the robot customization screen.\n\nInstead of the default placement, BOT-anist displays the ornament view at the top back. To specify its ornament view, it usesornament(visibility:attachmentAnchor:contentAlignment:ornament:), and a value oftopBack, which centers it at the top of the far side of the volume.\nCreate dynamic lights with shadows using Reality Composer Pro\nTo create dynamic lighting effects with shadows, add lights to your Reality Composer Pro project. To see the lights that BOT-anist uses, openBOTanistAssets.swiftin Reality Composer Pro and open the scene calledvolume.usda.\n\nAfter you add lights to your scene, build and run your app to see it with the new lights, including dynamic shadows. If you watch the robot botanist as you move it around the greenhouse, you see that it casts a shadow.\nYou can use up to eight lights in a RealityKit scene, but lights have a nontrivial performance impact, so use them strategically. Even when using dynamic lights, your entities still receive light from any image-based or environmental lighting your app uses.\n\nDetect viewpoint changes in volumes\nIn visionOS 2 and later, apps can useonVolumeViewpointChange(updateStrategy:initial:_:)to receive updates when the player moves to a different side. When BOT-anist receives an update, it rotates the robot toward the viewer and waves to them at their new location.\nInExplorationView.swift, which is the top-level view in the volume\u2019s window group, the app usesonVolumeViewpointChange(updateStrategy:initial:_:)to receive updates about which side of the volume is facing the person, and stores the new facing in a property.\nThe value the app receives is of typeViewpoint3D, and it identifies which side of the volume is currently facing the viewer relative to which side was the front face when the app first launched. The code that handles movement input monitors this property. When it detects a viewpoint change and the robot isn\u2019t moving, it starts the animations that cause the robot to rotate toward the new front face and wave cheerily.\nAnimate the robot\nBOT-anist contains multiple different body types that players can choose when building their robot, including one that walks, one that rolls, and one that floats. Each of these bodies has a different set of animations, and the app uses a state machine defined inAnimationStateMachine.swiftto keep track of which animation is currently playing, and when and how it transitions to a different animation.\nRealityKit can load multiple animations from different USDZ files and store them in anAnimationLibraryComponent. As long as two rigged entities have the same joint hierarchy, they can use each other\u2019s animations. BOT-anist uses oneAnimationLibraryComponentper body entity to store the animations for that body type.\nAt launch, BOT-anist loads each of the different modular parts that players use to build their robot. When it loads the bodies, it creates anAnimationLibraryComponenton each loaded entity, then loads and stores one animation per animation state.\nWhen the app transitions to a new animation state, it can find and play the correct animation by retrieving the animation for the current state from the animation library on the body entity that\u2019s in the scene.\nAnimate the plants using blend shapes\nWhile skeletal animations are an incredibly powerful and useful tool, certain types of animations need to move each vertex in the model individually. RealityKit stores vertex-level changes to a model usingblend shapes, which contain offset data for the model entity\u2019s vertices. You can set each blend shape to a value between0.0and1.0. Any value other than0.0or1.0represents a partial state in-between the model\u2019s default shape, and the shape contained in that blend shape.\nFor example, if you have a model of a plant as a sprout, and a shape key representing its fully grown shape, you can set the plant to grow only partially by setting that blend shape to a fractional value. Animating that value over time creates a blend-shape animation, which is how BOT-anist grows the flowers when you plant them.\nTo access blend shapes, useBlendShapeWeightsComponent. You can create blend shapes and set their values procedurally but, more often, you create blend shapes and blend shape animations using a 3D modeling tool, then store them in the model\u2019s USDZ file. RealityKit automatically creates aBlendShapeWeightsComponentfor any model entity it loads from a USDZ file that contains blend shapes. It also adds any blend shape animations in the USDZ file to the entity\u2019sAnimationLibraryComponent.\nNote\nSome software uses different terms when referring to per-vertex offset data. In addition to blend shape, you may also find the same functionality referred to asmorph targetsorshape keys. All of these export to USDZ files as blend shapes and work identically.\nTo animate the plants growing, BOT-anist uses blend shape animations created in a 3D modeling program and stored in the model\u2019s USDZ file. It uses the same approach to animate the celebratory dancing the flowers do once the robot has planted them all. Each type of plant has its own blend shapes and blend shape animations to show the plant growing and celebrating.\nTo play the blend shape animations, the app iterates through entities in the scene that have aBlendShapeWeightsComponentand plays the corresponding blend shape weight animation. For example, here\u2019s how it generates the grow animation:\nWhen BOT-anist transitions to the greenhouse, it has to make sure that all the growing plants are reset to their initial value. To do that, it manually sets all of the blend shapes to0.0except for the one that represents the initial hidden state.\nAnimate the head and backpack\nTo make the robot customizable, the app combines three separate entities to build it. Each of the three bodies (walking, rolling, floating) is a skeletal mesh with its own unique set of animations. When the app enters the greenhouse mode, it combines the selected head and backpack, which are static meshes, with the animated entity for the selected body.\nFor the head and backpack to animate correctly, BOT-anist needs to update their position and rotation every frame so they line up with the appropriate joint in the body\u2019s skeleton. BOT-anist does this using a system and custom component calledJointPinSystemandJointPinComponent, which together to keep the robot parts animating in sync. When the player taps or clicks the Start Planting button, the app adds the component to the parent entity that the three body parts share. It identifies that its entity has children thatJointPinSystemneeds to reposition.JointPinSystemthen uses the dataJointPinComponentprovides to reposition the backpack and head to match the body\u2019s animated position on each frame.\n\nWhen the player selects the Start Planting button, the app combines the three selected entities using theRobotCharacterclass. That class\u2019s initializer retrieves the transforms for the head and backpack joints using thepinsproperty onEntity. This property provides access to the entity\u2019sGeometricPinsComponent, which stores a collection of transforms, each of which identifies a different location, orientation, and scale relative to the entity, but without the overhead of a separate child entity for each one. People can create pins, but RealityKit also automatically creates a collection of pins to represent the joints in a rigged model.\nAfter the player taps or clicks the button, the app retrieves the two geometric pins that represent the head and backpack joints in the body\u2019s skeleton. Because skeleton joints are arranged in a hierarchy, with each joint inheriting its parent\u2019s transform, the app retrieves the entire joint chain from the root joint to the backpack or head joint using a private function calledgetJointHierarchy(_:for:).\nNext, it calculates an offset for the two pins. The back and head model entities are places so they align with the correct spot on the body model. Because they\u2019re not at the origin, in order to rotate them on the origin, theJointPinSystemneeds to move them before applying the transform, otherwise they have the wrong pivot point. To calculate the offset, it gets the position of each pin and inverts it by multiplying the position by-1.\nFinally, it creates theJointPinComponentwith all the information the system needs to update the head and backpack entities.\nTo move the head and body each frame,JointPinSystemuses an entity query to find the parent entity the head, body, and backpack share. It then retrieves the entity representing the body\u2019s skeleton and also retrieves all of the skeleton\u2019s joint transforms.\nBecause BOT-anist has to apply the same logic to two different meshes, only using a different joint and offset, it uses a private function calledpinEntity(indices:skeleton:transforms:offset:staticEntity:shouldRotate)to apply that logic, which it then calls twice \u2014 once for the head and once for the backpack \u2014 after retrieving the data it needs from the component.\nTo calculate the correct transform for each joint, the system uses the joint chain it put in the component, and multiplies each joint\u2019s transform matrix together starting with the root joint. It usesreduce(_:_:)to iterate through the joint chain, multiplying each transform with the next one. It then takes that calculated transform and offsets it to move it back to its original location.\nSee Also",
        "https://developer.apple.com/documentation/visionos/placing-content-on-detected-planes": "visionOS\nPlacing content on detected planes\nPlacing content on detected planes\nPlacing content on detected planes\nPlacing content on detected planes\nOverview\nFlat surfaces are an ideal place to position content in an app that uses a Full Space in visionOS. They provide a place for virtual 3D content to live alongside a person\u2019s surroundings. Use plane detection in ARKit to detect these kinds of surfaces and filter the available planes based on criteria your app might need, such as the size of the plane, its proximity to someone, or a required plane orientation.\nUse RealityKit anchor entities for basic plane anchoring\nIf you don\u2019t need a specific plane in your app and you\u2019re rendering your app\u2019s 3D content in RealityKit, you can use anAnchorEntityinstead. This approach lets you attach 3D content to a plane without prompting the person for world-sensing permission and without any particular knowledge of where that plane is relative to the person.\nThe following shows an anchor that you can use to attach entities to a table:\nAnchor entities don\u2019t let you choose a specific plane in a person\u2019s surroundings, but rather let you ask for a plane with certain characteristics. When you need more specific plane selection or real-time information about the plane\u2019s position and orientation in the world, useARKitSessionandPlaneDetectionProvider.\nConfigure an ARKit session for plane detection\nPlane-detection information comes from anARKitSessionthat\u2019s configured to use aPlaneDetectionProvider. You can choose to detect horizontal planes, vertical planes, or both. Each plane that ARKit detects comes with a classification, likePlaneAnchor.Classification.tableorPlaneAnchor.Classification.floor. You can use these classifications to further refine which kinds of planes your app uses to present content. Plane detection requiresARKitSession.AuthorizationType.worldSensingauthorization.\nThe following starts a session that detects both horizontal and vertical planes, but filters out planes classified as windows:\nCreate and update entities associated with each plane\nIf you\u2019re displaying content that needs to appear attached to a particular plane, update your content whenever you receive new information from ARKit. When a plane is no longer available in the person\u2019s surroundings, ARKit sends a removal event. Respond to these events by removing content associated with the plane.\nThe following shows plane updates that place a text entity on each plane in a person\u2019s surroundings; the text entity displays the kind of plane ARKit detected:\nSee Also\nARKit",
        "https://developer.apple.com/documentation/visionos/understanding-the-visionos-render-pipeline": "visionOS\nUnderstanding the visionOS render pipeline\nUnderstanding the visionOS render pipeline\nUnderstanding the visionOS render pipeline\nUnderstanding the visionOS render pipeline\nOverview\nLike other Apple platforms, visionOS renders changes to the UI in response to updates your app makes, input events, callbacks from actions you initiate, timers, and notifications. Unique on Apple Vision Pro, the system renders updates to the images the device displays in order to reposition the UI relative to changes in head position. When the system detects eye and hand movement, deliberate or inadvertent, it requires additional processing to determine what a person is looking at, or interacting with, to calculate a response. The system does a lot more to render an up-to-date UI and account for input from spatial algorithms.\nThe following diagram illustrates how input propagates through the system and updates content in visionOS:\n\nA person initiates an interaction through a look, hand gesture, a keyboard, or pointing device.\nSensors, or other hardware, recognize the input and forward it to the operating system (OS).\nThe OS relies on collision detection to determine which entity or entities to direct an interaction to, and the process responsible for handling the user input event \u2014 the app that owns the scene where the event occurs.\nThe system puts the event into an app-specific queue, and your app\u2019s main thread picks up those events from the queue and processes them. Your app updates its audio and visual output in response to these events. Your app updates the shared render server with any changes to the UI view hierarchy and 3D RealityKit based content.\nTherender serveris a continuously running process (backboardd) that receives updates from all the running apps and other processes with Core Animation and RealityKit content to display. The render server processes the updates and composites them into a single drawable image. It sends this combined image to the compositor.\nThecompositor, another continuously running process, receives the image frames from the render server, processes data about your surroundings from Apple Vision Pro sensors and cameras, then combines them into a set of images to display. To maintain visual smoothness, the compositor strives to maintain a consistent display refresh rate.\nOn visionOS, the display driver wakes up at a regular interval to update the display with the new image from the compositor. This differs from other platforms where the display driver checks at regular intervals with the render server to determine whether the screen needs updating.\nIn the Shared Space, each app updates its own UI and 3D content and syncs the updates to its view hierarchy and content to the shared render server. This server renders the updates from multiple apps running side-by-side. Then, the render server works with the compositor to generate final images to display of the UI and people\u2019s surroundings. Metal apps in a Full Space use theCompositor Servicesframework to render drawable frames directly to the Compositor, bypassing the render server.\n\nIf your app running in the Shared Space has content or updates that take too long to render, the render server can miss deadlines. Visual updates you expect in one compositor frame don\u2019t show up until a later frame.\n\nUse the RealityKit Trace template in Instruments to profile your app and identify workflows with dropped frames and other rendering and responsiveness bottlenecks. For more information, seeAnalyzing the performance of your visionOS app. To learn about optimizations you can make in your SwiftUI and UIKit interfaces, seeReducing the rendering cost of your UI on visionOS. To learn about optimizing your RealityKit content, seeReducing the rendering cost of RealityKit content on visionOS.\nWhen usingMetaland theCompositor Servicesframework to bypass the render server, use the Metal System Trace template to profile your app\u2019s performance. For more info, seeAnalyzing the performance of your Metal app.\nPace your metal frame submissions so that the compositor receives a new frame from your app on each of its updates.\nPace your metal frame submissions so that the compositor receives a new frame from your app on each of its updates.\nMaintain a consistent metal rendering frame rate that is equal to the Apple Vision Pro display refresh rate. Use the visualizations in the Display instrument timeline to compare your rendered frame times to the display refresh rate \u2014 usually 90Hz on the Apple Vision Pro, but it can be higher under certain environmental conditions.\nMaintain a consistent metal rendering frame rate that is equal to the Apple Vision Pro display refresh rate. Use the visualizations in the Display instrument timeline to compare your rendered frame times to the display refresh rate \u2014 usually 90Hz on the Apple Vision Pro, but it can be higher under certain environmental conditions.\nQuery a new foveation map and pose prediction for each frame immediately before you use it to encode GPU work.\nQuery a new foveation map and pose prediction for each frame immediately before you use it to encode GPU work.\nAvoid long-running fragment and vertex shader executions from your Metal app, or from custom materials with Reality Composer Pro.\nAvoid long-running fragment and vertex shader executions from your Metal app, or from custom materials with Reality Composer Pro.\nAvoid any long frame stalls. If your app takes too long to submit a new frame to the compositor, the system terminates it.\nAvoid any long frame stalls. If your app takes too long to submit a new frame to the compositor, the system terminates it.\nTo learn more about implementing fully immersive Metal apps, seeDrawing fully immersive content using Metaland watch the videoDiscover Metal for immersive apps.\nSee Also\nPerformance",
        "https://developer.apple.com/documentation/visionos/incorporating-real-world-surroundings-in-an-immersive-experience": "visionOS\nIncorporating real-world surroundings in an immersive experience\nIncorporating real-world surroundings in an immersive experience\nIncorporating real-world surroundings in an immersive experience\nIncorporating real-world surroundings in an immersive experience\nOverview\nScene reconstruction helps bridge the gap between the rendered 3D content in your app and the person\u2019s surroundings. Use scene reconstruction in ARKit to give your app an idea of the shape of the person\u2019s surroundings and to bring your app experience into their world. Immersive experiences  \u2014 those that use themixedspace style \u2014 are best positioned to incorporate this kind of contextual information: scene reconstruction is only available in spaces and isn\u2019t as relevant for thefullspace style.\nIn addition to providing a 3D mesh of the shape of different nearby objects, ARKit gives a classification to each mesh face it detects. For example, it might classify a face of a mesh as being part of an appliance, a piece of furniture, or structural information about the room like the position of walls and floors. The following video shows virtual cubes colliding with the scene reconstruction mesh, which makes the cubes appear to land on a table:\nConfigure a scene reconstruction session\nScene reconstruction requires theARKitSession.AuthorizationType.worldSensingauthorization type and corresponding usage description that you supply in your app\u2019sInfo.plistfile. The following starts a session and processes updates as ARKit refines its reconstruction of the person\u2019s surroundings:\nAdd real-world interactivity using collision components\nYou can make rendered 3D content more lifelike by having it appear to interact physically with objects in the person\u2019s surroundings, like furniture and floors. Use RealityKit\u2019s collision components and physics support to provide these interactions in your app. ThegenerateStaticMesh(from:)method bridges between scene reconstruction and RealityKit\u2019s physics simulation.\nWarning\nBe mindful of how much content you include in immersive scenes that use themixedstyle. Content that fills a significant portion of the screen, even if that content is partially transparent, can prevent the person from seeing potential hazards in their surroundings. If you want to immerse the person in your content, configure your space with thefullstyle. For more information, seeCreating fully immersive experiences in your app.\nUse low-priority tasks to generate meshes, because generating them is a computationally expensive operation. The following creates a mesh entity with collision shapes using scene reconstruction:\nNote\nScene reconstruction meshes only support thePhysicsBodyMode.staticphysics body component mode.\nEach object in the scene reconstruction mesh updates itsoriginFromAnchorTransforminformation independently and requires a separate static mesh because ARKit subdivides its representation of the world into multiple, distinct sections.\nDisplay scene reconstruction meshes during debugging\nPeople using an app that leverages scene reconstruction typically don\u2019t need to see a visual rendering of the scene reconstruction mesh. The system already shows passthrough video in an immersive experience. However, temporarily displaying the scene reconstruction mesh can help while you\u2019re developing and debugging your app. In Xcode\u2019s debugging toolbar, click the Enable Visualizations button and select Collision Shapes. Because each element of the scene reconstruction mesh has a collision component, the details of the mesh appear in the debug visualization. For more information, seeDiagnosing issues in the appearance of a running app.\nSee Also\nARKit",
        "https://developer.apple.com/documentation/visionos": "visionOS\nOverview\nvisionOS is the operating system that powers Apple Vision Pro. Use visionOS together with familiar tools and technologies to build immersive apps and games for spatial computing.\n\nDeveloping for visionOS requires a Mac with Apple silicon. Create new apps using SwiftUI to take full advantage of the spectrum of immersion available in visionOS. If you have an existing iPad or iPhone app, add the visionOS destination to your app\u2019s target to gain access to the standard system appearance, and add platform-specific features to create a compelling experience. To provide continuous access to your content in the meantime, deliver a compatible version of your app that runs in visionOS.\nExpand your app into immersive spaces\nStart with a familiar window-based experience to introduce people to your content. From there, addSwiftUIscene types specific to visionOS, such as volumes and spaces. These scene types let you incorporate depth, 3D objects, and immersive experiences.\nBuild your app\u2019s 3D content withRealityKitand Reality Composer Pro, and display it with aRealityView. In an immersive experience, useARKitto integrate your content with the person\u2019s surroundings.\n\nExplore new kinds of interaction\nPeople can select an element by looking at it and tapping their fingers together. They can also pinch, drag, zoom, and rotate objects using specific hand gestures.SwiftUIprovides built-in support for these standard gestures, so rely on them for most of your app\u2019s input. When you want to go beyond the standard gestures, useARKitto create custom gestures.\nTap to select\nPinch to rotate\nManipulate objects\nCreate custom gestures\nDive into featured sample apps\nExplore the core concepts for all visionOS apps with Hello World. Understand how to detect custom gestures using ARKit with Happy Beam. Discover streaming 2D and stereoscopic media with Destination Video. And learn how to build 3D scenes with RealityKit and Reality Composer Pro with Diorama and Swift Splash.\nTopics\nApp construction\nDesign\nSwiftUI\nRealityKit and Reality Composer Pro\nARKit\nVideo playback\nXcode and Simulator\nPerformance\niOS migration and compatibility\nEnterprise APIs for visionOS\nvisionOS\nOverview\nExpand your app into immersive spaces\nExplore new kinds of interaction\nDive into featured sample apps\nTopics",
        "https://developer.apple.com/documentation/visionos/introductory-visionos-samples": "visionOS\nIntroductory visionOS samples\nIntroductory visionOS samples\nIntroductory visionOS samples\nIntroductory visionOS samples\nOverview\nThe samples on this page are a starting point for developers new to visionOS. Each focuses on a specific feature, providing a solid foundation to build apps for the Apple Vision Pro.\nTopics\nBuilding shapes\nWorking with windows\nDrawing text\nImplementing an immersive space\nIntegrating ARKit\nBuilding materials\nApplying spatial audio\nCreating portals\nSee Also\nApp construction",
        "https://developer.apple.com/documentation/visionos/tracking-points-in-world-space": "visionOS\nTracking specific points in world space\nTracking specific points in world space\nTracking specific points in world space\nTracking specific points in world space\nOverview\nUse world anchors along with an ARKit session\u2019sWorldTrackingProviderto track points of interest in the world over time, as a person moves while wearing the device, and across device usage sessions. For example, someone might place a 3D object in a specific position on their desk and expect it to come back the next time they use the device.\nARKit keeps track of a unique identifier for each world anchor your app creates and automatically places those anchors back in the space when the person returns to your app in the same location. A world tracking provider also provides the position of the device the person is wearing.\nStart an ARKit session with world tracking\nUse anARKitSessionconfigured for world tracking to start receiving updates on the world anchors your app places. The following shows updates to world anchors your app previously registered using theaddAnchor(_:)method:\nImportant\nIf a person repositions the current space \u2014 for example, by holding down the Digital Crown \u2014 world anchor updates begin updating their position relative to the new world origin. For example, a world anchor placed on a table still reports information about the table\u2019s position, but those positions are relative to the updated world origin.\nCreate and add world anchors\nYou can create world anchors for any point of interest in your app\u2019s world coordinate system once you\u2019ve started a world tracking ARKit session. For example, you might track that a person placed an item at a particular offset from a desk in their space:\nOnce you add a world anchor to your app\u2019s tracking provider using theaddAnchor(_:)method, theanchorUpdatessequence in the current session and future runs of your app provides updates to the current position of that new world anchor.\nPersist world anchors across sessions\nThe only information ARKit persists about the world anchors in your app is theirUUID\u2014 aWorldAnchorinstance\u2019sidproperty \u2014 and pose in a particular space. It\u2019s your app\u2019s responsibility to persist additional information, such as the meaning of each anchor. For example, you might save local data about a custom 3D lamp model that a person placed on their desk.\nAs a person moves from town-to-town or room-to-room, your app won\u2019t receive all of the world anchor updates from each place someone used your app. Instead, theanchorUpdatessequence only provides world anchors for nearby objects.\nTrack the device position in the world\nUse the Compositor Services framework and theWorldTrackingProviderclass\u2019squeryDeviceAnchor(atTimestamp:)method to get low-latency information about the current and future-predicted pose of the person\u2019s device in world space. For more information, seeDrawing fully immersive content using Metal.\nSee Also\nARKit",
        "https://developer.apple.com/documentation/visionos/adding-3d-content-to-your-app": "visionOS\nAdding 3D content to your app\nAdding 3D content to your app\nAdding 3D content to your app\nAdding 3D content to your app\nOverview\nA device with a stereoscopic display lets people experience 3D content in a way that feels more real. Content appears to have real depth, and people can view it from different angles, making it seem like it\u2019s there in front of them.\nWhen building an app for visionOS, think about ways you might add depth to your app\u2019s interface. The system provides several ways to display 3D content, including in your existing windows, in a volume, and in an immersive space. Choose the options that work best for your app and the content you offer.\nWindow\nVolume\nImmersive space\nAdd depth to traditional 2D windows\nWindows are an important part of your app\u2019s interface. With visionOS, apps automatically get materials with the visionOS look and feel, fully resizable windows with spacing tuned for eyes and hands input, and access to highlighting adjustments for your custom controls.\nIncorporate depth effects into your custom views as needed, and use 3D layout options to arrange views in your windows.\nApply ashadow(color:radius:x:y:)orvisualEffect(_:)modifier to the view.\nApply ashadow(color:radius:x:y:)orvisualEffect(_:)modifier to the view.\nLift or highlight the view when someone looks at it using ahoverEffect(_:in:isEnabled:)modifier.\nLift or highlight the view when someone looks at it using ahoverEffect(_:in:isEnabled:)modifier.\nLay out views using aZStack.\nLay out views using aZStack.\nAnimate view-related changes withtransform3DEffect(_:).\nAnimate view-related changes withtransform3DEffect(_:).\nRotate the view using arotation3DEffect(_:axis:anchor:anchorZ:perspective:)modifier.\nRotate the view using arotation3DEffect(_:axis:anchor:anchorZ:perspective:)modifier.\nIn addition to giving 2D views more depth, you can also add static 3D models to your 2D windows. TheModel3Dview loads a USDZ file or other asset type and displays it at its intrinsic size in your window. Use this in places where you already have the model data in your app, or can download it from the network. For example, a shopping app might use this type of view to display a 3D version of a product.\nDisplay dynamic 3D scenes using RealityKit\nRealityKit is Apple\u2019s technology for building 3D models and scenes that you update dynamically onscreen. In visionOS, use RealityKit and SwiftUI together to seamlessly couple your app\u2019s 2D and 3D content. Load existing USDZ assets or create scenes in Reality Composer Pro that incorporate animation, physics, lighting, sounds, and custom behaviors for your content. To use a Reality Composer Pro project in your app, add the Swift package to your Xcode project and import its module in your Swift file. For more information, seeManaging files and folders in your Xcode project.\n\nWhen you\u2019re ready to display 3D content in your interface, use aRealityView. This SwiftUI view serves as a container for your RealityKit content, and lets you update that content using familiar SwiftUI techniques.\nThe following example shows a view that uses aRealityViewto display a 3D sphere. The code in the view\u2019s closure creates a RealityKit entity for the sphere, applies a texture to the surface of the sphere, and adds the sphere to the view\u2019s content.\nWhen SwiftUI displays yourRealityView, it executes your code once to create the entities and other content. Because creating entities is relatively expensive, the view runs your creation code only once. When you want to update the state of your entities, change the state of your view and use an update closure to apply those changes to your content. The following example uses an update closure to change the size of the sphere when the value in thescaleproperty changes:\nFor information about how to create content using RealityKit, seeRealityKit.\nRespond to interactions with RealityKit content\nTo handle interactions with the entities of your RealityKit scenes:\nAttach a gesture recognizer to yourRealityViewand add thetargetedToAnyEntity()modifier to it.\nAttach a gesture recognizer to yourRealityViewand add thetargetedToAnyEntity()modifier to it.\nAttach anInputTargetComponentto the entity or one of its parent entities.\nAttach anInputTargetComponentto the entity or one of its parent entities.\nAdd collision shapes to the RealityKit entities that support interactions.\nAdd collision shapes to the RealityKit entities that support interactions.\nThetargetedToAnyEntity()modifier provides a bridge between the gesture recognizer and your RealityKit content. For example, to recognize when someone drags an entity, specify aDragGestureand add the modifier to it. When the specified gesture occurs on an entity, SwiftUI executes the provided closure.\nThe following example adds a tap gesture recognizer to the sphere view from the previous example. The code also addsInputTargetComponentandCollisionComponentcomponents to the shape to allow the interactions to occur. If you omit these components, the view doesn\u2019t detect the interactions with your entity.\nDisplay 3D content in a volume\nA volume is a type of window that grows in three dimensions to match the size of the content it contains. Windows and volumes both accommodate 2D and 3D content, and are alike in many ways. However, windows clip 3D content that extends too far from the window\u2019s surface, so volumes are the better choice for content that is primarily 3D.\nTo create a volume, add aWindowGroupscene to your app and set its style tovolumetric. This style tells SwiftUI to create a window for 3D content. Include any 2D or 3D views you want in your volume. You can also add aRealityViewto build your content using RealityKit. The following example creates a volume with a static 3D model of some balloons stored in the app\u2019s bundle:\nWindows and volumes are a convenient way to display bounded 2D and 3D content, but your app doesn\u2019t control the placement of that content in the person\u2019s surroundings. The system sets the initial position of each window and volume at display time. The system also adds a window bar to allow someone to reposition the window or resize it.\n\nFor more information about when to use volumes, seeHuman Interface Guidelines > Windows.\nDisplay 3D content in a person\u2019s surroundings\nWhen you need more control over the placement of your app\u2019s content, add that content to anImmersiveSpace. An immersive space offers an unbounded area for your content, and you control the size and placement of content within the space. After receiving permission from the user, you can also use ARKit with an immersive space to integrate content into their surroundings. For example, you can use ARKit scene reconstruction to obtain a mesh of furniture and nearby objects and have your content interact with that mesh.\nAnImmersiveSpaceis a scene type that you create alongside your app\u2019s other scenes. The following example shows an app that contains an immersive space and a window:\nIf you don\u2019t add a style modifier to yourImmersiveSpacedeclaration, the system creates that space using themixedstyle. This style displays your content together with the passthrough content that shows the person\u2019s surroundings. Other styles let you hide passthrough to varying degrees. Use theimmersionStyle(selection:in:)modifier to specify which styles your space supports. If you specify more than one style, you can toggle between the styles using theselectionparameter of the modifier.\nWarning\nBe mindful of how much content you include in immersive scenes that use themixedstyle. Content that fills a significant portion of the screen, even if that content is partially transparent, can prevent the person from seeing potential hazards in their surroundings. If you want to immerse the person in your content, configure your space with thefullstyle. For more information, see,Creating fully immersive experiences in your app.\nRemember to set the position of items you place in anImmersiveSpace. Position SwiftUI views using modifiers, and position a RealityKit entity using its transform component. SwiftUI places the origin of a space at a person\u2019s feet initially, but can change this origin in response to other events. For example, the system might shift the origin to accommodate a SharePlay activity that displays your content with Spatial Personas. If you need to position SwiftUI views and RealityKit entities relative to one another, perform any needed coordinate conversions using the methods in thecontentparameter ofRealityView.\nTo display yourImmersiveSpacescene, open it using theopenImmersiveSpaceaction, which you obtain from the SwiftUI environment. This action runs asynchronously and uses the provided information to find and initialize your scene. The following example shows a button that opens the space with thesolarSystemidentifier:\nWhen an app presents anImmersiveSpace, the system hides the content of other apps to prevent visual conflicts. The other apps remain hidden while your space is visible but return when you dismiss it. If your app defines multiple spaces, you must dismiss the currently visible space before displaying a different space. If you don\u2019t dismiss the visible space, the system issues a runtime warning when you try to open the other space.\nSee Also\nApp construction",
        "https://developer.apple.com/documentation/visionos/accessing-the-main-camera": "visionOS\nAccessing the main camera\nAccessing the main camera\nAccessing the main camera\nAccessing the main camera\nOverview\nThis sample code project demonstrates how to use ARKit to access and display the left main camera frame in your visionOS app. You can use this functionality to implement computer vision-powered experiences or live streaming in your enterprise app. For instance, support technicians can live stream their surroundings to remote experts for improved guidance.\nConfigure the sample code project\nReplaceEnterprise.licensewith your license file. The sample app requires a valid license file to display the main camera.\nRequest the entitlement\nMain camera access is a part of enterprise APIs for visionOS, a collection of APIs that unlock capabilities for enterprise customers. To use main camera access, you need to apply for theMain camera accessentitlement. For more information, including how to apply for this entitlement, seeBuilding spatial experiences for business apps with enterprise APIs for visionOS.\nAdd usage descriptions for ARKit data access\nTo help protect people\u2019s privacy, visionOS limits app access to cameras and other sensors in Apple Vision Pro. You need to add anNSEnterpriseMCAMUsageDescriptionto your app\u2019s information property list to provide a usage description that explains how your app uses the data these sensors provide. People see this description when your app prompts for access to camera data.\nNote\nIn visionOS, ARKit is only available in an immersive space. SeeSetting up access to ARKit datato learn more about opening an immersive space and requesting authorization for ARKit data access. To learn more about best practices for privacy, seeAdopting best practices for privacy and user preferences.\nAccess and display main camera frames\nThe following code example accesses and displays the left main camera at the highest available resolution. To access the camera, start anARKitSessionwith aCameraFrameProvider, and then requestCameraFrameProvider.CameraFrameUpdatesin a given format. ARKit delivers a stream ofCameraFrameinstances; each frame includes aCameraFrame.Samplecontaining apixelBufferandCameraFrame.Sample.Parametersdescribing the frame\u2019s characteristics.\nTo display the frame\u2019s content, convert itspixelBufferto anImageusing the following extension:\nSee Also\nEnterprise APIs for visionOS",
        "https://developer.apple.com/documentation/visionos/object-tracking-with-reality-composer-pro-experiences": "visionOS\nObject tracking with Reality Composer Pro experiences\nObject tracking with Reality Composer Pro experiences\nObject tracking with Reality Composer Pro experiences\nObject tracking with Reality Composer Pro experiences\nOverview\nNote\nThis sample code project is associated with WWDC24 session100101: Explore object tracking for visionOS.\nConfigure the sample code project\nSimulator doesn\u2019t support ARKit, so you can only run this sample on a physical device. This sample can run on Apple Vision Pro with visionOS 2 or later.\nSee Also\nARKit",
        "https://developer.apple.com/documentation/visionos/bringing-your-app-to-visionos": "visionOS\nBringing your existing apps to visionOS\nBringing your existing apps to visionOS\nBringing your existing apps to visionOS\nBringing your existing apps to visionOS\nOverview\nIf you have an existing app that runs in iPadOS or iOS, you can build that app against the visionOS SDK to run it on the platform. Apps built specifically for visionOS adopt the standard system appearance, and they look more natural on the platform. Updating your app is also an opportunity to add elements that work well on the platform, such as 3D content and immersive experiences.\nIn most cases, all you need to do to support visionOS is update your Xcode project\u2019s settings and recompile your code. Depending on your app, you might need to make additional changes to account for features that are only found in the iOS SDK. While most of the same technologies are available on both platforms, some technologies don\u2019t make sense or require hardware that isn\u2019t present on visionOS devices. For example, people don\u2019t typically use a headset to make contactless payments, so apps that use the ProximityReader framework must disable those features when running in visionOS.\nNote\nIf you use ARKit in your iOS app to create an augmented reality experience, you need to make additional changes to support ARKit in visionOS. For information on how to update this type of app, seeBringing your ARKit app to visionOS.\nCreate a visionOS-specific version of your app\nTo update your app to build specifically for the visionOS SDK:\nIn your project\u2019s settings, select your app target.\nIn your project\u2019s settings, select your app target.\nNavigate to the General tab.\nNavigate to the General tab.\nIn Supported Destinations, click the Add (+) button to add a new destination and select the Apple Vision option.\nIn Supported Destinations, click the Add (+) button to add a new destination and select the Apple Vision option.\n\nWhen you add Apple Vision as a destination, Xcode makes some one-time changes to your project\u2019s build settings. After you add the destination, you can modify your project\u2019s build settings and build phases to customize the build behavior specifically for visionOS. For example, you might remove dependencies for the visionOS version of your app, or change the set of source files you want to compile.\nFor more information about how to update a target\u2019s configuration, seeCustomizing the build phases of a target.\nUpdate your code for features that are unavailable in visionOS\nThe first step to updating your existing app to run in visionOS is to stop using deprecated frameworks and to check for frameworks with behavioral changes in visionOS.\nIf your app currently uses deprecated APIs or frameworks, update your code to use appropriate replacements. visionOS removes many deprecated symbols entirely, turning these deprecation warnings into missing-symbol errors on the platform. Fix any deprecation warnings in the iOS version of your code before you build for visionOS to see the original deprecation warning and replacement details. ReadDetermining whether to bring your app to visionOSfor a list of deprecated frameworks.\nTo help you avoid using APIs for unavailable features, many frameworks offer APIs to check the availability of those features. Continue to use those APIs and take appropriate actions when the features aren\u2019t available. In other cases, prepare for the framework code to do nothing or to generate errors when you use it. ReadDetermining whether to bring your app to visionOSfor a list of APIs with availability checks and deprecated frameworks.\nThe iOS SDK includes many frameworks that don\u2019t apply to visionOS, either because they use hardware that isn\u2019t available or their features don\u2019t apply to the platform. Move code that uses these frameworks to separate source files whenever possible, and include those files only in the iOS version of your app. The following frameworks are available in the iOS SDK but not in the visionOS SDK.\n\n\n\nActivityKit\nAdSupport\nApp Clips\nAutomatedDeviceEnrollment\nBusinessChat\nCarKey\nCarPlay\nCinematic\nClockKit\nCoreLocationUI\nCoreMediaIO\nCoreNFC\nCoreTelephony\nDeviceActivity\nDockKit\nExposureNotification\nFamilyControls\nFinanceKit\nFinanceKitUI\nManagedSettings\nManagedSettingsUI\nMessages\nMLCompute\nNearbyInteraction\nOpenAL\nOpenGLES\nProximityReader\nSafetyKit\nScreenTime\nSensorKit\nServiceManagement\nSocial\nTwitter\nWidgetKit\nWorkoutKit\n\nWhen you can\u2019t isolate the code to separate source files, use conditional statements such as the ones below to offer a different code path for visionOS and iOS. The following example shows how to do this:\nFor additional information about how to isolate code to the iOS version of your app, seeRunning code on a specific platform or OS version.\nUpdate your interface to take advantage of visionOS features\nAfter your existing code runs correctly in visionOS, look for ways to improve the experience you offer on the platform. In visionOS, you can display content using more than just windows. Think about ways to incorporate the following elements into your interface:\nDepth.Many SwiftUI views use visual effects to add depth. Look for similar ways to incorporate depth into your own custom views. For guidance on how best to incorporate depth and 3D elements in your interface, seeHuman Interface Guidelines.\nDepth.Many SwiftUI views use visual effects to add depth. Look for similar ways to incorporate depth into your own custom views. For guidance on how best to incorporate depth and 3D elements in your interface, seeHuman Interface Guidelines.\n3D content.Think about where you might incorporate 3D models and shapes into your content. Use RealityKit to implement your content, and aRealityViewto present that content from your app. SeeAdding 3D content to your app.\n3D content.Think about where you might incorporate 3D models and shapes into your content. Use RealityKit to implement your content, and aRealityViewto present that content from your app. SeeAdding 3D content to your app.\nImmersive experiences.Present a space to immerse someone in your app\u2019s content. Spaces let you place content anywhere in a person\u2019s surroundings. You can also create fully immersive experiences that display only your app\u2019s content. SeeCreating fully immersive experiences in your app.\nImmersive experiences.Present a space to immerse someone in your app\u2019s content. Spaces let you place content anywhere in a person\u2019s surroundings. You can also create fully immersive experiences that display only your app\u2019s content. SeeCreating fully immersive experiences in your app.\nInteractions with someone\u2019s surroundings.Use ARKit to facilitate interactions between your content and the surroundings. For example, detect planar surfaces to use as anchor points for your content. SeeARKitfor more details.\nInteractions with someone\u2019s surroundings.Use ARKit to facilitate interactions between your content and the surroundings. For example, detect planar surfaces to use as anchor points for your content. SeeARKitfor more details.\nColor.Standard visionOS windows typically use the system-defined glass material, which lets light and objects from people\u2019s physical surroundings show through. Use color sparingly to draw attention to specific elements. Refer to the visionOS platform specific guidelines in the Human Interface GuidelinesColordocumentation for best practices.\nColor.Standard visionOS windows typically use the system-defined glass material, which lets light and objects from people\u2019s physical surroundings show through. Use color sparingly to draw attention to specific elements. Refer to the visionOS platform specific guidelines in the Human Interface GuidelinesColordocumentation for best practices.\nSystem-provided UI components.Take advantage of the components built for visionOS in SwiftUI. Components likeTabViewappear on the bottom of iOS or iPadOS apps and on the left side of visionOS apps. Other UI elements, like ornaments, are introduced specifically for visionOS. Using these elements keeps your interface adaptable between platforms and provides hover effects for free.\nSystem-provided UI components.Take advantage of the components built for visionOS in SwiftUI. Components likeTabViewappear on the bottom of iOS or iPadOS apps and on the left side of visionOS apps. Other UI elements, like ornaments, are introduced specifically for visionOS. Using these elements keeps your interface adaptable between platforms and provides hover effects for free.\nAdditional information on how to design your layout for visionOS is available on the Human Interface GuidelinesLayoutpage.\nNote\nIf you use ARKit in your iOS app to create an augmented reality experience, you need to make additional changes to support ARKit in visionOS. For information on how to update this type of app, seeBringing your ARKit app to visionOS.\nConsider your implementation\nIf your existing app is built with UIKit, consider your implementation plan for visionOS. Although you can still use UIKit and load iOS storyboards into your app, you can\u2019t include visionOS-specific or 3D content without using SwiftUI.\nConsider migrating your app to SwiftUI. The declarative syntax gives you less code to maintain and makes it easier to validate that your interface does what you want. SwiftUI is also unified across all Apple platforms and adapts to device-specific behavior without extra work. To learn more about migrating to the SwiftUI lifecycle, seeMigrating to the SwiftUI life cycle. You can also continue using UIKit views in a SwiftUI app withUIViewRepresentable.\nIf you plan to continue using UIKit, readCreate adaptive layouts in UIKitto ensure your layout looks good on visionOS. The WWDC23 videoMeet UIKit for Spatial Computingwalks through bringing your UIKit app to visionOS and shows how to take advantage of native features for visionOS by including SwiftUI views usingUIHostingController.\nFor a tutorial on mixing SwiftUI and UIKit content, seeInterfacing with UIKit.\nCreate adaptive layouts in UIKit\nAlthough visionOS is built for SwiftUI adoption, you can continue to use and build out your UIKit codebase as well. If your UIKit app uses hardcoded values or relies onUIScreenfor layout, the first step to migrating your app to visionOS is to start using an adaptable layout. When you make decisions using device details, your app might produce inconsistent or erroneous results on an unknown device type, or it might fail altogether. Find solutions that rely on environmental information, rather than the device type. For example, SwiftUI and UIKit start layout using the app\u2019s window size, which isn\u2019t necessarily the same size as the device\u2019s display.\nNote\nDevice-specific information is available when you absolutely need it, but validate the information you receive and provide reasonable default behavior for unexpected values.\nThink about ways to create adaptive layouts using the following techniques:\nUse stack views.UIStackViewobjects adjust the position of their contained views automatically when interface dimensions change. Alternatively,Auto Layoutconstraints let you specify the rules that determine the size and position of the views in your interface.\nUse stack views.UIStackViewobjects adjust the position of their contained views automatically when interface dimensions change. Alternatively,Auto Layoutconstraints let you specify the rules that determine the size and position of the views in your interface.\nStay within layout margins.ReadPositioning content within layout marginsto set up constraints that respect layout margins and don\u2019t crowd other content.\nStay within layout margins.ReadPositioning content within layout marginsto set up constraints that respect layout margins and don\u2019t crowd other content.\nRespect the safe area.Place views so they\u2019re not obstructed by other content. Each view has alayout guidethat helps you create constraints to position your views within the safe area. ReadPositioning content relative to the safe areafor guidance.\nRespect the safe area.Place views so they\u2019re not obstructed by other content. Each view has alayout guidethat helps you create constraints to position your views within the safe area. ReadPositioning content relative to the safe areafor guidance.\nAdapt based on changes in UITraitCollection.Write code to adjust your app\u2019s layout according to changes in the iOS interface elements, such as size class, display scale, and layout direction. ReadUITraitCollectionfor more information.\nAdapt based on changes in UITraitCollection.Write code to adjust your app\u2019s layout according to changes in the iOS interface elements, such as size class, display scale, and layout direction. ReadUITraitCollectionfor more information.\nUpdate your app\u2019s assets\nAdd vector-based or high-resolution images to your project specifically to support visionOS. In visionOS, people can view your app\u2019s content at different angles and different distances, so image pixels rarely line up with screen pixels. Vector-based images work best because they maintain their detail and crispness at any size. For bitmap-based images, use high-resolution images (@2xor better) to ensure they retain detail at different sizes.\nFor more information about designing images for your app, seeImagesin Human Interface Guidelines.\nSee Also\niOS migration and compatibility",
        "https://developer.apple.com/documentation/visionos/locating-and-decoding-barcodes-in-3d-space": "visionOS\nLocating and decoding barcodes in 3D space\nLocating and decoding barcodes in 3D space\nLocating and decoding barcodes in 3D space\nLocating and decoding barcodes in 3D space\nOverview\nThis sample code project demonstrates how to use barcode detection in ARKit to detect, decode, and place content near barcodes in your visionOS app. ARKit enables your visionOS app to detect barcodes (including QR codes), locate their positions in a person\u2019s surroundings, and decode their contents. For example, a warehouse worker can use your app to retrieve an item by looking at a package\u2019s barcode to confirm its contents.\nConfigure your sample code project\nReplaceEnterprise.licensewith your license file. The sample app requires a valid license file to detect barcodes.\nRequest the entitlement\nBarcode detection is a part of enterprise APIs for visionOS, a collection of APIs that unlock capabilities for enterprise customers. To use barcode detection, you need to apply for theSpatial barcode and QR code scanningentitlement. For more information, including how to apply for this entitlement, seeBuilding spatial experiences for business apps with enterprise APIs for visionOS.\nAdd usage descriptions for ARKit data access\nTo help protect people\u2019s privacy, visionOS limits app access to cameras and other sensors in Apple Vision Pro. You need to add anNSWorldSensingUsageDescriptionto your app\u2019s information property list to provide a usage description that explains how your app uses the data those sensors provide. People see this description when your app prompts for access to world-sensing data.\nNote\nIn visionOS, ARKit is only available in an immersive space. SeeSetting up access to ARKit datato learn more about opening an immersive space and requesting authorization for ARKit data access. To learn more about best practices for privacy, seeAdopting best practices for privacy and user preferences.\nDetect, decode, and highlight barcodes\nYour visionOS app can detect barcodes in a person\u2019s surroundings and highlight the barcode the person is looking for. The following code example detects and highlights every Code 128 or QR Code symbology in a person\u2019s surroundings. The code example includes three steps: detecting the barcode, printing its decoded content, and creating the highlight animation.\nTo start detecting barcodes, create aBarcodeDetectionProviderto get the positions of barcodes. Next, specify theBarcodeAnchor.Symbologyto indicate the types of barcodes you want ARKit to detect in the person\u2019s surroundings. Then, start anARKitSessionwith theBarcodeDetectionProvider.\nARKit delivers an asynchronous stream of updates as it detects changes in the scene. Each update includes aBarcodeAnchorcontaining the barcode\u2019s payload, extent, and transform. To implement the highlight animation, create a plane that you size and position to match that of the barcode, then fade it in and out.\nNote\nYou define a barcode\u2019s extents in the x-z plane. They have a width (x-axis), depth (z-axis), and zero height (y-axis).\nNote\nBecauseBarcodeDetectionProviderhas a low refresh rate, use its transform to initialize the position of content relative to a stationary barcode.\nDetermine the ideal barcode width\nThe sample code project can\u2019t read barcodes that are too small to appear clearly in a person\u2019s field of view. Larger barcodes generally improve readability, providing that they remain within the field of view. The minimum barcode size depends on itsBarcodeAnchor.Symbology. Refer to the table below to determine the minimum width required for a barcode to be readable under nominal lighting conditions (100 lux) at an arm\u2019s length distance (~40 cm).\nSymbology\nMinimum width (in cm)\nAztec\tCode\n2.0\nCodabar\n5.5\nCode 39\n6.5\nCode 39 Checksum\n6.5\nCode 39 Full ASCII\n3.0\nCode 39 Full ASCII Checksum\n4.5\nCode 93\n5.0\nCode 93i\n5.0\nCode 128\n2.5\nData Matrix\n1.0\nEAN-8\n3.0\nEAN-13\n4.0\nGS1 DataBar\n3.0\nGS1 DataBar Expanded\n6.5\nGS1 DataBar Limited\n3.0\nITF\n3.5\nITF-14\n5.0\nITF Checksum\n3.5\nMicroPDF417\n6.5\nMicro QR Code\n2.0\nMSI Plessey\n4.5\nPDF417\n6.0\nQR Code\n1.5\nUPC-E\n2.5\nSee Also\nEnterprise APIs for visionOS",
        "https://developer.apple.com/documentation/visionos/creating-fully-immersive-experiences": "visionOS\nCreating fully immersive experiences in your app\nCreating fully immersive experiences in your app\nCreating fully immersive experiences in your app\nCreating fully immersive experiences in your app\nOverview\nA fully immersive experience replaces everything the person sees with custom content you create. You might use this type of experience to:\nOffer a temporary transitional experience\nOffer a temporary transitional experience\nCreate a distraction-free space for your content\nCreate a distraction-free space for your content\nImplement a virtual reality (VR) game\nImplement a virtual reality (VR) game\nPresent a virtual world to explore\nPresent a virtual world to explore\nWith a fully immersive experience, you\u2019re responsible for everything that appears onscreen. The system hides passthrough video and displays the content you provide, showing the person\u2019s hands only when they come into view. To achieve the best performance, use RealityKit or Metal to create and animate your content.\nTypically, you combine a fully immersive experience with other types of experiences and provide transitions between them. When you display a window first and then offer controls to enter your immersive experience, you give people time to prepare for the transition. It also gives them the option to skip the experience if they prefer to use your app\u2019s windows instead.\nPrepare someone for your app\u2019s transitions\nGive people control over when they enter or exit fully immersive experiences, and provide clear transitions to and from those experiences. Clear visual transitions make it easier to adjust to such a large change. Sudden transitions might be disorienting, unpleasant, or make the person think something went wrong.\nAt launch time, display windows or other content that allows the person to see their surroundings. Add controls to that content to initiate the transition to the fully immersive experience, and provide a clear indication of what the controls do. Inside your experience, provide clear controls and instructions on how to exit the experience.\nWarning\nWhen you start a fully immersive experience, visionOS defines a system boundary that extends approximately 1.5 meters from the initial position of the person\u2019s head. If their head moves outside of that zone, the system automatically stops the immersive experience and turns on the external video again. This feature is an assistant to help prevent someone from colliding with objects.\nFor guidelines on how to design fully immersive experiences, seeHuman Interface Guidelines.\nOpen an immersive space\nTo create a fully immersive experience, open anImmersiveSpaceand set its style tofull. An immersive space is a type of SwiftUI scene that lets you place content anywhere in the person\u2019s surroundings. Applying thefullstyle to the scene tells the system to hide passthrough video and display only your app\u2019s content.\nDeclare spaces in thebodyproperty of your app object, or anywhere you manage SwiftUI scenes. The following example shows an app with a main window and a fully immersive space. At launch time, the app displays the window.\nTo display anImmersiveSpace, open it using theopenImmersiveSpaceaction, which you obtain from the SwiftUI environment. This action runs asynchronously and uses the provided information to find and initialize your scene. The following example shows a button that opens the space with thesolarSystemidentifier:\nAn app can display only one space at a time, and it\u2019s an error for you to try to open a space while another space is visible. To dismiss an open space, use thedismissImmersiveSpaceaction.\nFor more information about displaying spaces, see theImmersiveSpacetype.\nDraw your content using RealityKit\nRealityKit works well when your content consists of primitive shapes or existing content in USD files. Organize the contents of your scene using RealityKit entities, and animate that content using components and systems. Use Reality Composer Pro to assemble your content visually, and to attach dynamic shaders, animations, audio, and other behaviors to your content. Display the contents of your RealityKit scene in aRealityViewin your scene.\nTo load a Reality Composer Pro scene at runtime, fetch the URL of your Reality Composer Pro package file, and load the root entity of your scene. The following example shows how to create the entity for a package located in the app\u2019s bundle:\nFor more information about how to display content in aRealityViewand manage interactions with your content, seeAdding 3D content to your app.\nDraw your content using Metal\nAnother option for creating fully immersive scenes is to draw everything yourself using Metal. When using Metal to draw your content, use the Compositor Services framework to place that content onscreen. Compositor Services provides the code you need to set up your Metal rendering engine and start drawing.\nFor details on how to render content using Metal and Compositor Services, and manage interactions with your content, seeDrawing fully immersive content using Metal.\nSee Also\nApp construction",
        "https://developer.apple.com/documentation/visionos#Enterprise-APIs-for-visionOS": "visionOS\nOverview\nvisionOS is the operating system that powers Apple Vision Pro. Use visionOS together with familiar tools and technologies to build immersive apps and games for spatial computing.\n\nDeveloping for visionOS requires a Mac with Apple silicon. Create new apps using SwiftUI to take full advantage of the spectrum of immersion available in visionOS. If you have an existing iPad or iPhone app, add the visionOS destination to your app\u2019s target to gain access to the standard system appearance, and add platform-specific features to create a compelling experience. To provide continuous access to your content in the meantime, deliver a compatible version of your app that runs in visionOS.\nExpand your app into immersive spaces\nStart with a familiar window-based experience to introduce people to your content. From there, addSwiftUIscene types specific to visionOS, such as volumes and spaces. These scene types let you incorporate depth, 3D objects, and immersive experiences.\nBuild your app\u2019s 3D content withRealityKitand Reality Composer Pro, and display it with aRealityView. In an immersive experience, useARKitto integrate your content with the person\u2019s surroundings.\n\nExplore new kinds of interaction\nPeople can select an element by looking at it and tapping their fingers together. They can also pinch, drag, zoom, and rotate objects using specific hand gestures.SwiftUIprovides built-in support for these standard gestures, so rely on them for most of your app\u2019s input. When you want to go beyond the standard gestures, useARKitto create custom gestures.\nTap to select\nPinch to rotate\nManipulate objects\nCreate custom gestures\nDive into featured sample apps\nExplore the core concepts for all visionOS apps with Hello World. Understand how to detect custom gestures using ARKit with Happy Beam. Discover streaming 2D and stereoscopic media with Destination Video. And learn how to build 3D scenes with RealityKit and Reality Composer Pro with Diorama and Swift Splash.\nTopics\nApp construction\nDesign\nSwiftUI\nRealityKit and Reality Composer Pro\nARKit\nVideo playback\nXcode and Simulator\nPerformance\niOS migration and compatibility\nEnterprise APIs for visionOS\nvisionOS\nOverview\nExpand your app into immersive spaces\nExplore new kinds of interaction\nDive into featured sample apps\nTopics",
        "https://developer.apple.com/documentation/visionos#Video-playback": "visionOS\nOverview\nvisionOS is the operating system that powers Apple Vision Pro. Use visionOS together with familiar tools and technologies to build immersive apps and games for spatial computing.\n\nDeveloping for visionOS requires a Mac with Apple silicon. Create new apps using SwiftUI to take full advantage of the spectrum of immersion available in visionOS. If you have an existing iPad or iPhone app, add the visionOS destination to your app\u2019s target to gain access to the standard system appearance, and add platform-specific features to create a compelling experience. To provide continuous access to your content in the meantime, deliver a compatible version of your app that runs in visionOS.\nExpand your app into immersive spaces\nStart with a familiar window-based experience to introduce people to your content. From there, addSwiftUIscene types specific to visionOS, such as volumes and spaces. These scene types let you incorporate depth, 3D objects, and immersive experiences.\nBuild your app\u2019s 3D content withRealityKitand Reality Composer Pro, and display it with aRealityView. In an immersive experience, useARKitto integrate your content with the person\u2019s surroundings.\n\nExplore new kinds of interaction\nPeople can select an element by looking at it and tapping their fingers together. They can also pinch, drag, zoom, and rotate objects using specific hand gestures.SwiftUIprovides built-in support for these standard gestures, so rely on them for most of your app\u2019s input. When you want to go beyond the standard gestures, useARKitto create custom gestures.\nTap to select\nPinch to rotate\nManipulate objects\nCreate custom gestures\nDive into featured sample apps\nExplore the core concepts for all visionOS apps with Hello World. Understand how to detect custom gestures using ARKit with Happy Beam. Discover streaming 2D and stereoscopic media with Destination Video. And learn how to build 3D scenes with RealityKit and Reality Composer Pro with Diorama and Swift Splash.\nTopics\nApp construction\nDesign\nSwiftUI\nRealityKit and Reality Composer Pro\nARKit\nVideo playback\nXcode and Simulator\nPerformance\niOS migration and compatibility\nEnterprise APIs for visionOS\nvisionOS\nOverview\nExpand your app into immersive spaces\nExplore new kinds of interaction\nDive into featured sample apps\nTopics",
        "https://developer.apple.com/documentation/visionos#SwiftUI": "visionOS\nOverview\nvisionOS is the operating system that powers Apple Vision Pro. Use visionOS together with familiar tools and technologies to build immersive apps and games for spatial computing.\n\nDeveloping for visionOS requires a Mac with Apple silicon. Create new apps using SwiftUI to take full advantage of the spectrum of immersion available in visionOS. If you have an existing iPad or iPhone app, add the visionOS destination to your app\u2019s target to gain access to the standard system appearance, and add platform-specific features to create a compelling experience. To provide continuous access to your content in the meantime, deliver a compatible version of your app that runs in visionOS.\nExpand your app into immersive spaces\nStart with a familiar window-based experience to introduce people to your content. From there, addSwiftUIscene types specific to visionOS, such as volumes and spaces. These scene types let you incorporate depth, 3D objects, and immersive experiences.\nBuild your app\u2019s 3D content withRealityKitand Reality Composer Pro, and display it with aRealityView. In an immersive experience, useARKitto integrate your content with the person\u2019s surroundings.\n\nExplore new kinds of interaction\nPeople can select an element by looking at it and tapping their fingers together. They can also pinch, drag, zoom, and rotate objects using specific hand gestures.SwiftUIprovides built-in support for these standard gestures, so rely on them for most of your app\u2019s input. When you want to go beyond the standard gestures, useARKitto create custom gestures.\nTap to select\nPinch to rotate\nManipulate objects\nCreate custom gestures\nDive into featured sample apps\nExplore the core concepts for all visionOS apps with Hello World. Understand how to detect custom gestures using ARKit with Happy Beam. Discover streaming 2D and stereoscopic media with Destination Video. And learn how to build 3D scenes with RealityKit and Reality Composer Pro with Diorama and Swift Splash.\nTopics\nApp construction\nDesign\nSwiftUI\nRealityKit and Reality Composer Pro\nARKit\nVideo playback\nXcode and Simulator\nPerformance\niOS migration and compatibility\nEnterprise APIs for visionOS\nvisionOS\nOverview\nExpand your app into immersive spaces\nExplore new kinds of interaction\nDive into featured sample apps\nTopics",
        "https://developer.apple.com/documentation/visionos/setting-up-access-to-arkit-data": "visionOS\nSetting up access to ARKit data\nSetting up access to ARKit data\nSetting up access to ARKit data\nSetting up access to ARKit data\nOverview\nIn visionOS, ARKit can enable new kinds of experiences that leverage data such as hand tracking and world sensing. The system gates access to this kind of sensitive information. Because people can decline your app\u2019s request to use ARKit data or revoke access later, you need to provide alternative ways to use your app and to handle cases where your app loses access to data.\n\nAdd usage descriptions for ARKit data access\nPeople need to know why your app wants to access data from ARKit. Add the following keys to your app\u2019s information property list to provide a user-facing usage description that explains how your app uses the data:\nUse this key if your app uses hand tracking.\nUse this key if your app uses image tracking, plane detection, or scene reconstruction.\nNote\nWorldtracking\u2014 unlike worldsensing\u2014 doesn\u2019t require authorization. For more information, seeTracking specific points in world space.\nChoose between up-front or as-needed authorization\nYou can choose when someone sees an authorization request to use ARKit data. If you need precise control over when the request appears, call therequestAuthorization(for:)method onARKitSessionto explicitly authorize access at the time you call it. Otherwise, people see an authorization request when you call therun(_:)method. This is an implicit authorization because the timing of the request depends entirely on when you start the session.\nOpen a space and run a session\nTo help protect people\u2019s privacy, ARKit data is available only when your app presents a Full Space and other apps are hidden. Present one of these space styles before calling therun(_:)method.\nThe following shows an app structure that\u2019s set up to use a space with ARKit:\nCallopenImmersiveSpacefrom your app\u2019s user interface to create a space, start running an ARKit session, and kick off an immersive experience. The following shows a simple view with a button that opens the space:\nProvide alternatives for declined and revoked authorizations\nSomeone might not want to give your app access to data from ARKit, or they might choose to revoke that access later in Settings. Handle these situations gracefully, and remove or transition content that depends on ARKit data. For example, you might fade out content that you need to remove, or recenter content to an appropriate starting position. If your app uses ARKit data to place content in a person\u2019s surroundings, consider letting people place content using the system-provided interface.\nProviding alternatives is especially important if you\u2019re using ARKit for user input. People using accessibility features, trackpads, keyboards, or other forms of input might need a way to use your app without ARKit.\nSee Also\nARKit",
        "https://developer.apple.com/documentation/visionos/reducing-the-rendering-cost-of-realitykit-content-on-visionos": "visionOS\nReducing the rendering cost of RealityKit content on visionOS\nReducing the rendering cost of RealityKit content on visionOS\nReducing the rendering cost of RealityKit content on visionOS\nReducing the rendering cost of RealityKit content on visionOS\nOverview\nThe complexity of the assets and features you use in aRealityViewhave a big impact on the work your app and the render server do to render each frame. On visionOS, the system continuously renders 3D content in response to changes in head position and also incorporates any changes you make through system updates. Performance bottlenecks that prevent timely rendering and responsive feedback interfere with the spatial experience.\nTo identify any performance bottlenecks, use the RealityKit Trace template to profile your app. The RealityKit Metrics instrument that it includes collects data on 3D mesh rendering, spatial systems, entity commits, animations, physics, and particles effects work. If you encounter performance bottlenecks in yourRealityKitscenes, attempt to reduce the overhead in the bottleneck area to improve the rendering and responsiveness of your app. With careful balancing, your app can maintain utility and realism without exhausting the resources available on the system. Minimize overhead in less noticeable areas while prioritizing aspects of your app that provide critical functionality and an engaging experience.\nFor information on how input propagates through the system and updates content on visionOS, seeUnderstanding the visionOS render pipeline. For more information on using the RealityKit Trace template in Instruments to profile your app, seeAnalyzing the performance of your visionOS app.\nRelated sessions from WWDC23\n\nSession 10099:Meet RealityKit Trace\nSession 10100:Optimize app power and performance for spatial computing\nSession 10274:Create 3D models for Quick Look spatial experiences\nSession 10160:Demystify SwiftUI performance\nSession 10080:Build spatial experiences with RealityKit\nReduce the complexity of meshes and materials\nTo reduce the render server\u2019s CPU overhead, lower draw call counts. One way to do this is to combine parts of your mesh that share a material. The render server performs a draw call for each individual part and uses the CPU to setup each call it sends to the GPU. While combining parts can improve performance, avoid combining parts that are far apart in your scene or that become too large to stay in the field of view when combined. The system renders the entire mesh for a part that is only partially in the field of view. It doesn\u2019t render a part that completely falls outside the field of view.\nTo reduce both the CPU time the render server spends to create data for the draw calls and rendering work on the GPU, lower vertex and triangle counts, and optimize your meshes for overdraw.Overdrawis drawing pixels multiple times to produce the final result.\nTo identify areas of complex mesh rendering, check the RealityKit Metrics instrument for 3D Render Encoding (CPU), 3D Render GPU (GPU), and GPU Work Stall (CPU) bottlenecks. The instrument collects metrics on the number of 3D Mesh Draw calls, 3D Mesh Triangles, and 3D Mesh Vertices. Expand the view of the RealityKit Metrics instrument in the timeline pane to reveal graphs of this data under the 3D Render section. Select the section to view these metrics under Summary: Reality Module Metrics in the detail pane.\n\nIn general, use less than:\n250 draw calls in the Shared Space (or 500 in a Full Space)\n250 draw calls in the Shared Space (or 500 in a Full Space)\n250k vertices and 250k triangles in the Shared Space (or 500k in a Full Space)\n250k vertices and 250k triangles in the Shared Space (or 500k in a Full Space)\nFind a balance between the other work your app needs to complete and the features of your 3D meshes. Complex meshes and materials in addition to frequent mesh draw calls can create CPU performance bottlenecks. The GPU overhead of visual effects the system applies to 3D content can make the effects of these complexities worse. Under certain conditions, the system applies visual effects automatically, for example, when an app\u2019s scenes overlap a scene from another app or a person\u2019s surroundings. In these cases, you can turn off other effects, such as grounding shadows. To turn off grounding shadows, toggle theGroundingShadowComponentsetting in Reality Composer Pro. You can efficiently use Physically Based materials in Reality Composer Pro for smaller, fully opaque content. For larger content or content you choose to make transparent, the environmental lighting these materials use is expensive. Consider using a custom material with an unlit surface and add lighting textures or other less expensive effects to produce a similar effect.\nLoad assets efficiently\nComplex assets take a long time to load, contribute to longer app launches, and can trigger expensive render updates. To reduce asset loading times and their impact:\nExport files from Reality Composer Pro to use in your visionOS project. Reality Composer Pro optimizes the content in these files for fast loading and lower memory costs.\nExport files from Reality Composer Pro to use in your visionOS project. Reality Composer Pro optimizes the content in these files for fast loading and lower memory costs.\nMinimize the number and size of expensive file types in your assets, such as textures, meshes, audio, and video files. Reality Composer Pro performs texture compression automatically when you use it to export your assets.\nMinimize the number and size of expensive file types in your assets, such as textures, meshes, audio, and video files. Reality Composer Pro performs texture compression automatically when you use it to export your assets.\nMinimize the number of entities, textures, and primitives that USD models contain and the number of distinct and custom materials they use.\nMinimize the number of entities, textures, and primitives that USD models contain and the number of distinct and custom materials they use.\nPreload assets that contain custom materials compiling shaders at runtime.\nPreload assets that contain custom materials compiling shaders at runtime.\nUse asynchronous loading APIs to avoid blocking the main thread. This can be especially useful when you need to load multiple assets together.\nUse asynchronous loading APIs to avoid blocking the main thread. This can be especially useful when you need to load multiple assets together.\nReuse assets as much as possible for entities that can share the same resources. Entities that use the same assets and models can load the file once and share instances.\nReuse assets as much as possible for entities that can share the same resources. Entities that use the same assets and models can load the file once and share instances.\nThe complexity of an asset is primarily depends on its size and the amount of sub-assets it contains. When a RealityView loads an asset, your app\u2019s process performs the work to load the asset but the system still registers the asset entities with the render server. The RealityKit Metrics instrument might detect a bottleneck, or stall, in the render server while loading an expensive asset.\nMinimize updates\nWhen your custom systems modify entities and audio components, your app uses the CPU to encode the update. Then the render server performs additional work on the CPU to decode it and apply the changes to your content. To reduce the number of updates that your 3D RealityKit scenes make per frame:\nMinimize the amount of entity creation and destruction that your app does per frame, especially for attachments. Create entities in advance, and hide or show them as needed by adding or removing them from the hierarchy or toggling the value ofisEnabled.\nMinimize the amount of entity creation and destruction that your app does per frame, especially for attachments. Create entities in advance, and hide or show them as needed by adding or removing them from the hierarchy or toggling the value ofisEnabled.\nPerform work in custom systems only when you require it, rather than on every single frame.\nPerform work in custom systems only when you require it, rather than on every single frame.\nChange properties deliberately and avoid altering them unnecessarily.\nChange properties deliberately and avoid altering them unnecessarily.\nReduce the number of entities your app updates in response to events and actions. One way to accomplish this is to flatten your mesh entity hierarchies.\nReduce the number of entities your app updates in response to events and actions. One way to accomplish this is to flatten your mesh entity hierarchies.\nLower the update rates of code based animations and reduce the number of entities that animations update.\nLower the update rates of code based animations and reduce the number of entities that animations update.\nAvoid triggering excessiveSwiftUIredraw when updating RealityKit entities.\nAvoid triggering excessiveSwiftUIredraw when updating RealityKit entities.\nNote\nCertain actions initiate updates indirectly. For example, a physics simulation might cause transform updates.\nTo identify areas of frequent and complex updates, check the RealityKit Metrics instrument for Entity Commits (CPU) and  Custom RealityKit Systems (CPU) bottlenecks. The instrument collects metrics on the number of app updates the render server receives and the number of entities that it creates and destroys. Expand the view of the RealityKit Metrics instrument in the timeline pane to reveal graphs of this data under the Entity Commits section. Select the section to view a summary of these metrics in the detail pane.\n\nThe number of updates the render server gets from all apps over a particular interval.\nThe number of entities the render server creates and destroys across frames.\nNote\nDepending on the type of content, you might see additional bottlenecks that result from these updates. Transform updates, animations, material updates, asset loading, and view hierarchy updates also cause the render server to redraw 3D content.\nOptimize animations\nMinimize the CPU overhead of your animations and the total number of entities your animation affects.\nFor transform and material animations, minimize the number of entities you impact to lower the cost your app incurs. For example, you might use a custom RealityKit system to trigger and run these animations and callmove(to:relativeTo:)or make changes to materials, rotation, scale and transform properties in your app\u2019s update loop. Each entity you impact adds to the work your custom systems do and results in additional entity commits between your app and the render server.\nFor code based animations, synchronize updates with the device\u2019s display refresh rate. Inconsistent animation update intervals create a poor visual experience. Avoid creating material animations by generating a sequence of new materials at runtime. Instead, use a single material and animate a set of parameters usingParameterSetandMaterialParameters. Retain a copy of the material structs in your app to reuse across frames. This approach avoids redundant allocations and unnecessary overhead.\nFor Skeletal animations, reduce the total number of vertices in mesh geometries, weights per vertex, and separate the animations in content where possible. The render server does most of the work to implement these animations running shader deformers on the GPU. Limiting the cost of these operations is important; their overhead is greater when operating on more complex mesh geometries.\nTo identify areas of frequent and complex updates, check the RealityKit Metrics instrument for RealityKit Animations (GPU) and RealityKit Animations (CPU) bottlenecks. The RealityKit Metrics instrument collects metrics on number of skeletal animations running. Expand the view of the RealityKit Metrics instrument in the timeline pane to reveal graphs of this data under the RealityKit Animation section. Select the section to view a summary of these metrics in the detail pane.\n\nReduce collisions\nCollisions between objects in the Shared Space result in expensive physics calculations. To reduce the number of collisions and the work the system performs to compute collisions:\nRemove colliders and dynamic rigid bodies from a scene that aren\u2019t necessary to produce the experience you want to create.\nRemove colliders and dynamic rigid bodies from a scene that aren\u2019t necessary to produce the experience you want to create.\nSpace objects apart or organize objects into groups to avoid clustering. For example, 200 rigid bodies bouncing about in a single box results in more collisions than 50 rigid bodies bouncing around in 4 separate boxes.\nSpace objects apart or organize objects into groups to avoid clustering. For example, 200 rigid bodies bouncing about in a single box results in more collisions than 50 rigid bodies bouncing around in 4 separate boxes.\nTry different shapes. Choose collision shapes that minimize contact. Simpler shapes require less compute time. Avoid usinggenerateCollisionShapes(recursive:static:)when you can pick a simple shape. This function might create a more complex shape to fit a mesh.\nTry different shapes. Choose collision shapes that minimize contact. Simpler shapes require less compute time. Avoid usinggenerateCollisionShapes(recursive:static:)when you can pick a simple shape. This function might create a more complex shape to fit a mesh.\nMinimize the number of colliders. Using collider components for tap interactions is expensive when you create a lot of colliders.\nMinimize the number of colliders. Using collider components for tap interactions is expensive when you create a lot of colliders.\nReduce the number of physics objects stacked on top of one another. Stacked and overlapping physics shapes require more memory to track the overlapping contact pairs.\nReduce the number of physics objects stacked on top of one another. Stacked and overlapping physics shapes require more memory to track the overlapping contact pairs.\nTip\nTake into account a mesh\u2019s structure when you usegenerateCollisionShapes(recursive:static:)to generate physics shapes. This function recursively generates shapes for the meshes, but the shapes might be inefficient for collisions. SetisStaticto true to generate static colliders that are more efficient.\nTo identify areas with high CPU overhead resulting from collisions and physics calculations, check the RealityKit Metrics instrument for RealityKit Physics (CPU) bottlenecks. Expand the RealityKit Metrics instrument in the timeline pane to reveal graphs of this data under the RealityKit Physics section. Select the section to view a summary of this data in the detail pane.\n\nLower the impact of particle effects\nTo reduce the overhead of particle systems and the number of draw calls they generate, minimize the the total number of particles you have in your app. Often, you can create a similar effects with fewer particles. Without increasing the total number of particles, try to produce more particles per particle emitter rather than running several particle emitters synchronously with a small number of particles each. Loading particle effects is also an expensive operation, so preload them whenever possible and avoid loading several at the same time.\nExperiment with different particle effects, shapes, and shaders when attempting to reduce the overhead of your particles on the GPU. The total number of vertices and triangles for all particles, and their material and transparency, affect the amount of GPU work and overdraw the particles require and the number of pixels your effects take up.\nTo identify areas with high GPU overhead resulting from particle effects simulation, check the RealityKit Metrics instrument for 3D Render GPU bottlenecks. To identify areas with high CPU overhead, check for Particles Update (CPU) bottlenecks. The instrument collects metrics on the number of Particle Draw Calls, Particle Triangles, and Particle Vertices. Expand the RealityKit Metrics instrument in the timeline pane to reveal graphs of this data under the 3D Render section. Select the section to view a summary of this data in the detail pane.\nView scene statistics in Reality Composer Pro\nTake advantage of the statistics Reality Composer Pro provides when you use it to author RealityKit scenes. To view this data:\nOpen the project\u2019s Reality Composer Pro (.realitycomposerpro) file in Reality Composer Pro.\nOpen the project\u2019s Reality Composer Pro (.realitycomposerpro) file in Reality Composer Pro.\nTo select a scene to inspect, click on its tab at the top of the project window.\nTo select a scene to inspect, click on its tab at the top of the project window.\nChoose View > Statistics to display the statistics at the bottom of the window.\nChoose View > Statistics to display the statistics at the bottom of the window.\n\nThe tool provides information about entity counts, physics, animations, particle emitters, materials, lighting effects, and mesh geometry that effect rendering overhead. For more information about Reality Composer Pro, seeDesigning RealityKit content with Reality Composer Pro.\nSee Also\nPerformance",
        "https://developer.apple.com/documentation/visionos/exploring_object_tracking_with_arkit": "visionOS\nExploring object tracking with ARKit\nExploring object tracking with ARKit\nExploring object tracking with ARKit\nExploring object tracking with ARKit\nOverview\nThe sample app demonstrates how to use a reference object to discover and track a specific object\u00a0in a person\u2019s surroundings in visionOS. This capability allows you to create engaging experiences based on objects in a person\u2019s surroundings and lets you  attach digital content to these objects. For example, you can build an app that uses reference objects to describe the specific assembly of a machine a person is testing or repairing. Using this reference model, when ARKit recognizes that object, you can attach digital content to it, such as a diagram of the device, more information about its function, and so on.\nThis sample includes a reference object that ARKit uses to recognize a Magic Keyboard in someone\u2019s surroundings.\nNote\nThis sample code project is associated with WWDC24Session 10101 \u2014 Explore object tracking for visionOS.\nConfigure the sample code project\nNote\nThis app requires Xcode 16 and visionOS 2 or later, and an Apple Vision Pro. Object tracking isn\u2019t supported in the visionOS simulator.\nIn the project\u2019s settings, select Signing and Capabilities.\nIn the project\u2019s settings, select Signing and Capabilities.\nSelect your team name from the drop-down menu.\nSelect your team name from the drop-down menu.\nPair Xcode with your device wirelessly or using the developer strap.\nPair Xcode with your device wirelessly or using the developer strap.\nClick Run or press Command-R to launch the app.\nClick Run or press Command-R to launch the app.\nImport the reference object to track a specific object\nObject tracking demonstrates two methods for importing a reference object into the app. The first loads reference objects directly from the app\u2019s bundle, as shown here:\nIn the second method, a person can provide a URL for a reference object file through a file importer dialog:\nRun object tracking on a session\nTo start receiving events, create anObjectTrackingProviderthat you initialize with a reference object, and then start anARKitSessionwith theObjectTrackingProvideryou created, as shown below:\nHandle adding, updating, removing, and visualizing objects\nARKit delivers an asynchronous stream of updates as it detects changes in the scene. Your app needs to process these as they arrive and update the scene in response. The example below demonstrates handling these events inside the app\u2019sRealityView:\nWhen the app adds objects to the scene, it attaches virtual content to the reference object using theObjectAnchorVisualizationentity to render a wireframe that shows the reference object\u2019s outline.\nCreate your own reference objects\nCreating your own reference objects requires an iPhone, iPad, or other device that you can use to create high-fidelity scans of the physical object you want to model, and a Mac with an M2 chip or later to process the images and create a reference object using Create ML.\nSee Also\nARKit",
        "https://developer.apple.com/documentation/visionos#RealityKit-and-Reality-Composer-Pro": "visionOS\nOverview\nvisionOS is the operating system that powers Apple Vision Pro. Use visionOS together with familiar tools and technologies to build immersive apps and games for spatial computing.\n\nDeveloping for visionOS requires a Mac with Apple silicon. Create new apps using SwiftUI to take full advantage of the spectrum of immersion available in visionOS. If you have an existing iPad or iPhone app, add the visionOS destination to your app\u2019s target to gain access to the standard system appearance, and add platform-specific features to create a compelling experience. To provide continuous access to your content in the meantime, deliver a compatible version of your app that runs in visionOS.\nExpand your app into immersive spaces\nStart with a familiar window-based experience to introduce people to your content. From there, addSwiftUIscene types specific to visionOS, such as volumes and spaces. These scene types let you incorporate depth, 3D objects, and immersive experiences.\nBuild your app\u2019s 3D content withRealityKitand Reality Composer Pro, and display it with aRealityView. In an immersive experience, useARKitto integrate your content with the person\u2019s surroundings.\n\nExplore new kinds of interaction\nPeople can select an element by looking at it and tapping their fingers together. They can also pinch, drag, zoom, and rotate objects using specific hand gestures.SwiftUIprovides built-in support for these standard gestures, so rely on them for most of your app\u2019s input. When you want to go beyond the standard gestures, useARKitto create custom gestures.\nTap to select\nPinch to rotate\nManipulate objects\nCreate custom gestures\nDive into featured sample apps\nExplore the core concepts for all visionOS apps with Hello World. Understand how to detect custom gestures using ARKit with Happy Beam. Discover streaming 2D and stereoscopic media with Destination Video. And learn how to build 3D scenes with RealityKit and Reality Composer Pro with Diorama and Swift Splash.\nTopics\nApp construction\nDesign\nSwiftUI\nRealityKit and Reality Composer Pro\nARKit\nVideo playback\nXcode and Simulator\nPerformance\niOS migration and compatibility\nEnterprise APIs for visionOS\nvisionOS\nOverview\nExpand your app into immersive spaces\nExplore new kinds of interaction\nDive into featured sample apps\nTopics",
        "https://developer.apple.com/documentation/visionos#app-top": "visionOS\nOverview\nvisionOS is the operating system that powers Apple Vision Pro. Use visionOS together with familiar tools and technologies to build immersive apps and games for spatial computing.\n\nDeveloping for visionOS requires a Mac with Apple silicon. Create new apps using SwiftUI to take full advantage of the spectrum of immersion available in visionOS. If you have an existing iPad or iPhone app, add the visionOS destination to your app\u2019s target to gain access to the standard system appearance, and add platform-specific features to create a compelling experience. To provide continuous access to your content in the meantime, deliver a compatible version of your app that runs in visionOS.\nExpand your app into immersive spaces\nStart with a familiar window-based experience to introduce people to your content. From there, addSwiftUIscene types specific to visionOS, such as volumes and spaces. These scene types let you incorporate depth, 3D objects, and immersive experiences.\nBuild your app\u2019s 3D content withRealityKitand Reality Composer Pro, and display it with aRealityView. In an immersive experience, useARKitto integrate your content with the person\u2019s surroundings.\n\nExplore new kinds of interaction\nPeople can select an element by looking at it and tapping their fingers together. They can also pinch, drag, zoom, and rotate objects using specific hand gestures.SwiftUIprovides built-in support for these standard gestures, so rely on them for most of your app\u2019s input. When you want to go beyond the standard gestures, useARKitto create custom gestures.\nTap to select\nPinch to rotate\nManipulate objects\nCreate custom gestures\nDive into featured sample apps\nExplore the core concepts for all visionOS apps with Hello World. Understand how to detect custom gestures using ARKit with Happy Beam. Discover streaming 2D and stereoscopic media with Destination Video. And learn how to build 3D scenes with RealityKit and Reality Composer Pro with Diorama and Swift Splash.\nTopics\nApp construction\nDesign\nSwiftUI\nRealityKit and Reality Composer Pro\nARKit\nVideo playback\nXcode and Simulator\nPerformance\niOS migration and compatibility\nEnterprise APIs for visionOS\nvisionOS\nOverview\nExpand your app into immersive spaces\nExplore new kinds of interaction\nDive into featured sample apps\nTopics",
        "https://developer.apple.com/documentation/visionos/placing-entities-using-head-and-device-transform": "visionOS\nPlacing entities using head and device transform\nPlacing entities using head and device transform\nPlacing entities using head and device transform\nPlacing entities using head and device transform\nOverview\nThis sample code project demonstrates how to create and display content that appears at a person\u2019s head location, and follows a person\u2019s view as they move their head in immersive spaces. It usesAnchorEntityandqueryDeviceAnchor(atTimestamp:)to get the transform of the person\u2019s head and Apple Vision Pro to place content relative to them.\nThis sample creates the following two views and allows you to toggle between them:\nA hummingbird and a feeder directly in front of the person wearing the device.\nA hummingbird and a feeder directly in front of the person wearing the device.\nA hummingbird that flies to stay in the view of the person wearing the device.\nA hummingbird that flies to stay in the view of the person wearing the device.\nThe sample code project uses RealityKit and ARKit, respectively, to position the entities relative to the person. You can run the sample app in either Simulator or on-device.\nNote\nSeeDesign considerations for vision and motionandMotionin the Human Interface Guidelines for guidance on continuously head-tracked entities.\nShow entities at a person\u2019s head position\nTo launch the hummingbird feeder at the position of the wearer\u2019s head, the sample usesAnchorEntitywith the anchoring target ofAnchoringComponent.Target.head. This target provides the center of the wearer\u2019s head, rather than the position of the device itself. You can only useAnchorEntityin an immersive space. Although it allows you to anchor content to the wearer\u2019s head, you can\u2019t access its transform because there\u2019s no authorization required. If you attempt to access the transform, the property returns the identity transform instead.\nNote\nYou can get the transform of anAnchorEntitywith a differentAnchoringComponent.Target, such as a hand, by using aSpatialTrackingSessionand requesting authorization from the person using the app.\nThe sample creates anAnchorEntitythat anchors to the wearer\u2019s head, and sets theAnchoringComponent.TrackingModetoonceto stop tracking after the initial anchor. The head-positioned entity root contains both the feeder entity and the hummingbird entity, which the sample loads from Reality Composer Pro. The app adds the root entity as a subentity of the head anchor to track it. The sample then offsets the feeder from the center of the wearer\u2019s head by setting the position.\nMove entities relative to device transform\nThis sample contains a hummingbird that reacts to the wearer while they move around. It achieves this by creating aSystemand usingqueryDeviceAnchorto update the entities in the scene with each scene update.\nYou can only usequeryDeviceAnchorin an immersive space, but it doesn\u2019t require authorization.\nNote\nqueryDeviceAnchorgives you the transform of the device, not the wearer\u2019s head. If you want to get the visual transform of the center of the wearer\u2019s head, useAnchorEntity(.head).\nThe sample starts by creating a RealityKit system, which allows you to update the entities with each scene update. SeeImplementing systems for entities in a scenefor information on creating a system class and using components to query entities. In the system, the app creates a query for entities with theFollowComponentWorldTrackingProviderand anARKitSessionas follows:\nThen, the sample starts the session by using theARKitSessionto run theWorldTrackingProvider.\nThe sample adds a customComponentnamedFollowComponentto the root entity of the hummingbird entity, and then uses it to query the entities in the scene to apply the movement to.\nImportant\nMake sure to register both the system and the component.\nThe following example shows how to query the device anchor and move the entity accordingly:\nThe sample keeps the hummingbird at the top right of the wearer\u2019s field of vision by setting the hummingbird\u2019s position relative to its root entity and offsetting it on theyandzaxes.\nSee Also\nRealityKit and Reality Composer Pro",
        "https://developer.apple.com/documentation/visionos/diorama": "visionOS\nDiorama\nDiorama\nDiorama\nDiorama\nOverview\nUse Reality Composer Pro to compose, edit, and preview RealityKit content for your visionOS app. In your Reality Composer Pro project, you can create one or more scenes, each of which contains a hierarchy of virtual objects called entities that your app can efficiently load and display.\nIn addition to helping you compose entity hierarchies, Reality Composer Pro also gives you the ability to add and configure components \u2014 even custom components that you\u2019ve written \u2014 to the entities in your scenes.\nYou can also design the visual appearance of entities usingShader Graph, a node-based visual tool for creating RealityKit materials. Shader Graph gives you a tremendous amount of control over the surface details and shape of entities. You can even create animated materials and dynamic materials that change based on the state of your app or user input.\nDiorama demonstrates many of RealityKit and Reality Composer Pro\u2019s features. It displays an interactive, virtual topographical trail map, much like the real-world dioramas you find at trailheads and ranger stations in national parks. This virtual map has points of interest you can tap to bring up more detailed information. You can also smoothly transition between two trail maps: Yosemite and Catalina Island.\nImport assets for building the scene\nYour Reality Composer Pro project must contain assets, which you use to compose scenes for your app. Diorama\u2019s project has several assets, including 3D models like the diorama table, trail map, some birds and clouds that fly over the map, and a number of sounds and images. Reality Composer Pro provides a library of 3D models you can use. Access the library by clicking the Add (+) button on the right side of the toolbar. Selecting objects from the library imports them into your project.\n\nDiorama uses custom assets instead of the available library assets. To use custom assets in your own Reality Composer Pro scenes, import them into your project in one of three ways: by dragging them to Reality Composer Pro\u2019s project browser, using File > Import from the File menu, or copying the assets into the.rkassetsbundle inside your project\u2019s Swift package.\n\nNote\nAlthough you can still load USDZ files and other assets directly in visionOS, RealityKit compiles assets in your Reality Composer Pro project into a binary format that loads considerably faster than loading from individual files.\nCreate scenes containing the app\u2019s entities\nA single Reality Composer Pro project can have multiple scenes. Asceneis an entity hierarchy stored in the project as a.usdafile that you can load and display in aRealityView. You can use Reality Composer\u2019s scenes to build an entire RealityKit scene, or to store reusable entity hierarchies that you can use as building block for composing scenes at runtime \u2014 the approach Diorama uses. You can add as many different scenes to your project as you need by selecting File > New > Scene, or pressing \u2318N.\nAt the top of the Reality Composer Pro window, there\u2019s a separate tab for every scene that\u2019s currently open. To open a scene, double-click the scene\u2019s.usdafile in the project browser. To edit a scene, select its tab, and make changes using the hierarchy viewer, the 3D view, and the inspector.\n\nAdd assets to your scenes\nRealityKit can only include entities in a scene, but it can\u2019t use every type of asset that Reality Composer Pro supports as an entity. Reality Composer Pro automatically turns some assets, like 3D models, into an entity when you place them in a scene. It uses other assets indirectly. It uses image files, for example, primarily to define the surface details of model entities.\nDiorama uses multiple scenes to group assets together and then, at runtime, combines those scenes into a single immersive experience. For example, the diorama table has its own scene that includes the table, the map surface, and the trail lines. There are separate scenes for the birds that flock over the table, and for the clouds that float above it.\n\nTo add entities to a scene, drag assets from the project browser to the scene\u2019s hierarchy view or 3D view. If the asset you drag is a type that can be represented as an entity, Reality Composer Pro adds it to your scene. You can select any asset in the scene hierarchy or the 3D view and change its location, rotation, and scale using the inspector on the right side of the window or the manipulator in the 3D view.\nAdd components to entities\nRealityKit follows a design pattern called Entity Component System (ECS). In an ECS app, you store additional data on an entity using components and can implement entity behavior by writing systems that use the data from those components. You can add and configure components to entities in Reality Composer Pro, including both shipped components likePhysicsBodyComponent, and custom components that you write and place in the Sources folder of your Reality Composer Pro Swift package. You can even create new components in Reality Composer Pro and then edit them in Xcode. For more information about ECS, seeUnderstanding the modular architecture of RealityKit.\nDiorama uses custom components to identify which transforms are points of interest, to mark the birds so the app can make sure they flock together, and to control the opacity of entities that are specific to just one of the two maps.\nTo add a component to an entity, select that entity in the hierarchy view or 3D view. At the bottom right of the inspector window, click on the Add Component button. A list of available components appears and the first item in that list is New Component. This item creates a new component class, and optionally a new system class, and adds the component to the selected entity.\nIf you look at the list of components, you see thePointOfInterestComponentthat Diorama uses to indicate which transforms are points of interest. If the selected entity doesn\u2019t already contain aPointOfInterestComponent, selecting that adds it to the selected entity. Each entity can only have one component of a specific type. You can edit the values of the existing component in the inspector, which changes what shows up when you tap that point of interest in the app.\n\nUse transforms to mark locations\nIn Reality Composer Pro, atransformis an empty entity that marks a point in space. A transform contains a location, rotation, and scale, and its child entities inherit those. But, transforms have no visual representation and do nothing by themselves. Use transforms to mark locations in your scene or organize your entity hierarchy. For example, you might make several entities that need to move together into child entities of the same transform, so you can move them together by moving the parent transform.\nDiorama uses transforms with aPointOfInterestComponentto indicate points of interest on the map. When the app runs, those transforms mark the location of the floating placards with the name of the location. Tapping on a placard expands it to show more detailed information. To turn transforms into an interactive view, the app looks for a specific component on transforms called aPointOfInterestComponent. Because a transform contains no data other than location, orientation, and scale, it uses this component to hold the data the app needs to display on the placards. If you open theDioramaAssembledscene in Reality Composer Pro and click on the transform calledCathedral_Rocks, you see thePointOfInterestComponentin the inspector.\n\nLoad a scene at runtime\nTo load a Reality Composer Pro scene, useload(named:in:), passing the name of the scene you want to load and the project\u2019s bundle. Reality Composer Pro Swift packages define a constant that provides ready access to its bundle. The constant is the name of the Reality Composer Pro project with \u201cBundle\u201d appended to the end. In this case, the project is calledRealityKitContent, so the constant is calledRealityKitContentBundle. Here\u2019s how Diorama loads the map table in theRealityViewinitializer:\nTheload(named:in:)function is asynchronous when called from an asynchronous context. Because the content closure of theRealityViewinitializer is asynchronous, it automatically uses theasyncversion to load the scene.  Note that when using it asynchronously, you must call it using theawaitkeyword.\nCreate the floating view\nDiorama adds aPointOfInterestComponentto a transform to display details about interesting places. Every point of interest\u2019s name appears in a view that floats above its location on the map. When you tap the floating view, it expands to show detailed information, which the app pulls from thePointOfInterestComponent. The app shows these details by creating a SwiftUI view for each point of interest and querying for all entities that have aPointOfInterestComponentusing this query declared inImmersiveView.swift:\nIn theRealityViewinitializer, Diorama queries to retrieve the points of interest entities and passes them to a function calledcreateLearnMoreView(for:), which creates the view and saves it for display when it\u2019s tapped.\nCreate attachments for points of interest\nDiorama displays the information added to aPointOfInterestComponentin aLearnMoreView, which it stores as an attachment.Attachmentsare SwiftUI views that are also RealityKit entities and that you can place into a RealityKit scene at a specific location. Diorama uses attachments to position the view that floats above each point of interest.\nThe app first checks to see if the entity has a component calledPointOfInterestRuntimeComponent. If it doesn\u2019t, it creates a new one and adds it to the entity. This new component contains a value you only use at runtime that you don\u2019t need to edit in Reality Composer Pro.\nBy putting this value into a separate component and adding it to entities at runtime, Reality Composer Pro never displays it in the inspector. ThePointOfInterestRuntimeComponentstores an identifier called anattachment tag, which uniquely identifies an attachment so the app can retrieve and display it at the appropriate time.\nNext, Diorama creates a SwiftUI view called aLearnMoreViewwith the information from thePointOfInterestComponent, tags that view, and stores the tag in thePointOfInterestRuntimeComponent. Finally, it stores the view in anAttachmentProvider, which is a custom class that maintains references to the attachment views so they don\u2019t get deallocated when they\u2019re not in a scene.\nDisplay point of interest attachments\nAssigning a view to an attachment provider doesn\u2019t actually display that view in the scene. The initializer forRealityViewhas an optional view builder calledattachmentsthat\u2019s used to specify the attachments.\nIn theupdateclosure of the initializer, which RealityKit calls when the contents of the view change, the app queries for entities with aPointOfInterestRuntimeComponent, uses the tag from that component to retrieve the correct attachment for it, and then adds that attachment and places it above its location on the map.\nCreate custom materials with Shader Graph\nTo switch between the two different topographical maps, Diorama shows a slider that morphs the map between the two locations. To accomplish this, and to draw elevation lines on the map, theFlatTerrainentity in theDioramaAssembledscene uses aShader Graph material. Shader Graph is a node-based material editor that\u2019s built into Reality Composer Pro. Shader Graph gives you the ability to create dynamic materials that you can change at runtime. Prior to Reality Composer Pro, the only way to implement a dynamic material like this was to create aCustomMaterialand write Metal shaders to implement the necessary logic.\nDiorama\u2019sDynamicTerrainMaterialEnhanceddoes two things. It draws contour lines on the map based on height data stored in displacement map images, and it also offsets the vertices of the flat disk based on the same data. By interpolating between two different height maps, the app achieves a smooth transition between the two different sets of height data.\nWhen you build Shader Graph materials, you can give them input parameters calledpromoted inputsthat you set from Swift code. This allows you to implement logic that previously required writing a Metal shader. The materials you build in the editor can affect both the look of an entity using the custom surface output node, which equates to writing Metal code in a fragment shader, or the position of vertices using the geometry modifier output, which equates to Metal code running in a vertex shader.\n\nNode graphs can containsubgraphs, which are similar to functions. They contain reusable sets of nodes with inputs and outputs. Subgraphs contain the logic to draw the contour lines and the logic to offset the vertices. Double-click a subgraph to edit it. For more information about building materials using Shader Graph, seeExplore Materials in Reality Composer Pro.\nUpdate the Shader Graph material at runtime\nTo change the map,DynamicTerrainMaterialEnhancedhas a promoted input calledProgress. If that parameter is set to1.0, it displays Catalina Island. If it\u2019s set to0, it displays Yosemite. Any other number shows a state in transition between the two. When someone manipulates the slider, the app updates that input parameter based on the slider\u2019s value.\nImportant\nShader Graph material parameters are case-sensitive. If the capitalization is wrong, your code won\u2019t actually update the material.\nThe app sets the value of the input parameter in a function calledhandleMaterial()that the slider\u2019s.onChangedclosure calls. That function retrieves theShaderGraphMaterialfrom the terrain entity and callssetParameter(name:value:)on it.\nSee Also",
        "https://developer.apple.com/documentation/visionos/making-your-app-compatible-with-visionos": "visionOS\nMaking your existing app compatible with visionOS\nMaking your existing app compatible with visionOS\nMaking your existing app compatible with visionOS\nMaking your existing app compatible with visionOS\nOverview\nA compatible iPadOS or iOS app links against the iOS SDK and runs in visionOS without needing to add a visionOS destination. Although visionOS provides a complete set of iOS frameworks for linking, some features of those frameworks might be unavailable due to hardware or usage differences. ReadDetermining whether to bring your app to visionOSfor details on behavior changes, API availability checks, and deprecated frameworks. To ensure your app runs correctly in visionOS, handle any unavailable features gracefully and provide workarounds wherever possible.\nRun as a compatible app in visionOS\nThe App Store makes compatible iPad and iPhone apps available in visionOS automatically after you sign the updated Apple Developer Program License Agreement. If you have an app in the iOS App Store, try downloading it on Apple Vision Pro and run it. If you built your app using the iOS SDK, Xcode 15 and later automatically adds a Designed for iPad runtime destination to your project.\n\nUse this destination to run your app and test its compatibility in visionOS. Depending on your app, you might need to make additional changes to account for features that are only found in the iOS SDK. You can test most of your app\u2019s core functionality in Simulator, but some features are available only on a device.\nHandle SDK differences gracefully\nvisionOS contains most of the same technologies as iPadOS and iOS, but there are differences. In some cases, a feature you use in your app might not be available because of hardware differences or because of differences in how people use a visionOS device. As part of your testing, consider the impact of any unavailable features on your app\u2019s overall experience. Whenever possible, work around unavailable features by disabling them or providing alternate ways to access the same content.\nThe following features aren\u2019t available in compatible iPad and iPhone apps in visionOS. Use framework APIs listed inDetermining whether to bring your app to visionOSto determine when the features are available.\nCore Motion services\nCore Motion services\nBarometer and magnetometer data\nBarometer and magnetometer data\nAll location services except the standard service\nAll location services except the standard service\nHealthKit data\nHealthKit data\nVideo or still-photo capture\nVideo or still-photo capture\nCamera features like Auto Focus or flash\nCamera features like Auto Focus or flash\nRear-facing (selfie) cameras\nRear-facing (selfie) cameras\nNote\nAlthough device cameras are unavailable on Apple Vision Pro, compatible apps can capture photos of personas usingAVCaptureDevicewith the position of.frontor use continuity camera to capture photo and video from iPhone and iPad.\nIf your app uses an unsupported feature but can function without it, you can still bring your app to visionOS. Remove features that aren\u2019t available and focus on bringing the rest of your content to the platform. For example, if you have an app that lets people write down notes and take pictures to include with those notes, disable the picture-taking ability in visionOS but let people add text and incorporate images from their library.\nIf your app relies on frameworks that behave differently in visionOS, update your code to handle those differences. Throughout your code, make sure you respond to unusual situations:\nUse availability checks.Availability checks give you a clear indication when you can\u2019t use a feature, but some frameworks might have more subtle behavior. ReadDetermining whether to bring your app to visionOSfor a list of frameworks and features with availability checks.\nUse availability checks.Availability checks give you a clear indication when you can\u2019t use a feature, but some frameworks might have more subtle behavior. ReadDetermining whether to bring your app to visionOSfor a list of frameworks and features with availability checks.\nRemove deprecated code.If your app currently uses deprecated APIs or frameworks, update your code to use appropriate replacements. ReadDetermining whether to bring your app to visionOSfor a list of deprecated frameworks.\nRemove deprecated code.If your app currently uses deprecated APIs or frameworks, update your code to use appropriate replacements. ReadDetermining whether to bring your app to visionOSfor a list of deprecated frameworks.\nHandle error conditions.If a function throws an exception or returns an error, handle the error. Use error information to adjust your app\u2019s behavior or provide an explanation of why it can\u2019t perform certain operations.\nHandle error conditions.If a function throws an exception or returns an error, handle the error. Use error information to adjust your app\u2019s behavior or provide an explanation of why it can\u2019t perform certain operations.\nHandlenilor empty values gracefully.Validate objects and return values before you try to use them.\nHandlenilor empty values gracefully.Validate objects and return values before you try to use them.\nUpdate your user interface.Provide appropriate messaging in your interface when a feature is unavailable, or remove feature-specific views entirely if you can do so cleanly. Don\u2019t leave empty views where the feature was.\nUpdate your user interface.Provide appropriate messaging in your interface when a feature is unavailable, or remove feature-specific views entirely if you can do so cleanly. Don\u2019t leave empty views where the feature was.\nAdapt to device differences\nApple frameworks take a device-agnostic approach whenever possible to minimize issues when you use them on different device types. Apple devices come in a variety of shapes and sizes, with different sets of features. Rather than build your app for a specific device, make sure it adapts to any device and can gracefully handle differences.\nBuild robustness into your app during the design process. Avoid assumptions that might cause your app to break when it runs on a new device, and make sure your app adapts dynamically to different conditions. For example:\nDon\u2019t assume the device type or idiom is always iPhone, iPad, or iPod Touch.Avoid decisions based on the current idiom. If you do rely on the current idiom, provide reasonable defaults for unknown idioms.\nDon\u2019t assume the device type or idiom is always iPhone, iPad, or iPod Touch.Avoid decisions based on the current idiom. If you do rely on the current idiom, provide reasonable defaults for unknown idioms.\nDesign your app to handle unavailable hardware or features.Specific hardware and features might be unavailable for many different reasons. For example, a feature might be unavailable when your app runs in Simulator. Perform availability checks whenever possible, and handle unavailable features gracefully.\nDesign your app to handle unavailable hardware or features.Specific hardware and features might be unavailable for many different reasons. For example, a feature might be unavailable when your app runs in Simulator. Perform availability checks whenever possible, and handle unavailable features gracefully.\nDesign your windows and views to adapt dynamically.Build your interface to adapt dynamically to any size using SwiftUI or Auto Layout. Assume the size of your app can change dynamically.\nDesign your windows and views to adapt dynamically.Build your interface to adapt dynamically to any size using SwiftUI or Auto Layout. Assume the size of your app can change dynamically.\nDon\u2019t assume the device has a specific number of displays.People can connect iPad and iPhone to an external display, and visionOS devices use two displays to create a stereoscopic version of your app\u2019s content.\nDon\u2019t assume the device has a specific number of displays.People can connect iPad and iPhone to an external display, and visionOS devices use two displays to create a stereoscopic version of your app\u2019s content.\nDon\u2019t make assumptions based on the available frameworks or symbols.The presence or absence of frameworks or code symbols is an unreliable way to identify a device type and can change in later software updates. SeeDetermining whether to bring your app to visionOSfor information on using availability checks to identify which features are available for a given framework.\nDon\u2019t make assumptions based on the available frameworks or symbols.The presence or absence of frameworks or code symbols is an unreliable way to identify a device type and can change in later software updates. SeeDetermining whether to bring your app to visionOSfor information on using availability checks to identify which features are available for a given framework.\nDon\u2019t assume your app runs in the background.visionOS doesn\u2019t support location, external accessory, or Bluetooth-peripheral background execution modes.\nDon\u2019t assume your app runs in the background.visionOS doesn\u2019t support location, external accessory, or Bluetooth-peripheral background execution modes.\nDon\u2019t assume that background apps are hidden.In visionOS, the windows of background apps remain visible, but are dimmed when no one looks at them. The only time app windows disappear is when one app presents an immersive space.\nDon\u2019t assume that background apps are hidden.In visionOS, the windows of background apps remain visible, but are dimmed when no one looks at them. The only time app windows disappear is when one app presents an immersive space.\nAudit your interface code\nTo minimize disruptions, visionOS runs your compatible iPad or iPhone app in an environment that matches an iPad as much as possible. Windows and views retain the same appearance that they have in iPadOS or iOS, and the system sizes your app\u2019s window to fit an iPad whenever possible.\nWhen building your app\u2019s interface, make choices that ensure your app runs well in visionOS too. Adopt the following best practices for your interface-related code:\nSupport iPad and iPhone in the same app.Create one app that supports both device types, rather than separate apps for each device. SwiftUI and UIKit support adaptable interfaces, and Xcode provides tools to help you visualize your interface at different supported sizes.\nSupport iPad and iPhone in the same app.Create one app that supports both device types, rather than separate apps for each device. SwiftUI and UIKit support adaptable interfaces, and Xcode provides tools to help you visualize your interface at different supported sizes.\nOrganize your interface using scenes.Scenes are a fundamental tool for managing your app\u2019s interface. Use the scene types in SwiftUI and UIKit to assemble and manage the views you display in windows.\nOrganize your interface using scenes.Scenes are a fundamental tool for managing your app\u2019s interface. Use the scene types in SwiftUI and UIKit to assemble and manage the views you display in windows.\nAdapt your interface to any size.Design your interface to adapt naturally to different sizes. For an introduction to SwiftUI views and layout, seeDeclaring a custom view. For information about laying out views in UIKit, seeView layout.\nAdapt your interface to any size.Design your interface to adapt naturally to different sizes. For an introduction to SwiftUI views and layout, seeDeclaring a custom view. For information about laying out views in UIKit, seeView layout.\nDon\u2019t access screen details.visionOS provides reasonable values forUIScreenobjects, but don\u2019t use those values to make decisions. Instead, create an adaptive layout or useAuto Layoutto make your app look good on all platforms.\nDon\u2019t access screen details.visionOS provides reasonable values forUIScreenobjects, but don\u2019t use those values to make decisions. Instead, create an adaptive layout or useAuto Layoutto make your app look good on all platforms.\nDon\u2019t rely on the status bar for layouts.statusBarFramereturnsCGRectZeroon visionOS. Usesafe areasto calculate layout instead.\nDon\u2019t rely on the status bar for layouts.statusBarFramereturnsCGRectZeroon visionOS. Usesafe areasto calculate layout instead.\nSpecify the supported interface orientations.Add theUISupportedInterfaceOrientationskey to your app\u2019sInfo.plistfile to specify the interface orientations it supports. Support all interface orientations whenever possible. visionOS adds an interface rotation for your app button only when this key is present. To display your app\u2019s interface in a particular orientation at launch, add theUIPreferredDefaultInterfaceOrientationkey to your app\u2019sInfo.plistfile. Set the value of the key to one of the values in your app\u2019sUISupportedInterfaceOrientationskey. Add~ipador~iphoneto the key name, for example,UIInterfaceOrientationPortrait~ipad, to specify device-specific orientation preferences.\nSpecify the supported interface orientations.Add theUISupportedInterfaceOrientationskey to your app\u2019sInfo.plistfile to specify the interface orientations it supports. Support all interface orientations whenever possible. visionOS adds an interface rotation for your app button only when this key is present. To display your app\u2019s interface in a particular orientation at launch, add theUIPreferredDefaultInterfaceOrientationkey to your app\u2019sInfo.plistfile. Set the value of the key to one of the values in your app\u2019sUISupportedInterfaceOrientationskey. Add~ipador~iphoneto the key name, for example,UIInterfaceOrientationPortrait~ipad, to specify device-specific orientation preferences.\nAdopt vector-based images when possible.Vector-based images scale well to different sizes while retaining a crisp appearance. If you use bitmap-based assets, make them the exact size you need. Don\u2019t use oversized assets, which require extra work to display at the correct size.\nAdopt vector-based images when possible.Vector-based images scale well to different sizes while retaining a crisp appearance. If you use bitmap-based assets, make them the exact size you need. Don\u2019t use oversized assets, which require extra work to display at the correct size.\nUpdate hover effects in custom views.Hover effects convey the focused view or control in your interface. Standard system views apply hover effects as needed. For custom views and controls, verify that the hover effects look appropriate in visionOS. Add or update the content shape for your hover effects if needed. The following example uses SwiftUI to add a rectangle-shaped hover effect to a rectangle in a view:\nUpdate hover effects in custom views.Hover effects convey the focused view or control in your interface. Standard system views apply hover effects as needed. For custom views and controls, verify that the hover effects look appropriate in visionOS. Add or update the content shape for your hover effects if needed. The following example uses SwiftUI to add a rectangle-shaped hover effect to a rectangle in a view:\nCreate adaptive layouts in UIKit\nIf your UIKit app uses hardcoded values or relies onUIScreenfor layout, the first step to migrating your app to visionOS is to use an adaptable layout. When you make decisions using device details, your app might produce inconsistent or erroneous results on an unknown device type, or it might fail altogether. Find solutions that rely on environmental information, rather than the device type. For example, SwiftUI and UIKit start layout using the app\u2019s window size, which isn\u2019t necessarily the same size as the device\u2019s display.\nNote\nDevice-specific information is available when you absolutely need it, but validate the information you receive and provide reasonable default behavior for unexpected values.\nThink about ways to create adaptive layouts using the following techniques:\nUse stack views.UIStackViewobjects adjust the position of their contained views automatically when interface dimensions change. Alternatively,Auto Layoutconstraints let you specify the rules that determine the size and position of the views in your interface.\nUse stack views.UIStackViewobjects adjust the position of their contained views automatically when interface dimensions change. Alternatively,Auto Layoutconstraints let you specify the rules that determine the size and position of the views in your interface.\nStay within layout margins.ReadPositioning content within layout marginsto set up constraints that respect layout margins and don\u2019t crowd other content.\nStay within layout margins.ReadPositioning content within layout marginsto set up constraints that respect layout margins and don\u2019t crowd other content.\nRespect the safe area.Place views so they\u2019re not obstructed by other content. Each view has alayout guidethat helps you create constraints to position your views within the safe area, which adapt to the current device automatically. ReadPositioning content relative to the safe areafor guidance.\nRespect the safe area.Place views so they\u2019re not obstructed by other content. Each view has alayout guidethat helps you create constraints to position your views within the safe area, which adapt to the current device automatically. ReadPositioning content relative to the safe areafor guidance.\nAdapt based on changes in UITraitCollection.Write code to adjust your app\u2019s layout according to changes in elements of the iOS user interface, such as size class, display scale, and layout direction. ReadUITraitCollectionfor more information.\nAdapt based on changes in UITraitCollection.Write code to adjust your app\u2019s layout according to changes in elements of the iOS user interface, such as size class, display scale, and layout direction. ReadUITraitCollectionfor more information.\nTest specific scenarios before uploading your app\nThe following App Store features for iOS continue to work when your app runs in visionOS:\nIn-app purchases and subscriptions\nIn-app purchases and subscriptions\nApp capabilities and entitlements\nApp capabilities and entitlements\nOn-demand resources\nOn-demand resources\nApp thinning\nApp thinning\nWhen you use app thinning to optimize your app for different devices and operating systems, the App Store selects the resources and content that offer the best fit for visionOS devices. It then removes any other resources to create a streamlined installation of your app. When you export your app from Xcode 15 or later, you can test the thinning support using the visionOS virtual thinning target.\nSee Also\niOS migration and compatibility",
        "https://developer.apple.com/documentation/visionos/determining-whether-to-bring-your-app-to-visionos": "visionOS\nDetermining whether to bring your app to visionOS\nDetermining whether to bring your app to visionOS\nDetermining whether to bring your app to visionOS\nDetermining whether to bring your app to visionOS\nOverview\nIf you have an existing app that runs in iPadOS or iOS and you want to bring it to visionOS, you can choose to either run your compatible app as-is or create a visionOS-specific version.\nvisionOS supports most of the same technologies as iOS, so many apps built to run on iPad or iPhone can run unmodified on Apple Vision Pro. When a compatible app runs in visionOS, it retains the same appearance it has in iPadOS or iOS, and its content appears in a window in the person\u2019s surroundings. Apps built specifically for visionOS adopt the standard system appearance, look more natural on the platform, and support 3D content and immersive experiences.\nThe visionOS SDK has many differences from the iOS SDK. Frameworks and features might behave differently or be unavailable when your app runs in visionOS. Use this article to ensure your app behaves as you expect on every platform.\nDecide whether your app suits the platform\nIn some cases, you may decide your app is not well-suited to visionOS due to platform differences. For example, consider the following types of apps:\nApps that act as containers for app extensions.This includes apps where the primary purpose is to deliver custom keyboard extensions, device drivers, sticker packs, SMS and MMS message-filtering extensions, call directory extensions, or widgets.\nApps that act as containers for app extensions.This includes apps where the primary purpose is to deliver custom keyboard extensions, device drivers, sticker packs, SMS and MMS message-filtering extensions, call directory extensions, or widgets.\nNavigation-based apps.This includes apps that follow a person\u2019s location changes, such as apps that offer turn-by-turn directions or navigation.\nNavigation-based apps.This includes apps that follow a person\u2019s location changes, such as apps that offer turn-by-turn directions or navigation.\nSelfie or camera-based apps.This includes apps where the primary purpose is to capture images or video from the device\u2019s cameras. The device cameras are unavailable, but continuity camera and persona capture are available on Apple Vision Pro.\nSelfie or camera-based apps.This includes apps where the primary purpose is to capture images or video from the device\u2019s cameras. The device cameras are unavailable, but continuity camera and persona capture are available on Apple Vision Pro.\nOpt out of running on visionOS\nIf you don\u2019t want your app to run on Apple Vision Pro, change your app\u2019s availability in App Store Connect:\nSelect your app in App Store Connect.\nSelect your app in App Store Connect.\nNavigate to the Pricing and Availability information.\nNavigate to the Pricing and Availability information.\nDisable the \u201cMake this app available on Apple Vision Pro\u201d option.\nDisable the \u201cMake this app available on Apple Vision Pro\u201d option.\nWhen you remove your app\u2019s availability for Apple Vision Pro, the App Store stops making your iOS app available for visionOS. People who already downloaded your app on their Vision Pro can still run it in visionOS, but they can\u2019t download it again and won\u2019t receive any updates. This setting doesn\u2019t affect the version of your app built natively using the visionOS SDK.\nFor information on managing your app\u2019s availability for Apple Vision Pro, seeManage availability of iPhone and iPad apps on Apple Vision Pro.\nRun as a compatible app on visionOS\nvisionOS runs compatible iPad and iPhone apps by linking against the iOS SDK to provide continuous access to existing content right away. visionOS supports most of the same technologies as iOS, so many apps built to run on iPad or iPhone can run unmodified on Apple Vision Pro. ReadMaking your existing app compatible with visionOSto learn how to make your app run successfully as a compatible app in visionOS.\nCreate a visionOS version of your app\nApps built specifically for visionOS adopt the standard system appearance, and they look more natural on the platform. Creating a version of your app specifically for visionOS gives you the opportunity to add elements that work well on the platform, such as 3D content and immersive experiences. ReadBringing your existing apps to visionOSfor more information on how to modify your app to run successfully as a visionOS app and how to update your interface to take advantage of visionOS-specific elements.\nCheck framework availability in visionOS\nThe following frameworks are deprecated in their entirety in both iOS and visionOS. If your app still uses these frameworks, stop using them immediately. The reference documentation for each framework includes information about how to update your code.\nAccounts\nAccounts\nAddress Book\nAddress Book\nAddress Book UI\nAddress Book UI\nAssets Library\nAssets Library\nGLKit\nGLKit\niAd\niAd\nNewsstand Kit\nNewsstand Kit\nNotification Center\nNotification Center\nImportant\nvisionOS removed many deprecated symbols entirely, turning these deprecation warnings into missing-symbol errors on the platform.\nHere\u2019s a list of frameworks and features that behave differently in visionOS:\nActivityKit.Available on iOS only. Check theareActivitiesEnabledproperty ofActivityAuthorizationInfoto determine if Live Activities are authorized.\nActivityKit.Available on iOS only. Check theareActivitiesEnabledproperty ofActivityAuthorizationInfoto determine if Live Activities are authorized.\nAirPlay.visionOS hides AirPlay sharing buttons in system interfaces, and you can\u2019t use AirPlay features from compatible apps.\nAirPlay.visionOS hides AirPlay sharing buttons in system interfaces, and you can\u2019t use AirPlay features from compatible apps.\nApp extensions.visionOS doesn\u2019t load App Clips, device drivers, device activity monitors, keyboard extensions, Messages app extensions, photo-editing app extensions, SMS and call-reporting extensions, or widgets.\nApp extensions.visionOS doesn\u2019t load App Clips, device drivers, device activity monitors, keyboard extensions, Messages app extensions, photo-editing app extensions, SMS and call-reporting extensions, or widgets.\nApple Watch features.visionOS ignores watchOS apps and WatchKit extensions in your iOS or iPadOS app. Face sharing inClockKitdoes nothing in visionOS.\nApple Watch features.visionOS ignores watchOS apps and WatchKit extensions in your iOS or iPadOS app. Face sharing inClockKitdoes nothing in visionOS.\nARKit.This framework requires you to use different APIs for iOS and visionOS, as visionOS can\u2019t display windows that contain ARKit views. Check theisSupportedproperty of your configuration object to determine availability of augmented reality features. In visionOS, ARKit views such asARVieware never available, so isolate interface code containing those views to the iOS version of your app. For information about how to bring an ARKit app to visionOS, seeBringing your ARKit app to visionOS.\nARKit.This framework requires you to use different APIs for iOS and visionOS, as visionOS can\u2019t display windows that contain ARKit views. Check theisSupportedproperty of your configuration object to determine availability of augmented reality features. In visionOS, ARKit views such asARVieware never available, so isolate interface code containing those views to the iOS version of your app. For information about how to bring an ARKit app to visionOS, seeBringing your ARKit app to visionOS.\nAudio and video.visionOS doesn\u2019t support Picture in Picture or AV routing features. Check the availability of video features before using them. Be prepared for audio playback to stop automatically when your app moves to the background.\nAudio and video.visionOS doesn\u2019t support Picture in Picture or AV routing features. Check the availability of video features before using them. Be prepared for audio playback to stop automatically when your app moves to the background.\nAutomatic Assessment Configuration.Check for error values when you configure anAEAssessmentSessionobject. The framework returns an error if you try to start a test in visionOS.\nAutomatic Assessment Configuration.Check for error values when you configure anAEAssessmentSessionobject. The framework returns an error if you try to start a test in visionOS.\nAVFoundation.Identify what cameras are available using theAVCaptureDevice.DiscoverySessionclass. Don\u2019t assume the presence of specific cameras. Capture interfaces aren\u2019t available in visionOS. Use availability checks to determine which services are present.\nAVFoundation.Identify what cameras are available using theAVCaptureDevice.DiscoverySessionclass. Don\u2019t assume the presence of specific cameras. Capture interfaces aren\u2019t available in visionOS. Use availability checks to determine which services are present.\nCellular telephony and CallKit.You can still implement Voice-over-IP (VoIP) services usingCallKitandCore Telephony. Phone number verification, call-blocking, and other cellular-related services are unavailable.\nCellular telephony and CallKit.You can still implement Voice-over-IP (VoIP) services usingCallKitandCore Telephony. Phone number verification, call-blocking, and other cellular-related services are unavailable.\nContacts.Use theCNContactStoreclass to determine your app\u2019s authorization status.\nContacts.Use theCNContactStoreclass to determine your app\u2019s authorization status.\nCore Bluetooth.Use theCBCentralManagerandCBPeripheralManagerclasses to determine feature availability and your app\u2019s authorization status.\nCore Bluetooth.Use theCBCentralManagerandCBPeripheralManagerclasses to determine feature availability and your app\u2019s authorization status.\nCore Haptics.visionOS plays audio feedback instead of haptic feedback. Call thecapabilitiesForHardware()method of the haptic engine to determine the available features.\nCore Haptics.visionOS plays audio feedback instead of haptic feedback. Call thecapabilitiesForHardware()method of the haptic engine to determine the available features.\nCore Location.You can request location using the standard location service, but most other services are unavailable. Use availability checks to determine which services are present. The Always authorization level is unavailable and automatically becomes When in Use authorization. Check the properties ofCLLocationManagerto determine the availability of location services.\nCore Location.You can request location using the standard location service, but most other services are unavailable. Use availability checks to determine which services are present. The Always authorization level is unavailable and automatically becomes When in Use authorization. Check the properties ofCLLocationManagerto determine the availability of location services.\nCore Motion.Barometer data is unavailable, but most other sensors are available. Use availability checks to determine which sensors you can use. Check the properties ofCMMotionManagerto determine the availability of accelerometers, gyroscopes, magnetometers, and other hardware sensors.\nCore Motion.Barometer data is unavailable, but most other sensors are available. Use availability checks to determine which sensors you can use. Check the properties ofCMMotionManagerto determine the availability of accelerometers, gyroscopes, magnetometers, and other hardware sensors.\nCore NFC.Check thereadingAvailableproperty of your reader session to determine if NFC tag reading is available.\nCore NFC.Check thereadingAvailableproperty of your reader session to determine if NFC tag reading is available.\nDevice management.Calls to theManagedSettingsandManagedSettingsUIframeworks do nothing in visionOS.\nDevice management.Calls to theManagedSettingsandManagedSettingsUIframeworks do nothing in visionOS.\nEventKit.Use theEKEventStoreclass to determine your app\u2019s authorization status.\nEventKit.Use theEKEventStoreclass to determine your app\u2019s authorization status.\nExposure Notification.Use theENManagerclass to determine your app\u2019s authorization status.\nExposure Notification.Use theENManagerclass to determine your app\u2019s authorization status.\nGame controllers.visionOS delivers game controller events only when someone is looking at your app. To require a game controller as an input device, add theGCRequiresControllerUserInteractionkey with the visionOS value to your app\u2019sInfo.plist.\nGame controllers.visionOS delivers game controller events only when someone is looking at your app. To require a game controller as an input device, add theGCRequiresControllerUserInteractionkey with the visionOS value to your app\u2019sInfo.plist.\nHandoff.visionOS doesn\u2019t attempt to hand off user activities to other devices.\nHandoff.visionOS doesn\u2019t attempt to hand off user activities to other devices.\nHomeKit.You can\u2019t add accessories using a QR code from Apple Vision Pro. Check the properties ofHMHomeManagerto determine your app\u2019s authorization status.\nHomeKit.You can\u2019t add accessories using a QR code from Apple Vision Pro. Check the properties ofHMHomeManagerto determine your app\u2019s authorization status.\nLocal Authentication.Use theLAContextclass to determine the authentication policies you can use.\nLocal Authentication.Use theLAContextclass to determine the authentication policies you can use.\nMapKit.User-tracking features that involve heading information aren\u2019t available in visionOS.\nMapKit.User-tracking features that involve heading information aren\u2019t available in visionOS.\nMedia Player.Some APIs are unavailable in visionOS. Use theMPMediaLibraryclass to determine your app\u2019s authorization status.\nMedia Player.Some APIs are unavailable in visionOS. Use theMPMediaLibraryclass to determine your app\u2019s authorization status.\nMetrics.You can useMetricKitto gather on-device diagnostic logs and generate reports, but you can\u2019t gather metrics in visionOS.\nMetrics.You can useMetricKitto gather on-device diagnostic logs and generate reports, but you can\u2019t gather metrics in visionOS.\nMulti-Touch.The system reports a maximum of two simultaneous touch inputs \u2014 one for each of the person\u2019s hands. All system gesture recognizers handle these inputs appropriately, including for zoom and rotation gestures that require multiple fingers. If you have custom gesture recognizers that require more than two points of interaction, update them to support only one or two touches in visionOS.\nMulti-Touch.The system reports a maximum of two simultaneous touch inputs \u2014 one for each of the person\u2019s hands. All system gesture recognizers handle these inputs appropriately, including for zoom and rotation gestures that require multiple fingers. If you have custom gesture recognizers that require more than two points of interaction, update them to support only one or two touches in visionOS.\nMusicKit.Some APIs are unavailable in visionOS.\nMusicKit.Some APIs are unavailable in visionOS.\nNearby Interaction.The framework does nothing in visionOS. Check thedeviceCapabilitiesproperty of your session to determine whether features are available.\nNearby Interaction.The framework does nothing in visionOS. Check thedeviceCapabilitiesproperty of your session to determine whether features are available.\nParental controls.Calls to theFamilyControlsframework do nothing in visionOS.\nParental controls.Calls to theFamilyControlsframework do nothing in visionOS.\nPencilKit.visionOS doesn\u2019t report touches of typeUITouch.TouchType.pencil, but it does report other types of touches.\nPencilKit.visionOS doesn\u2019t report touches of typeUITouch.TouchType.pencil, but it does report other types of touches.\nPhotoKit.Use thePHPhotoLibraryclass to determine your app\u2019s authorization status.\nPhotoKit.Use thePHPhotoLibraryclass to determine your app\u2019s authorization status.\nProximityReader.Check theisSupportedproperty of the card reader object to determine if Tap to Pay on iPhone is available.\nProximityReader.Check theisSupportedproperty of the card reader object to determine if Tap to Pay on iPhone is available.\nPush to Talk.These services are unavailable in visionOS. Check for errors when creating aPTChannelManager.\nPush to Talk.These services are unavailable in visionOS. Check for errors when creating aPTChannelManager.\nReplayKit.Check theisAvailableproperty ofRPScreenRecorderto determine if screen recording support is available.\nReplayKit.Check theisAvailableproperty ofRPScreenRecorderto determine if screen recording support is available.\nRoomPlan.Check theisSupportedproperty of theRoomCaptureSessionobject to determine if LiDAR scanning is available on the device.\nRoomPlan.Check theisSupportedproperty of theRoomCaptureSessionobject to determine if LiDAR scanning is available on the device.\nSafari Services.A link that presents aSFSafariViewControllernow opens a new scene in the Safari app.\nSafari Services.A link that presents aSFSafariViewControllernow opens a new scene in the Safari app.\nScreen Time.Calls to theScreen Timeframework do nothing in visionOS.\nScreen Time.Calls to theScreen Timeframework do nothing in visionOS.\nSensor-related features.TheSensorKitframework is unavailable in the native visionOS SDK and calls to it do nothing when running a compatible app. Use theSRSensorReaderclass to determine your app\u2019s authorization status for compatible apps.\nSensor-related features.TheSensorKitframework is unavailable in the native visionOS SDK and calls to it do nothing when running a compatible app. Use theSRSensorReaderclass to determine your app\u2019s authorization status for compatible apps.\nSocial media.Calls to theSocialframework do nothing in visionOS.\nSocial media.Calls to theSocialframework do nothing in visionOS.\nSpeech.Use theSFSpeechRecognizerclass to determine if speech recognition is available.\nSpeech.Use theSFSpeechRecognizerclass to determine if speech recognition is available.\nSystem interfaces.Authorization prompts, Sign in with Apple prompts, and other system-provided interfaces run asynchronously outside of your app\u2019s process. Because these interfaces don\u2019t run modally in your app, your app might not receive immediate responses.\nSystem interfaces.Authorization prompts, Sign in with Apple prompts, and other system-provided interfaces run asynchronously outside of your app\u2019s process. Because these interfaces don\u2019t run modally in your app, your app might not receive immediate responses.\nUser Notifications.Use thegetNotificationSettings(completionHandler:)method ofUNUserNotificationCenterto determine your app\u2019s authorization status.\nUser Notifications.Use thegetNotificationSettings(completionHandler:)method ofUNUserNotificationCenterto determine your app\u2019s authorization status.\nVehicle features.The system doesn\u2019t call your app\u2019sCarPlaycode. Calls you make usingCarKeydo nothing in visionOS.\nVehicle features.The system doesn\u2019t call your app\u2019sCarPlaycode. Calls you make usingCarKeydo nothing in visionOS.\nVisionKit.TheDataScannerViewControllerAPIs are unavailable, but other features are still available. Data scanners do nothing inVisionKitin visionOS.\nVisionKit.TheDataScannerViewControllerAPIs are unavailable, but other features are still available. Data scanners do nothing inVisionKitin visionOS.\nWatch Connectivity.The framework supports connections only between an iPhone and Apple Watch. Call theisSupported()method of theWCSessionobject to determine if the framework is available.\nWatch Connectivity.The framework supports connections only between an iPhone and Apple Watch. Call theisSupported()method of theWCSessionobject to determine if the framework is available.\nNote\nReviewBuilding spatial experiences for business apps with enterprise APIs for visionOSfor information on enterprise APIs and how to request the entitlements.\nSee Also\niOS migration and compatibility",
        "https://developer.apple.com/documentation/visionos/presenting-windows-and-spaces": "visionOS\nPresenting windows and spaces\nPresenting windows and spaces\nPresenting windows and spaces\nPresenting windows and spaces\nOverview\nAn app\u2019s scenes, which contain views that people interact with, can take different forms. For example, a scene can fill a window, a tab in a window, or an entire screen. Some scenes can even place views throughout a person\u2019s surroundings. How a scene appears depends on its type, the platform, and the context.\nWhen someone launches your app, SwiftUI looks for the firstWindowGroup,Window, orDocumentGroupin your app declaration and opens a scene of that type, typically filling a new window or the entire screen, depending on the platform. For example, the following app running in macOS presents a window that contains aMailViewerview:\nIn visionOS, you can alternatively configure your app to open the firstImmersiveSpacethat the app declares. In any case, specific platforms and configurations enable you to open more than one scene at a time. Under those conditions, you can use actions that appear in the environment to programmatically open and close the scenes in your app.\nCheck for multiple-scene support\nIf you share code among different platforms and need to find out at runtime whether the current system supports displaying multiple scenes, read thesupportsMultipleWindowsenvironment value. The following code creates a button that\u2019s hidden unless the app supports multiple windows:\nThe value that you read depends on both the platform and how you configure your app:\nIn macOS, this property returnstruefor any app that uses the SwiftUI app lifecycle.\nIn macOS, this property returnstruefor any app that uses the SwiftUI app lifecycle.\nIn iPadOS and visionOS, this property returnstruefor any app that uses the SwiftUI app lifecycle and has the Information Property List keyUIApplicationSupportsMultipleScenesset totrue, andfalseotherwise.\nIn iPadOS and visionOS, this property returnstruefor any app that uses the SwiftUI app lifecycle and has the Information Property List keyUIApplicationSupportsMultipleScenesset totrue, andfalseotherwise.\nFor all other platforms and configurations, the value returnsfalse.\nFor all other platforms and configurations, the value returnsfalse.\nIf your app only ever runs in one of these situations, you can assume the associated behavior and don\u2019t need to check the value.\nEnable multiple simultaneous scenes\nYou can always present multiple scenes in macOS. To enable an iPadOS or visionOS app to simultaneously display multiple scenes \u2014 includingImmersiveSpacescenes in visionOS \u2014 add theUIApplicationSupportsMultipleSceneskey with a value oftruein theUIApplicationSceneManifestdictionary of your app\u2019s Information Property List. Use the Info tab in Xcode for your app\u2019s target to add this key:\n\nApps on other platforms can display only one scene during their lifetime.\nOpen windows programmatically\nSome platforms provide built-in controls that enable people to open instances of the window-style scenes that your app defines. For example, in macOS people can choose File > New Window from the menu bar to open a new window. SwiftUI also provides ways for you to open new windows programmatically.\nTo do this, get theopenWindowaction from the environment and call it with an identifier, a value, or both to indicate what kind of window to open and optionally what data to open it with. The following view opens a new instance of the previously defined mail viewer window when someone clicks or taps the button:\nWhen the action runs on a system that supports multiple scenes, SwiftUI looks for a window in the app declaration that has a matching identifier and creates a new scene of that type.\nImportant\nIfsupportsMultipleWindowsisfalseand you try to open a new window, SwiftUI ignores the action and logs a runtime error.\nIn addition to opening more instances of an app\u2019s main window, as in the above example, you can also open other window types that your app\u2019s body declares. For example, you can open an instance of theWindowthat displays connectivity information:\nOpen a space programmatically\nIn visionOS, you open an immersive space \u2014 a scene that you can use to present unbounded content in a person\u2019s surroundings \u2014 in much the same way that you open a window, except that you use theopenImmersiveSpaceaction. The action runs asynchronously, so you use theawaitkeyword when you call it, and typically do so from inside aTask:\nBecause your app operates in a Full Space when you open anImmersiveSpacescene, you can only open one scene of this type at a time. If you try to open a space when one is already open, the system logs a runtime error.\nYour app can display any number of windows together with an immersive space. However, when you open a space from your app, the system hides all windows that belong to other apps. After you dismiss your space, the other apps\u2019 windows reappear. Similarly, the system hides your app\u2019s windows if another app opens an immersive space.\nDesignate a space as your app\u2019s main interface\nWhen visionOS launches an app, it opens the first window group, window, or document scene that the app\u2019s body declares, just like on other platforms. This is true even if you first declare a space. However, if you want to open your app into an immersive space directly, specify a space as the default scene for your app by adding theUIApplicationPreferredDefaultSceneSessionRolekey to your app\u2019s information property list and setting its value toUISceneSessionRoleImmersiveSpaceApplication. In that case, visionOS opens the first space that it finds in your app declaration.\nImportant\nBe careful not to overwhelm people when starting your app with an immersive space. For design guidance, seeImmersive experiences.\nClose windows programmatically\nPeople can close windows using system controls, like the close button built into the frame around a macOS window. You can also close windows programmatically. Get thedismissWindowaction from the environment, and call it using the identifier of the window that you want to dismiss:\nIn iPadOS and visionOS, the system ignores the dismiss action if you use it to close a window that\u2019s your app\u2019s only open scene.\nClose spaces programmatically\nTo close a space, call thedismissImmersiveSpaceaction. Like the corresponding open space action, the close action operates asynchronously and requires theawaitkeyword:\nYou don\u2019t need to specify an identifier for this action, because there can only ever be one space open at a time. Like with windows, you can\u2019t dismiss a space that\u2019s your app\u2019s only open scene.\nTransition between a window and a space\nBecause you can\u2019t programmatically close the last open window or immersive space in a visionOS app, be sure to open a new scene before closing the old one. Pay particular attention to the sequencing when moving between a window and an immersive space, because the space\u2019s open and dismiss actions run asynchronously.\nFor example, consider a chess game that begins by displaying a start button in a window. When someone taps the button, the app dismisses the window and opens an immersive space that presents a chess board. The following button demonstrates proper sequencing by opening the space and then closing the window:\nIn the above code, it\u2019s important to include thedismissWindowaction inside the task, so that it waits until theopenImmersiveSpaceaction completes. If you put the action outside the task \u2014 either before or after \u2014 it might execute before the asynchronous open action completes, when the window is still the only open scene. In that case, the system opens the space but doesn\u2019t close the window.\nSee Also\nSwiftUI",
        "https://developer.apple.com/documentation/visionos#Design": "visionOS\nOverview\nvisionOS is the operating system that powers Apple Vision Pro. Use visionOS together with familiar tools and technologies to build immersive apps and games for spatial computing.\n\nDeveloping for visionOS requires a Mac with Apple silicon. Create new apps using SwiftUI to take full advantage of the spectrum of immersion available in visionOS. If you have an existing iPad or iPhone app, add the visionOS destination to your app\u2019s target to gain access to the standard system appearance, and add platform-specific features to create a compelling experience. To provide continuous access to your content in the meantime, deliver a compatible version of your app that runs in visionOS.\nExpand your app into immersive spaces\nStart with a familiar window-based experience to introduce people to your content. From there, addSwiftUIscene types specific to visionOS, such as volumes and spaces. These scene types let you incorporate depth, 3D objects, and immersive experiences.\nBuild your app\u2019s 3D content withRealityKitand Reality Composer Pro, and display it with aRealityView. In an immersive experience, useARKitto integrate your content with the person\u2019s surroundings.\n\nExplore new kinds of interaction\nPeople can select an element by looking at it and tapping their fingers together. They can also pinch, drag, zoom, and rotate objects using specific hand gestures.SwiftUIprovides built-in support for these standard gestures, so rely on them for most of your app\u2019s input. When you want to go beyond the standard gestures, useARKitto create custom gestures.\nTap to select\nPinch to rotate\nManipulate objects\nCreate custom gestures\nDive into featured sample apps\nExplore the core concepts for all visionOS apps with Hello World. Understand how to detect custom gestures using ARKit with Happy Beam. Discover streaming 2D and stereoscopic media with Destination Video. And learn how to build 3D scenes with RealityKit and Reality Composer Pro with Diorama and Swift Splash.\nTopics\nApp construction\nDesign\nSwiftUI\nRealityKit and Reality Composer Pro\nARKit\nVideo playback\nXcode and Simulator\nPerformance\niOS migration and compatibility\nEnterprise APIs for visionOS\nvisionOS\nOverview\nExpand your app into immersive spaces\nExplore new kinds of interaction\nDive into featured sample apps\nTopics",
        "https://developer.apple.com/documentation/visionos/tracking-images-in-3d-space": "visionOS\nTracking preregistered images in 3D space\nTracking preregistered images in 3D space\nTracking preregistered images in 3D space\nTracking preregistered images in 3D space\nOverview\nUse ARKit\u2019s support for tracking 2D images to place 3D content in a space. ARKit provides updates to the image\u2019s location as it moves relative to the person. If you supply one or more reference images in your app\u2019s asset catalog, people can use a real-world copy of that image to place virtual 3D content in your app. For example, if you design a pack of custom playing cards and provide those assets to people in the form of a real-world deck of playing cards, they can place unique content per card in a fully immersive experience.\nThe following example tracks a set of images loaded from an app\u2019s asset catalog:\nIf you know the real-world dimensions of the images you\u2019re tracking, use thephysicalSizeproperty to improve tracking accuracy. TheestimatedScaleFactorproperty provides information about how the scale of the tracked image differs from the expected physical size you provide.\nSee Also\nARKit",
        "https://developer.apple.com/documentation/visionos#App-construction": "visionOS\nOverview\nvisionOS is the operating system that powers Apple Vision Pro. Use visionOS together with familiar tools and technologies to build immersive apps and games for spatial computing.\n\nDeveloping for visionOS requires a Mac with Apple silicon. Create new apps using SwiftUI to take full advantage of the spectrum of immersion available in visionOS. If you have an existing iPad or iPhone app, add the visionOS destination to your app\u2019s target to gain access to the standard system appearance, and add platform-specific features to create a compelling experience. To provide continuous access to your content in the meantime, deliver a compatible version of your app that runs in visionOS.\nExpand your app into immersive spaces\nStart with a familiar window-based experience to introduce people to your content. From there, addSwiftUIscene types specific to visionOS, such as volumes and spaces. These scene types let you incorporate depth, 3D objects, and immersive experiences.\nBuild your app\u2019s 3D content withRealityKitand Reality Composer Pro, and display it with aRealityView. In an immersive experience, useARKitto integrate your content with the person\u2019s surroundings.\n\nExplore new kinds of interaction\nPeople can select an element by looking at it and tapping their fingers together. They can also pinch, drag, zoom, and rotate objects using specific hand gestures.SwiftUIprovides built-in support for these standard gestures, so rely on them for most of your app\u2019s input. When you want to go beyond the standard gestures, useARKitto create custom gestures.\nTap to select\nPinch to rotate\nManipulate objects\nCreate custom gestures\nDive into featured sample apps\nExplore the core concepts for all visionOS apps with Hello World. Understand how to detect custom gestures using ARKit with Happy Beam. Discover streaming 2D and stereoscopic media with Destination Video. And learn how to build 3D scenes with RealityKit and Reality Composer Pro with Diorama and Swift Splash.\nTopics\nApp construction\nDesign\nSwiftUI\nRealityKit and Reality Composer Pro\nARKit\nVideo playback\nXcode and Simulator\nPerformance\niOS migration and compatibility\nEnterprise APIs for visionOS\nvisionOS\nOverview\nExpand your app into immersive spaces\nExplore new kinds of interaction\nDive into featured sample apps\nTopics",
        "https://developer.apple.com/documentation/visionos/capturing-screenshots-and-video-from-your-apple-vision-pro-for-2d-viewing": "visionOS\nCapturing screenshots and video from Apple Vision Pro for 2D viewing\nCapturing screenshots and video from Apple Vision Pro for 2D viewing\nCapturing screenshots and video from Apple Vision Pro for 2D viewing\nCapturing screenshots and video from Apple Vision Pro for 2D viewing\nOverview\nUse screenshots and short videos of your visionOS app to showcase your user interface, highlight functionality, and demonstrate usage. Help people understand what to expect from an immersive experience by recording content from Apple Vision Pro that includes your app and its surroundings.\nThe system renders content with spatial effects and optimizations for viewing during immersive experiences. Techniques that improve rendering performance during normal operation \u2014 such asfoveated rendering, which reduces image quality in the peripheral \u2014 don\u2019t translate well to 2D displays. To produce high-resolution content for people to view on 2D displays, the system needs to render without these effects and drop some optimizations. Use Developer Capture in Reality Composer Pro to notify the system to reconfigure rendering, and capture screenshots or high-resolution video, including sound, for up to 60 seconds from Apple Vision Pro.\nNote\nFor guidance on the screenshots and previews you include in your app\u2019s product page, seeSubmit your apps to the App Store for Apple Vision Pro.\nPair your Apple Vision Pro to Xcode\nBefore capturing screenshots and video from your device, pair it with a Mac that has Xcode and the visionOS SDK installed. For instructions on pairing your device, seeRunning your app in Simulator or on a device.\nPrepare to capture your app and its surroundings\nSelect a well-lit location that\u2019s free from clutter. Avoid including objects that might distract the audience or get in the way of your app\u2018s windows and 3D content. Include enough detail in the scene to provide context and anchoring points. Avoid material that you don\u2019t have permission to capture, including people, screens, branded products, logos, artwork, and other intellectual property.\nUse the version of your app that you intend to share with your audience. Build and install your app using a release configuration. This configuration enables code optimizations for better runtime performance and disables the generation of debugging information. Debug configurations typically disable code optimizations and might include UI you don\u02bct intend to share. Don\u2019t use them to record video for previews you intend to share. Build schemes manage the build configuration Xcode uses during build actions, for more information seeCustomizing the build schemes for a project.\nPlan the tasks you intend to capture ahead of time and keep them short and focused. Launch your app and go to the state where you plan to begin the capture. Reduce unnecessary processing overhead on Apple Vision Pro by quitting other apps and avoiding background tasks.\nTo capture screenshots or video from a device, select your device from the capture dialog in Reality Composer Pro:\nLaunch Reality Composer Pro. Choose Open Developer Tool > Reality Composer Pro from the Xcode menu.\nLaunch Reality Composer Pro. Choose Open Developer Tool > Reality Composer Pro from the Xcode menu.\nChoose File > Developer Capture to bring up the Developer Capture dialog.\nChoose File > Developer Capture to bring up the Developer Capture dialog.\nSelect the device to capture from the pop-up menu.\nSelect the device to capture from the pop-up menu.\n\nIf you see the message \u201cPreparing, wait for the device to be ready\u201d. You can click the info button that appears to the right of the pop-up menu for more information.\nCapture screenshots\nTo begin capturing screenshots from Apple Vision Pro, click the button with the still camera icon in the capture dialog. The system begins your capture session:\n\nTo capture a screenshot immediately, without a countdown, press the spacebar. Click the countdown button to capture a screenshot after a 3 second countdown. Continue to keep relevant content centered and in frame for screenshots. The aspect ratio of screenshots crops content that appears at the sides of an experience.\nThe status area of the capture dialog displays the time remaining before the system ends the capture session. Click the stop button from your Mac to end the capture session yourself.\nCapture video\nTo begin capturing video from the device, click the video camera button in the Developer Capture dialog. This begins a countdown. When the countdown reaches 0, the capture session begins. As the capture process happens, the video changes because the system reconfigures to render content for viewing in 2D. You might notice reduced responsiveness from the device during the session as it devotes more processing to render and capture the video.\nWhile recording on the device, perform your planned interactions. Keep relevant content centered and in frame. The aspect ratio of the video you capture crops content that appears at the sides of an experience. Keep your head stable, and use slow, steady movement to transition the focus of the device when necessary. When viewing the video you capture in 2D, small head movements appear amplified and might be jarring to the audience.\nThe capture session ends when the elapsed time exceeds 60 seconds. You can click the record button again from your Mac to end the session sooner.\nNote\nTo begin a capture, the device must have a stable connection to your Mac and start at low power and thermal levels to stay below thresholds necessary to achieve consistent frame rates. When capturing multiple sessions, you might need to wait between each session.\nReview the captured video file\nEach recording session creates a QuickTime Movie file (.mov) and saves it to the desktop of your Mac. The file includes video captured at 30 FPS using 10-bit HEVC in HDTV Rec. 709 color space with system audio recorded in 32-bit floating-point linear PCM.\nReview the video to make sure that it includes all the content you planned and it doesn\u2019t include any unexpected elements. Ensure that the transitions and animations are smooth and frame rates are consistent.\nUse additional video-editing tools to trim, edit, and apply post-processing, such as stabilization, to the video to create a high-quality preview.\nSee Also\nRealityKit and Reality Composer Pro",
        "https://developer.apple.com/documentation/visionos#Expand-your-app-into-immersive-spaces": "visionOS\nOverview\nvisionOS is the operating system that powers Apple Vision Pro. Use visionOS together with familiar tools and technologies to build immersive apps and games for spatial computing.\n\nDeveloping for visionOS requires a Mac with Apple silicon. Create new apps using SwiftUI to take full advantage of the spectrum of immersion available in visionOS. If you have an existing iPad or iPhone app, add the visionOS destination to your app\u2019s target to gain access to the standard system appearance, and add platform-specific features to create a compelling experience. To provide continuous access to your content in the meantime, deliver a compatible version of your app that runs in visionOS.\nExpand your app into immersive spaces\nStart with a familiar window-based experience to introduce people to your content. From there, addSwiftUIscene types specific to visionOS, such as volumes and spaces. These scene types let you incorporate depth, 3D objects, and immersive experiences.\nBuild your app\u2019s 3D content withRealityKitand Reality Composer Pro, and display it with aRealityView. In an immersive experience, useARKitto integrate your content with the person\u2019s surroundings.\n\nExplore new kinds of interaction\nPeople can select an element by looking at it and tapping their fingers together. They can also pinch, drag, zoom, and rotate objects using specific hand gestures.SwiftUIprovides built-in support for these standard gestures, so rely on them for most of your app\u2019s input. When you want to go beyond the standard gestures, useARKitto create custom gestures.\nTap to select\nPinch to rotate\nManipulate objects\nCreate custom gestures\nDive into featured sample apps\nExplore the core concepts for all visionOS apps with Hello World. Understand how to detect custom gestures using ARKit with Happy Beam. Discover streaming 2D and stereoscopic media with Destination Video. And learn how to build 3D scenes with RealityKit and Reality Composer Pro with Diorama and Swift Splash.\nTopics\nApp construction\nDesign\nSwiftUI\nRealityKit and Reality Composer Pro\nARKit\nVideo playback\nXcode and Simulator\nPerformance\niOS migration and compatibility\nEnterprise APIs for visionOS\nvisionOS\nOverview\nExpand your app into immersive spaces\nExplore new kinds of interaction\nDive into featured sample apps\nTopics",
        "https://developer.apple.com/documentation/visionos/creating-your-first-visionos-app": "visionOS\nCreating your first visionOS app\nCreating your first visionOS app\nCreating your first visionOS app\nCreating your first visionOS app\nOverview\nIf you\u2019re new to visionOS, start with a new Xcode project to learn about the platform features, and to familiarize yourself with visionOS content and techniques. When you build an app for visionOS, SwiftUI is an excellent choice because it gives you full access to visionOS features. Although you can also use UIKit to build portions of your app, you need to use SwiftUI for many features that are unique to the platform.\nNote\nDeveloping for visionOS requires a Mac with Apple silicon.\nIn any SwiftUI app, you place content onscreen using scenes. A scene contains the views and controls to display onscreen. Scenes also define the appearance of those views and controls when they appear onscreen. In visionOS, you can include both 2D and 3D views in the same scene, and you can present those views in a window or as part of the person\u2019s surroundings.\nScene with a window\nScene with a window and 3D objects\nStart with a new Xcode project and add features to familiarize yourself with visionOS content and techniques. Run your app in Simulator to verify your content looks like you expect, and run it on device to see your 3D content come to life.\nOrganize your content around one or more scenes, which manage your app\u2019s interface. Each scene contains the views and controls you want to display, and the scene type determines whether your content adopts a 2D or 3D appearance. SwiftUI adds 3D scene types specifically for visionOS, and also adds 3D elements and layout options for all scene types.\nCreate your Xcode project\nCreate a new project in Xcode by choosing File > New > Project. Navigate to the visionOS section of the template chooser, and choose the App template. When prompted, specify a name for your project along with other options.\nWhen creating a new visionOS app, you can configure your app\u2019s initial scene types from the configuration dialog. To display primarily 2D content in your initial scene, choose a Window as your initial scene type. For primarily 3D content, choose a Volume. You can also add an immersive scene to place your content in the person\u2019s surroundings.\n\nInclude a Reality Composer Pro project file when you want to create 3D assets or scenes to display from your app. Use this project file to build content from primitive shapes and existing USDZ assets. You can also use it to build and test custom RealityKit animations and behaviors for your content.\nModify the existing window\nBuild your initial interface using standard SwiftUI views. Views provide the basic content for your interface, and you customize the appearance and behavior of them using SwiftUI modifiers. For example, the.backgroundmodifier adds a partially transparent tint color behind your content:\nTo learn more about how to create and configure interfaces using SwiftUI, seeSwiftUI Essentials.\nHandle events in your views\nMany SwiftUI views handle interactions automatically \u2014 all you do is provide code to run when the interactions occur. You can also add SwiftUI gesture recognizers to a view to handle tap, long-press, drag, rotate, and zoom gestures. The system automatically maps the following types of input to your SwiftUI event-handling code:\n\nIndirect input. The person\u2019s eyes indicate the target of an interaction. To start the interaction, the person touches their thumb and forefinger together on one or both hands. Additional finger and hand movements define the gesture type.\n\nDirect input. When a person\u2019s finger occupies the same space as an onscreen item, the system reports an interaction. Additional finger and hand movements define the gesture type.\n\nKeyboard input. People can use a connected mouse, trackpad, or keyboard to interact with items, trigger menu commands, and perform gestures.\nFor more information about handling interactions in SwiftUI views, seeHandling User Inputin theSwiftUI Essentialstutorial.\nBuild and run your app\nBuild and run your app in Simulator to see how it looks. Simulator for visionOS has a virtual background as the backdrop for your app\u2019s content. Use your keyboard and your mouse or trackpad to navigate around the environment and interact with your app.\nTap and drag the window bar below your app\u2019s content to reposition the window in the environment. Move the pointer over the circle next to the window bar to reveal the window\u2019s close button. Move the cursor to one of the window\u2019s corners to turn the window bar into a resizing control.\nNote\nApps don\u2019t control the placement of windows in the space. The system places each window in its initial position, and updates that position based on further interactions with the app.\nFor additional information about how to interact with your app in Simulator, seeInteracting with your app in the visionOS simulator.\nSee Also\nApp construction",
        "https://developer.apple.com/documentation/visionos#ARKit": "visionOS\nOverview\nvisionOS is the operating system that powers Apple Vision Pro. Use visionOS together with familiar tools and technologies to build immersive apps and games for spatial computing.\n\nDeveloping for visionOS requires a Mac with Apple silicon. Create new apps using SwiftUI to take full advantage of the spectrum of immersion available in visionOS. If you have an existing iPad or iPhone app, add the visionOS destination to your app\u2019s target to gain access to the standard system appearance, and add platform-specific features to create a compelling experience. To provide continuous access to your content in the meantime, deliver a compatible version of your app that runs in visionOS.\nExpand your app into immersive spaces\nStart with a familiar window-based experience to introduce people to your content. From there, addSwiftUIscene types specific to visionOS, such as volumes and spaces. These scene types let you incorporate depth, 3D objects, and immersive experiences.\nBuild your app\u2019s 3D content withRealityKitand Reality Composer Pro, and display it with aRealityView. In an immersive experience, useARKitto integrate your content with the person\u2019s surroundings.\n\nExplore new kinds of interaction\nPeople can select an element by looking at it and tapping their fingers together. They can also pinch, drag, zoom, and rotate objects using specific hand gestures.SwiftUIprovides built-in support for these standard gestures, so rely on them for most of your app\u2019s input. When you want to go beyond the standard gestures, useARKitto create custom gestures.\nTap to select\nPinch to rotate\nManipulate objects\nCreate custom gestures\nDive into featured sample apps\nExplore the core concepts for all visionOS apps with Hello World. Understand how to detect custom gestures using ARKit with Happy Beam. Discover streaming 2D and stereoscopic media with Destination Video. And learn how to build 3D scenes with RealityKit and Reality Composer Pro with Diorama and Swift Splash.\nTopics\nApp construction\nDesign\nSwiftUI\nRealityKit and Reality Composer Pro\nARKit\nVideo playback\nXcode and Simulator\nPerformance\niOS migration and compatibility\nEnterprise APIs for visionOS\nvisionOS\nOverview\nExpand your app into immersive spaces\nExplore new kinds of interaction\nDive into featured sample apps\nTopics",
        "https://developer.apple.com/documentation/visionos/creating-a-performance-plan-for-visionos-app": "visionOS\nCreating a performance plan for your visionOS app\nCreating a performance plan for your visionOS app\nCreating a performance plan for your visionOS app\nCreating a performance plan for your visionOS app\nOverview\nPerformance tuning is an important part of the development process, regardless of platform. Performance tuning means making your app run as efficiently as possible, so it does more work in less time and with fewer system resources. Efficiency is especially important on devices that can support multiple apps in an immersive experience. Apps that consume too many resources, can push the device beyond thermal limits. When this occurs, the system takes steps to cool down to a more acceptable level. This can have a noticeable visual impact and be disorienting for the wearer.\nAs you start development, set aggressive goals and evaluate progress throughout the development cycle. Automate the collection of performance metrics as much as possible and look at data over time to see if performance is improving or declining. When you detect a significant decrease in performance, take immediate steps to correct it. When you start fine-tuning early in development, you have more time to make needed changes to algorithms and approaches.\nFor more information on performance tuning, seeImproving your app\u2019s performance.\nSet performance and power targets\nPerformance isn\u2019t a single metric that you measure and improve. Typically, you choose several metrics and set goals for each of them. For example, consider:\nMake sure your app launches quickly; this is your first chance to make a good impression.\nYour interface needs to respond quickly to interactions, even while doing other work. Minimize the time it takes to start tasks. For example, make sure audio and video start without noticeable delays.\nFor an immersive experience with realtime rendering, it\u2019s important to maintain consistently high frame rates. Help maintain these rates by avoiding unnecessary changes that result in more frequent updates to the shared render server. Measure things like update rates, stalls, and hangs in both the render server and your app. Only render the content you need, and optimize the textures and other resources you use during drawing.\nWhen the device begins to reach thermal limits, the system reduces CPU or GPU usage and performance degrades over time. Avoid this thermal ceiling by prioritizing and spreading out work, limiting the number of simultaneous threads your app maintains, and turning off hardware-related features likeCore Locationwhen you don\u2019t need them.\nMake the app do as much as possible using the smallest amount of hardware resources. Minimize task-based overhead.\nUse as little free memory as possible. Don\u2019t allocate or deallocate memory during critical operations, which might make your app appear slow.\nAfter you choose the metrics you want, set realistic goals and prioritize them, so you know which ones matter the most. Performance tuning often involves making tradeoffs between competing goals. For example, if you reduce CPU usage by caching computed data or pre-load assets to improve responsiveness, you increase your app\u2019s memory usage. Make these kinds of tradeoffs carefully, and always measure the results of any changes to learn whether they were successful. In some cases, you might find the sacrifice isn\u2019t worthwhile.\nConsider how people will use your app. If your app runs in the Shared Space, consider more conservative targets and goals for system resources. If you expect people to use your app for longer periods of time, factor this extended use into your targets and goals when choosing metrics.\nIdentify the code flows and user scenarios to test\nAfter you choose the metrics to collect, decide which portions of your app to test. Choose features that are repeatable, measurable, and reliable to test. Repeatable automated tests allow you to compare the results and know the comparisons represent the exact same task. Focus on places where your app executes code, but don\u2019t ignore places where your app hands off data to the system and waits. If your app spends a significant amount of time waiting for information, consider eliminating the requests altogether or batching them to achieve better performance.\nFocus your tuning efforts on the parts of your app that people use the most, or that have the most impact on overall system performance, including:\nUser-facing workflows\nUser-facing workflows\nKey algorithms\nKey algorithms\nTask that allocate or deallocate memory\nTask that allocate or deallocate memory\nBackground and network-based tasks\nBackground and network-based tasks\nCustom Metal shaders\nCustom Metal shaders\nChoose actions that people perform frequently or that correspond to important features. For example, if your app lets someone add a new contact, test the workflow for creating the contact, editing the contact, and saving the results. Test your app with a particular feature enabled and disabled to determine whether the feature is solely responsible for any performance impacts. Choose lightweight workflows such as how your app performs at idle time, and also heavyweight workflows, for example, ones that involve user interactions and your app\u2019s responses. For launch times, gather metrics for both hot and cold launches \u2014 that is, when the app is already resident in memory and when it is not.\nConsider thermal and environmental factors\nConsider how environmental factors impact your app. The characteristics of your physical environment can affect system load and thermals of the device. Consider the effect that ambient room temperature, the presence of other people, and the number and type of real-world objects can have on the your app\u2018s algorithms. Try to test in different settings to get an idea of whether you need to optimize for these scenarios or not.\nUse Xcode\u2019s thermal inducers to mimic the device hitting its thermal limits and consider how your app responds to fair, serious, and critical thermal notifications. You might need to have different performance goals when under thermal pressure, and prioritize optimizing for power or find ways to dynamically lower your app\u2018s complexity in response to thermal pressure to give a smoother experience, even if latency is a bit higher.\nChoose tools to collect performance data\nThere are many tools and APIs you can use to collect performance-related data for your visionOS app. Use a variety of tools to make sure you have the data you need:\nMonitor the CPU, memory, disk and network gauges in the Debug navigator to track system resources utilization.\nProfile your app to gather performance data on most metrics. Instruments lets you profile your app\u2019s code execution, find memory leaks, track memory allocations, analyze file-system or graphics performance, SwiftUI performance, and much more. Use the RealityKit Trace template to monitoring and investigate render server stalls and bottlenecks on visionOS.\nUseXCTestAPIs to collect performance data.\nUseMetricKitto gather on-device app diagnostics and generate reports.\nReview diagnostic logs for hangs, disk and energy usage, and crashes in the Xcode Organizer.\nReview statistics on the contents of your RealityKit scenes. Use this information to optimize your 3D models and textures.\nAdd signposts to your code to generate timing information you can view in Instruments. For more information, seeRecording performance data.\nInclude log messages to report significant events and relevant data for those events. For more information, seeGenerating log messages from your code.\nGet feedback from testers about their experiences with beta versions of your app. Fill out the Test Information page for your beta version, and request that testers provide feedback about the performance of your app.\nProfile on a physical device\nIn general, profile and analyze performance on a physical device rather than in Simulator. Even if something works well in Simulator, it might not perform as well on devices for all use cases. Simulator doesn\u2019t support some hardware features and APIs. There are differences in the rendering pipeline for Simulator running on macOS, so rendering performance characteristics will be different. Other pipelines such as input delivery and audio or video playback are also different. There are, however, some insights you can gain profiling in Simulator, such as CPU stalls, that help you spot areas to investigate and address.\nBuild automated test cases and run them regularly\nXcode comes with tools to help you automate the collection of performance data:\nUse theXCTestframework to build test cases to collect performance metrics. XCTest lets you gather several different metrics, including the time it takes to perform operations, the amount of CPU activity that occurs during the test, details about memory or storage use, and more.\nUse theXCTestframework to build test cases to collect performance metrics. XCTest lets you gather several different metrics, including the time it takes to perform operations, the amount of CPU activity that occurs during the test, details about memory or storage use, and more.\nUse Instruments to collect metrics for specific interactions with your app. Record those interactions and play them back later to collect a new set of metrics.\nUse Instruments to collect metrics for specific interactions with your app. Record those interactions and play them back later to collect a new set of metrics.\nWrite custom scripts to gather performance-related data using system command-line tools. Integrate these scripts into your project\u2019s build process to automate their execution.\nWrite custom scripts to gather performance-related data using system command-line tools. Integrate these scripts into your project\u2019s build process to automate their execution.\nConfigure Xcode to run test cases each time you build your app, or create a separate target to run test cases or custom scripts on demand. Integrate your performance tests into your Xcode Cloud workflows, or your own custom continuous integration solution.\nNote\nCollect performance data using a production version of your app to obtain more accurate results. Debug builds contain additional code to support debugging operations and logging. You can collect data from debug builds too, but keep those metrics separate from production-build metrics.\nFor information about how to write test cases for your app, seeTesting. For information about how to automate testing with Xcode Cloud, seeXcode Cloud.\nSee Also\nPerformance",
        "https://developer.apple.com/documentation/visionos/building-spatial-experiences-for-business-apps-with-enterprise-apis": "visionOS\nBuilding spatial experiences for business apps with enterprise APIs for visionOS\nBuilding spatial experiences for business apps with enterprise APIs for visionOS\nBuilding spatial experiences for business apps with enterprise APIs for visionOS\nBuilding spatial experiences for business apps with enterprise APIs for visionOS\nOverview\nNote\nThis article is associated with WWDC24 session 10139:Introducing enterprise APIs for visionOS.\nYou can use the entitlements that enterprise APIs for visionOS offer to create even more powerful enterprise solutions and spatial experiences for your visionOS app. The enterprise APIs for visionOS consist of two distinct categories.\nThe first category of APIs provides enhanced sensor access and improves the visual capabilities of Apple Vision Pro, including access to the main camera, improved capture and streaming, and enhanced functionality through the camera that allows you to see what the wearer sees.\nCapture input data from the forward-facing main camera.\nAccess a composite feed of what an Apple Vision Pro wearer is seeing (physical world and digital content).\nScan barcodes and QR codes with the ability to decode contents and locate spatial positions.\nThe second category focuses on platform control to help you get the most out of visionOS. These entitlements provide advanced machine learning (ML) capabilities using the Apple Neural Engine for your custom ML model, enhanced object-tracking capabilities for faster object detection, and the ability to tune the performance of your apps to achieve even more compute functionality for intensive workloads.\nSpecifically target Apple Neural Engine (ANE) for machine learning tasks, similar to iOS.\nOptimize known object detection and tracking using configurable parameters.\nUse increased power of the CPU and GPU for high-compute needs, with a tradeoff of increased thermal usage and reduced battery life.\nStream USB UVC devices connected to the Developer strap.\nNote\nEach of these entitlements allows a device to operate outside the default configuration. When using these features, be aware that they may impact the performance of other apps.\nRequest the entitlements\nIf you\u2019re interested in using the enterprise APIs for visionOS in your app, the Account Holder of your Apple Developer Program and/or Apple Developer Enterprise Program can submit anentitlement request.\nTo be eligible, your app needs to:\nBe for use in a business setting only\nBe for use in a business setting only\nMeet specific criteria associated with usage for each API\nMeet specific criteria associated with usage for each API\nEnterprise APIs for visionOS are eligible for business use only. You can distribute apps that you develop with the enterprise APIs for visionOS privately as proprietary in-house apps or custom apps using Apple Business Manager. For more information on distributing custom apps, seeSet distribution methods.\nYou can also request access to the entitlements forDevelopment Onlypurposes. With this access, you can build and run apps on your registered test devices with development provisioning profiles.\nConfigure your app\u2019s Xcode project\nTo use entitlements, you need to include both the entitlement file and a corresponding license file in your app. After Apple approves your app for one or more entitlements, you receive a license file, along with additional instructions.\nYou add the license file to your app\u2019s Xcode project. Placing the license file within your project and adding it to your build target allows Xcode to compile it within your app and then validate it when checking your entitlements.\nNote\nThe license file comes with an expiration date, so you need to renew it before then to ensure your entitlements continue to function.\nTo add an entitlement in Xcode:\nSelect your project in the Project navigator.\nSelect your project in the Project navigator.\nSelect the applicable target and then click the Signing & Capabilities tab.\nSelect the applicable target and then click the Signing & Capabilities tab.\nClick the Add Capability button (+) and type the name of the entitlement you want to add, such asmain camera access.\nClick the Add Capability button (+) and type the name of the entitlement you want to add, such asmain camera access.\nDouble-click the entitlement to add it to the Signing section. This creates a.entitlementsfile with the relevant capability, such ascom.apple.developer.arkit.main-camera-access.allowfor \u201cMain camera access\u201d.\nDouble-click the entitlement to add it to the Signing section. This creates a.entitlementsfile with the relevant capability, such ascom.apple.developer.arkit.main-camera-access.allowfor \u201cMain camera access\u201d.\nAfter you add the.licenseand.entitlementsfiles, you can implement and test the APIs you have approval to use. For more information, seeAdding capabilities to your app.\nSee Also\nEnterprise APIs for visionOS",
        "https://developer.apple.com/documentation/visionos/improving-accessibility-support-in-your-app": "visionOS\nImproving accessibility support in your visionOS app\nImproving accessibility support in your visionOS app\nImproving accessibility support in your visionOS app\nImproving accessibility support in your visionOS app\nOverview\nvisionOS is an immersive platform that supports people of all abilities. Even though experiences incorporate stunning visual content and hand- and eye-tracking technologies, people can engage with content in other ways. In fact, the platform supports people in many different situations, including those who are blind, have low vision, have limited mobility, or have limb differences. With the help of assistive technologies, people can interact with all of your app\u2019s content.\nDuring development, enable VoiceOver and other assistive features and test your app\u2019s accessibility support. Make sure people can navigate your app\u2019s interface intuitively, and that all of the necessary elements are present. Improve the descriptive information for those elements to communicate their intended purpose. And make sure your app adapts to changing conditions, such as changes to the Dynamic Type setting while your app is running.\nDefault font size\nIncreased font size\nFor general information about supporting accessibility, seeAccessibility. For design guidance, seeHuman Interface Guidelines > Accessibility.\nAdd accessibility traits to RealityKit entities\nVoiceOver and other assistive technologies rely on the accessibility information that your app\u2019s views and content provide. SwiftUI and UIKit provide default information for the standard system views, but RealityKit doesn\u2019t provide default information for the entities in your scenes.\nTo configure the accessibility information for a RealityKit entity, add an instance ofAccessibilityComponentto the entity. Use this component to specify the same values you specify for the rest of your app\u2019s views. The following example shows how to create this component and add it to an entity:\nPeople can use VoiceOver to initiate specific types of actions on your entities. Assign a value to thesystemActionsproperty of your component if your entity supports the incrementing or decrementing of its value, or supports activation with a gesture other than a standard tap. You don\u2019t need to set a system action if you let people interact with the entity using a standard single-tap gesture.\nThe following example uses the content of aRealityViewto determine when activation events occur on the view\u2019s entities. After subscribing to the view\u2019s activation events, the code sets up an asynchronous task to handle incoming events. When a new event occurs, the task executes the custom code to handle a collision.\nAdd support for Direct Gesture mode\nWhen VoiceOver is active in visionOS, people use hand gestures to navigate your app\u2019s interface and inspect elements. To prevent your app\u2019s code from interfering with VoiceOver interactions, the system doesn\u2019t deliver hand input to your app during this time. However, a person can perform a special VoiceOver gesture to enable Direct Gesture mode, which leaves VoiceOver enabled but restores hand input to your app.\nAdd VoiceOver announcements to your code to communicate the results of meaningful events. VoiceOver speaks these announcements at all times, but they are particularly useful when Direct Gesture mode is on. The following example posts an announcement when a custom gesture causes an interaction with a game piece:\nProvide alternatives to input that involves physical movement\nReduced mobility can affect a person\u2019s ability to interact with your app\u2019s content. When designing your app\u2019s input model, avoid experiences that require specific body movements or positions. For example, if your app supports custom hand gestures, add menu commands for each gesture so someone can enter them using a keyboard or assistive device.\nSome assistive technologies let people interact with your app using only their eyes. Using these technologies they can select, scroll, long press, or drag items in your interface. Even if you support other types of interactions, give people a way to access all of your app\u2019s behavior using only these interactions.\nAvoid head-anchored content\nSome assistive technologies allow people to navigate or view your app\u2019s interface using head movements. As the person\u2019s head moves, the assistive technology focuses on the item directly in front of them. Content that follows the movements of the person\u2019s head interferes with the behavior of these assistive technologies.\nWhen designing your interface, place content in windows or anchor it to locations other than the virtual camera. If you do need head-anchored content, provide an alternative solution when relevant assistive technologies are in use. For example, you might move head-anchored content to an anchor point that doesn\u2019t follow the person\u2019s head movements.\nTo determine when to change the anchoring approach for your content, check theaccessibilityPrefersHeadAnchorAlternativeenvironment variable in SwiftUI, or get theprefersHeadAnchorAlternativeproperty. This environment variable istruewhen an assistive technology is in use that conflicts with head-anchored content. Adapt your content to use alternate anchoring mechanisms at that time.\nLimit motion effects in your content\nMotion effects on any immersive device can be jarring, even for people who aren\u2019t sensitive to motion. Limit the use of motion effects that incorporate rapid movement, bouncing or wave-like movement, zooming animations, multi-axis movement, spinning, or rotations. When the person wearing the device is sensitive to motion effects, eliminate the use of these effects altogether.\nThe Reduce Motion system setting lets you know when to provide alternatives for all of your app\u2019s motion effects. Access this setting using theaccessibilityReduceMotionenvironment variable in SwiftUI or with theisReduceMotionEnabledproperty in UIKit. When the setting istrue, provide suitable alternatives for motion effects or eliminate them altogether. For example, show a static snapshot of the ocean instead of a video.\nFor more information, seeHuman Interface Guidelines > Motion.\nInclude captions for audio content\nFor people who are deaf or hard of hearing, provide high-quality captions for your app\u2019s content. Captions are a necessity to some, but are practical for everyone in certain situations. For example, captions are useful to someone watching a video in a noisy environment. Remember to include captions not just for text and dialogue, but also for music and sound effects in your content. For Spatial Audio content, include information in your captions that indicates the direction of various sounds.\nAVKitandAVFoundationprovide built-in support for displaying captioned content. These frameworks configure the font, size, color, and style of the captions automatically according to the person\u2019s accessibility settings. For example, the frameworks adopt the current Dynamic Type setting when displaying text.\nIf you have a custom video engine, check theisClosedCaptioningEnabledaccessibility setting to determine when to display captions. To get the correct appearance information for your captioned content, adoptMedia Accessibilityin your project. This framework provides you with the optimal font, color, and opacity information to apply to captioned text and images.\nSee Also\nDesign",
        "https://developer.apple.com/documentation/visionos/swift-splash": "visionOS\nSwift Splash\nSwift Splash\nSwift Splash\nSwift Splash\nOverview\nApple Vision Pro\u2019s ability to combine virtual content seamlessly with the real world allows for many kinds of interactive virtual experiences. Swift Splash leverages RealityKit and Reality Composer Pro to create a virtual water slide by combining modular slide pieces. When the builder finishes their ride, they can release an adventurous goldfish to try it out.\nSwift Splash uses multiple Reality Composer Scenes to create prepackaged entity hierarchies that represent each of the slide pieces the player connects to construct their ride. It demonstrates how to hide and reveal sections of the entity hierarchy based on the current state of the app. For example, each slide piece contains an animated fish entity that\u2019s hidden until the ride runs and the fish arrives at that particular piece. While Swift Splash is a fun, game-like experience, the core idea of assembling virtual objects out of predefined parts can also be used as the basis for a productivity or creation app.\nSwift Splash scenes include Shader Graph materials built in Reality Composer Pro to change the appearance of the ride at runtime. Each piece can be configured to display in one of three materials: metal, wood, or plastic. Other Shader Graph materials create special effects, such as the movement of the water and the flashing lights on the start and end pieces. Even particle effects are included in some of these prepackaged entities, such as the fireworks that play when the goldfish crosses the finish line.\nBuild slide pieces in Reality Composer Pro\nSlide pieces are the building blocks of Swift Splash. The Reality Composer project contains a separate scene for each one. In addition to the 3D models that make up the slide piece, each scene contains a number of other entities the app uses to animate and place the slide piece.\n\nIn the hierarchy viewer on the left side of the screenshot above, there are two transform entities calledconnect_inandconnect_out. These transforms mark the points where the slide piece connects to the next or previous piece. Swift Splash uses these transforms to place new pieces at the end of the existing slide, as well as to snap pieces to other slide pieces when you manually move them near each other.\nSlide pieces demonstrate the two primary mechanisms Swift Splash uses to find entities at runtime. For some entities, such asconnect_in, Swift Splash uses a naming convention and retrieves the entities by name or suffix when it needs to use them. In other cases, such as when names aren\u2019t unique or the retrieving code needs configuration values, Swift Splash uses a custom component to mark and retrieve entities.\nFor example, animated entities that appear when the ride runs contain a component calledRideAnimationComponent. The app uses this component to determine if the entity is an animation that plays while the ride is running. The component also stores additional state the app needs to implement the ride animation, such as a property calleddurationthat specifies when to start the animations on the next connected slide piece.\nRideAnimationComponentalso includes a property calledisPersistent. Persistent ride animations stay visible at all times but only animate when the ride is running, such as the animated door on the start piece. Nonpersistent ride animations, such as the fish swimming through a slide piece, display only while the ride is running and the fish swims through that particular piece.\nAvoid duplicate materials with material references\nMany of Swift Splash\u2019s slide pieces use the same materials. For example, the shader graph material that changes pieces from metal to wood to plastic is shared by all but one of the slide pieces. To avoid having duplicate copies of each material, Swift Splash leverages USDmaterial referencesto share materials between multiple entities in multiple scenes.\nThe Reality Composer Pro project contains a separate scene for each shared material, containing only that one material. Other track pieces create references to that material. If you change the original material, it affects all of the entities that reference it. For example, a scene calledM_RainbowLights.usdacontains the materialM_RainbowLights, and bothStartPiece.usdaandEndPiece.usdareference that material.\n\nParallelize the asset load\nTo maximize load speed and make the most efficient use of available compute resources, Swift Splash parallelizes loading scenes from the Reality Composer project using aTaskGroup. The app creates a separateTaskfor each of the scenes it needs to load.\nThe app then uses an async iterator to wait for and receive the results.\nFor more information on task groups, seeConcurrencyinThe Swift Programming Language.\nEach of these loaded pieces acts as a template. When the player adds a new piece of that type, the app clones the piece loaded from Reality Composer Pro and adds the clone to the scene.\nSpecify sort ordering for transparent entities\nWhen multiple entities have more than one overlapping, nonopaque material, RealityKit\u2019s default depth-sorting can cause it to draw those entities in the wrong order. As a result, some entities may not be visible from certain angles or in certain positions relative to other transparent entities. The default depth sorting is based on the center of the entity\u2019s bounding box, which may result in the incorrect drawing order when there are multiple overlapping materials with any amount of transparency. You can see an example of this by looking at the start piece in Reality Composer Pro, or by watching the video below.\nThe following video demonstrates the problem. If the three boxes are the bounding boxes for three different transparent entities, and the small spheres are the box centers, the sphere that\u2019s closest to the camera changes as the camera moves around the boxes, which changes the order that RealityKit\u2019s default depth sorting algorithm draws them.\nSwift Splash assigns aModelSortGroupComponentto each of the transparent entities to manually specify the relative depth sorting. To fix the transparency issues in the start piece in the video above, Swift Splash instructs RealityKit to draw the opaque parts of the fish first, its transparent goggles second, the water third, the glass globe fourth, and the selection glow shell last. Swift Splash does this by assigning aModelSortGroupComponentto each of the overlapping entities using the sameModelSortGroup, but with a different order specified.\nTraverse connected track pieces\nThe root entity for all of the individual slide pieces has aConnectableComponent. This custom component marks the entity as one that can be connected or snapped to other connectable entities. At runtime, the app adds aConnectableStateComponentto each slide piece it adds. The component stores state information for the track piece that doesn\u2019t need to be edited in Reality Composer Pro. Among the state information that this component stores is a reference to the next and previous piece.\nTo iterate through the entire ride, ignoring any disconnected pieces, the app gets a reference to the start piece and then iterates untilnextPieceisnil. This iteration, similar to iterating a linked list, repeats many times throughout the app. One example is the function that calculates the duration of the built ride by iterating through the individual pieces and adding up the duration of their animations.\nInteract with the ride\nTo build and edit the ride, players interact with Swift Splash in two different ways. They interact with SwiftUI windows to perform certain tasks, such as adding a new piece or deleting an existing piece of the ride. They also manipulate slide pieces using standard visionOS gestures, including taps, double taps, drags, and rotates. The player taps on a piece to select or deselect it. When a player double taps a piece, they select that piece without deselecting any other selected pieces. When someone drags a piece, it moves around the immsersive space, snapping together with other pieces if placed near one. A two-finger rotate gesture spins the selected track piece or pieces on the Z-axis.\nSwift Splash handles all of these interactions using standard SwiftUI gestures targeted to an entity. To support any of these gestures at any time, the app declares them usingSimultaneousGesture. The code for all of the gestures are contained inTrackBuildingView, which controls the app\u2019s immersive space. Here\u2019s how the app defines the rotation gesture:\nBecause multiple tap gestures on the sameRealityViewexecute with a different number of taps, multiple gestures may be called at once. If a player double taps an entity, for example, both the single tap and the double tap gesture code get called, and the app has to determine which one to execute. Swift Splash makes this determination by using a Boolean state variable. If a player single taps, it sets that variable\u00a0\u2014 calledshouldSingleTap\u2014 totrue. Then it waits for a period of time before executing the rest of its code. IfshouldSingleTapgets set tofalsewhile it\u2019s waiting, the code doesn\u2019t execute. When SwiftSplash detects a double tap gesture, it setsshouldSingleTaptofalse, preventing the single-tap code from firing when it executes the double-tap code.\nSee Also",
        "https://developer.apple.com/documentation/visionos/building-an-immersive-media-viewing-experience": "visionOS\nBuilding an immersive media viewing experience\nBuilding an immersive media viewing experience\nBuilding an immersive media viewing experience\nBuilding an immersive media viewing experience\nOverview\nvisionOS provides powerful features for building immersive media playback apps. It supports playing 3D video and Spatial Audio, which helps bring the content to life and makes the viewer feel like they\u2019re part of the action. Starting in visionOS 2, you can take your app\u2019s playback experience even further by creating custom environments using RealityKit and Reality Composer Pro.\nTheDestination Videosample includes a custom environment, Studio. The Studio environment provides a large, open space that\u2019s specifically designed to provide an optimal media viewing experience, as shown in the following image.\n\nDefine a video docking location\nDestination Video usesAVPlayerViewControllerto present video, which enables the app to provide a playback experience across platforms that matches system apps like TV and Music. In visionOS,AVPlayerViewControllerparticipates in the system docking behavior. When you play video in a full-window player then open an immersive experience, the system docks the video screen in a fixed location and presents streamlined playback controls that keep your focus on the content.\n\nThe system determines the docking location for the scene by default. In visionOS 2, you can customize this location by specifying a custom docking region.\nThe environment in Destination Video anchors the video player in front of the walkway at the top of the staircase. To have the video player dock to this location, the project defines aPlayerentity and adds aDockingRegionComponentto it in Reality Composer Pro\u2019s Inspector. This component defines the bounding region for the video player, which has a depth of0and uses a fixed 2.4:1 aspect ratio. Because the aspect ratio is fixed, to configure the docking region\u2019s size use thewidthproperty.\n\nReality Composer Pro provides a template to set up a configuration for Docking Region and related media reflections. You can access this template from the Insert menu by selecting Insert > Environment > Video Dock.\nChoose a location for your docking region that provides a comfortable viewing angle to avoid causing strain or discomfort during longer viewing sessions. Avoid placing objects between the viewer and the video. Using Reality Composer Pro to define the docking region helps to visualize how it looks in context. Review your environment and docking region placement on Apple Vision Pro to get an appropriate sense of scale and layout.\nEnhance the realism of your scene with reflections\nTo make your environment feel like a real, dynamic space, enable reflections from the video player on your environment surfaces. Reality Composer Pro supports two types of reflections that it exposes as Shader Graph nodes:\nA direct reflection of media content. Apply this reflection type on glossy surfaces like metals, mirrors, and water.\nA softer falloff of media content. Apply this reflection type to rougher, more organic surfaces like concrete or wood floor.\nDestination Video uses both types of reflections in its custom environment to create a more realistic experience that better grounds the video player in the scene.\n\nTo learn more about how the custom environment uses reflections, seeEnabling video reflections in an immersive environment.\nDefine the virtual scene lighting\nWhen Destination Video presents the Studio environment in a progressive immersion style, the scene provides a source of indirect lighting to the system. RealityKit represents this light source using an instance ofVirtualEnvironmentProbeComponent. To configure this lighting, the Studio scene defines anEnvironmentProbeentity and adds a Virtual Environment Probe component to it in Reality Composer Pro\u2019s Inspector. It defines the source as a blend between the project\u2019s light and dark image-based lighting (IBL) files, as shown below.\n\nWhen the app presents the light or dark variant, it looks up the probe and configures the source with an appropriate blend value. The app passes a value of0.0for the light variant and1.0for the dark, which effectively toggles which image the component uses as its source.\nEnhance audio immersion\nBy default, visionOS reverberates spatial audio sources by simulating the acoustics of the user\u2019s real environment. When you present a custom environment in a progressive or fully immersive space, you can enhance the level of immersion by applying reverb that matches the visuals of your scene.\nNote\nWhen your app presents an environment in an immersive space using theprogressiveimmersion style, turning the Digital Crown blends the acoustics of the real and virtual spaces to match the visual level of immersion.\nThe Studio environment defines aReverbentity and adds aReverbComponentto it in Reality Composer Pro\u2019s Inspector. The component defines a singlereverbproperty to indicate a specific preset to apply. There are several high-quality reverb presets to choose from including various rooms, hall, and outside spaces. The app uses theVery Large Roompreset, which best fits the environment\u2019s visuals.\n\nDefine a reverb component in your scene even if it doesn\u2019t provide custom audio. The system still uses the reverb preset to spatialize system sounds such as UI interactions.\nNote\nTo optimize the viewing experience, in most cases lower the volume of environment sounds, or stop their playback altogether, when video playback begins.\nSpecify content brightness and surroundings effects\nDestination Video presents the Studio environment by opening an immersive space in theprogressiveimmersion style. This style works well for media apps because people can customize their level of immersion by turning the Digital Crown - from no immersion to fully immersive.\nTo enhance the media presentation and create a more immersive experience when presenting the Studio environment, the app customizes the space in the following ways:\nIt specifies a content brightness value for the immersive space, which indicates the overall brightness of the scene. The system uses this value to tailor the video presentation to best fit its surroundings.\nIt specifies a content brightness value for the immersive space, which indicates the overall brightness of the scene. The system uses this value to tailor the video presentation to best fit its surroundings.\nIt sets a custom tint color for the video passthrough of the user\u2019s hands and surroundings. The app defines tint color that matches the light or dark variant of the environment, and sets the appropriate tint color using thepreferredSurroundingsEffect(_:)view modifier.\nIt sets a custom tint color for the video passthrough of the user\u2019s hands and surroundings. The app defines tint color that matches the light or dark variant of the environment, and sets the appropriate tint color using thepreferredSurroundingsEffect(_:)view modifier.\nPresent a custom scene in the environment picker\nIn visionOS 2,AVPlayerViewControllerautomatically displays a button for a person to pick an environment. When a person presses the button, the system displays a list of viewing environments in which they can watch the video. Selecting an item from the list opens the environment, and docks the player into its ideal viewing location within the scene. By default, the environment picker lists the most recently used system environments, but you can configure the list to show your custom environments as well.\nDestination Video adds the Studio environment\u2019s light and dark variants to the list by attaching the newimmersiveEnvironmentPicker(content:)view modifier to the player view. This modifier takes aViewBuilderthat defines a button for each environment entry you\u2019re adding.\nThis sample passes the modifier a custom view that defines two buttons: one for the light variant and one for the dark. Each button displays a title, thumbnail image, and subtitle that indicates which variant it is.\nAfter adding these buttons to the environment picker, they appear alongside the system environments:\n\nSee Also",
        "https://developer.apple.com/documentation/visionos#Performance": "visionOS\nOverview\nvisionOS is the operating system that powers Apple Vision Pro. Use visionOS together with familiar tools and technologies to build immersive apps and games for spatial computing.\n\nDeveloping for visionOS requires a Mac with Apple silicon. Create new apps using SwiftUI to take full advantage of the spectrum of immersion available in visionOS. If you have an existing iPad or iPhone app, add the visionOS destination to your app\u2019s target to gain access to the standard system appearance, and add platform-specific features to create a compelling experience. To provide continuous access to your content in the meantime, deliver a compatible version of your app that runs in visionOS.\nExpand your app into immersive spaces\nStart with a familiar window-based experience to introduce people to your content. From there, addSwiftUIscene types specific to visionOS, such as volumes and spaces. These scene types let you incorporate depth, 3D objects, and immersive experiences.\nBuild your app\u2019s 3D content withRealityKitand Reality Composer Pro, and display it with aRealityView. In an immersive experience, useARKitto integrate your content with the person\u2019s surroundings.\n\nExplore new kinds of interaction\nPeople can select an element by looking at it and tapping their fingers together. They can also pinch, drag, zoom, and rotate objects using specific hand gestures.SwiftUIprovides built-in support for these standard gestures, so rely on them for most of your app\u2019s input. When you want to go beyond the standard gestures, useARKitto create custom gestures.\nTap to select\nPinch to rotate\nManipulate objects\nCreate custom gestures\nDive into featured sample apps\nExplore the core concepts for all visionOS apps with Hello World. Understand how to detect custom gestures using ARKit with Happy Beam. Discover streaming 2D and stereoscopic media with Destination Video. And learn how to build 3D scenes with RealityKit and Reality Composer Pro with Diorama and Swift Splash.\nTopics\nApp construction\nDesign\nSwiftUI\nRealityKit and Reality Composer Pro\nARKit\nVideo playback\nXcode and Simulator\nPerformance\niOS migration and compatibility\nEnterprise APIs for visionOS\nvisionOS\nOverview\nExpand your app into immersive spaces\nExplore new kinds of interaction\nDive into featured sample apps\nTopics",
        "https://developer.apple.com/documentation/visionos/analyzing-the-performance-of-your-visionos-app": "visionOS\nAnalyzing the performance of your visionOS app\nAnalyzing the performance of your visionOS app\nAnalyzing the performance of your visionOS app\nAnalyzing the performance of your visionOS app\nOverview\nTo maintain the sense of immersion on Apple Vision Pro, the system attempts to provide the device displays with up-to-date imagery at a constant rate and respond to interactions with minimum latency. Any visual choppiness or delay in responsiveness interferes with the spatial experience. Higher power consumption over extended periods of time, or extreme power consumption over shorter periods of time, can trigger thermal mitigations that also impact the quality of the experience. It\u2019s important to minimize your app\u2019s use of system resources to ensure your app performs well on the platform. Many of the same best practices and optimization procedures you use developing for other Apple platforms apply when developing for visionOS as well. For more information about optimizing your app on other platforms, seeImproving your app\u2019s performance.\nTo get useful information specific to rendering bottlenecks, high system power use, and other issues that effect the responsiveness of your visionOS app, profile your app with the RealityKit Trace template in Instruments. This template helps you identify:\nComplex content or content with frequent updates that cause the render server to miss deadlines and drop frames.\nComplex content or content with frequent updates that cause the render server to miss deadlines and drop frames.\nContent and tasks that result in high system power use.\nContent and tasks that result in high system power use.\nLong running tasks on the the main thread that interfere with efficient processing of input events.\nLong running tasks on the the main thread that interfere with efficient processing of input events.\nTasks running on other threads that don\u2019t complete in time to sync back to the main thread for view hierarchy updates.\nTasks running on other threads that don\u2019t complete in time to sync back to the main thread for view hierarchy updates.\nNote\nYou can profile using a real device or a simulator, but to get the most accurate and actionable information, use a real device. Software and hardware differences between a simulator on your Mac and a real device prevent you from relying on timing information. Simulated devices are useful for quick iteration and improving performance aspects that aren\u2019t based on time.\nOpen a new trace document\nTo create a new trace document:\nSelect your app\u2019s scheme and a visionOS run destination from the Xcode project window.\nSelect your app\u2019s scheme and a visionOS run destination from the Xcode project window.\nChoose Product > Profile.\nChoose Product > Profile.\nChoose RealityKit Trace template\nChoose RealityKit Trace template\nSelect the Choose button.\nSelect the Choose button.\n\nAlternatively, launch Instruments and choose a target app from the template selection dialog.\nThe RealityKit Trace template includes the following instruments:\nCaptures frame render times and lifespans for frames the visionOS render server generates. This instrument indicates when frames miss rendering deadlines and provides average CPU and GPU render rates.\nCaptures comprehensive timing information from the entire render pipeline including rendering, commits, animations, physics, and spatial systems. This instrument identifies potential bottlenecks in your app\u2019s process or in the render server as a result of your app\u2019s content and indicates areas of moderate and high system power usage that require optimization.\nCaptures and displays Runloop execution details.\nProfiles running threads on all cores at regular intervals for all processes.\nCaptures and displays periods of time when the main thread is unresponsive.\nRecords Metal app events.\nConsider adding other instruments to your trace for specific investigations. For example, you can use the Thermal State instrument to record device thermal states to check if thermal pressures are throttling performance.\nProfile your workflows\nClick the record button at the top left of the window to start capturing profile data. Perform the actions in your app that you want to investigate. When you complete the actions, click the record button again to stop recording.\nTo investigate performance issues or analyze system power impact, profile your app in isolation to understand your app\u2019s impact on system performance and ensure you get the most actionable information. For apps that run alongside other apps, profile your app again with those other apps running to understand how people experience your app in conjunction with other apps.\nInspect frame rendering performance\nTo maintain a smooth visual experience, the system tries to render new frames for the Apple Vision Pro at 90 frames per second (FPS). The system renders at other frame rates depending on the content it displays and the current surroundings. Each frame has a deadline for rendering based on the target frame rate. Not meeting these deadlines results in dropped frames. This creates a poor spatial experience overall. People tend to notice it in the visual performance of Persona and SharePlay experiences, video playback, and scrolling. The RealityKit Frames instrument displays the time spent rendering each frame in the Frames section of its timeline:\n\nWhen you zoom out, you can identify areas with a high number of frame drops or with frames running close to the rendering deadline. The timeline uses green to identify frames that complete rendering before the deadline, orange for frames that complete rendering close to the deadline, and red for frames that don\u2019t complete rendering that the renderer drops. Dropped frames contribute to a poor spatial experience, but frames that complete close to their rendering deadline indicate performance problems too. Hold the Option key and drag to zoom into a frame, or group of frames, to see their lifespan broken down in stages:\n\nThis provides you with insight into which portion of the rendering pipeline to investigate further. This timeline also includes sections that visualize the Average CPU Frame Time and Average GPU Frame Time to indicate the type of processing that computes the frames. A region of the timeline without a frame block indicates a period of time without changes to a person\u2019s surroundings or app updates. The render server avoids computing new frames to send to the compositor during these periods which helps optimize power use.\nMonitor system power usage\nWhen thermal levels rise to levels that trigger thermal mitigations in the system, performance degrades and negatively impacts the responsiveness of your app. Optimize for power to avoid this negative impact. The timeline for the RealityKit Metrics instrument includes a System Power Impact section to identify areas of high power usage in your app:\n\nIf the timeline displays green, the tool considers your app\u2019s impact on system power low enough to sustain. Regions that display orange or red indicate the system power usage could cause thermal levels to rise and trigger thermal mitigations. This decreases the availability of system resources, which can cause visual interruptions and responsiveness issues.\nNote\nIf the render server can\u2019t maintain the target frame rate of 90 FPS due to thermal pressure, it might reduce its frame rate in half. When this occurs, all frames in the frames track show up as missing their rendering deadlines. Other factors can cause reduced frame rate, including the complexity and frequency of the content the system is processing. Use the Thermal State instrument to determine if thermal conditions are causing the rate limiting or if it\u2019s due to other factors.\nIdentify bottlenecks\nThe Bottlenecks section of the timeline for the RealityKit Metrics instrument contains markers that indicate high overhead in your app or the render server that contribute to dropped frames and high system power use. When you encounter either of these issues, check if the timeline identifies bottlenecks you can address. Double-click on any of the markers to display more information in the detail area at the bottom of the instruments window. If the detail area is hidden, choose View > Detail Area > Show Detail Area to reveal it. The render server encounters bottlenecks in either the CPU or GPU. The instrument categorizes bottlenecks by their severity and type.\nTo filter the bottlenecks listed in the detail area to a particular time period, drag inside the timeline to select the region. To see an outline view of the bottlenecks organized by severity and type, select Summary: RealityKit Bottlenecks from the menu at the top left of the detail area. Click the arrow button to the right of the severity or type in the outline view to show the list of bottlenecks in that category.\nWhen you select a specific bottleneck, the extended detail provides recommendations for you to address the bottleneck \u2013 choose View > Show Extended Detail to reveal the extended detail if it\u2019s hidden.\n\nExplore the metrics that relate to bottlenecks\nThe trace provides additional information you can use to identify changes to make in your app to address these bottlenecks. Click the expansion arrow for the RealityKit Metrics instrument timeline to reveal graphs specific to each major category of work. Use the metrics associated with these graphs to determine which RealityKit feature has the biggest impact on high CPU frame times in the app process or in the render server. When interpreting these graphs, lower indicates better performance and power. The metrics represent values from all apps running, so profile with just your app running when trying to optimize for these metrics.\n\nMetrics related to the cost of 3D RealityKit rendering in the render server. This includes the number of draw calls, triangles, and vertices from all apps.\nMetrics related to UI content rendering costs in the render server. This includes the total number of render passes, offscreen render passes, and translucent UI meshes from all apps.\nMetrics related to the costs of entity commits in the app and the render server. This includes the number of RealityKit entities shared with the render server from all apps, as well as the number of updates received from all apps over certain intervals.\nMetrics related to the cost of RealityKit animations in the app and the render server. This includes the number of skeletal animations, across all apps.\nMetrics related to the cost of RealityKit physics simulations, collisions, and hit testing in the app process and render server. This includes the number of rigid body counts and colliders in use, as well as the type of physics shapes that the UI and other 3D content use, across all apps.\nMetrics related to the costs of spatial algorithms in the render server. This includes the number of custom anchors, across all apps.\nTip\nThe graphs for some sections combine several individual metrics. The heading indicates this by displaying a graph count. Click on the bottom of the timeline\u2019s heading and drag down to display individual graphs for each metric. For example, the 3D Render Timeline might display 13 Graphs in the heading; expanding that timeline exposes individual graphs for 3D Mesh Draw Calls, 3D Mesh Triangles, 3D Mesh Vertices, and the 10 additional metrics.\nThe timeline for your app\u2019s process helps summarize information from the instruments about your process and the work the render server completes for your process.\n\nChoose an option from the pop-up in the timeline header to show different graphs in the timeline:\nTime each thread spends waiting or busy.\nTime the main thread is unresponsive.\nCPU usage and lifecycle status.\nOverhead attributed to RealityKit systems.\nWhen you select the timeline for your app\u2019s process, you can choose instrument summaries and profile data to display in the detail area from the popup-button at its top-left:\n\nTo filter the information in the detail area by time, select periods of time in the timeline  above.\nDetect delays on the main thread\nSelect Hangs in your app\u2019s process timeline to identify times in the trace that might have interaction delays. Use the RealityKit Metrics and Time Profiler summaries to better understand the work your app is doing. Choose the following options from the detail area pop-up menu:\nShows information from the Time Profiler instrument to determine what your app is doing during a hang.\nRealityKit System CPU times: Shows minimum, maximum, and average times the CPU spends on various RealityKit system operations.\nOptimize any 3D render updates, hit testing, and collision work you find. For more information about addressing hangs in your app, seeImproving app responsiveness.\nManage audio overhead\nUse the Audio Playback section of your process\u2019s timeline to identify areas of high audio overhead. The system defaults to using spatial audio for your app when running on visionOS. It processes information in real time about your position, surroundings, and the current location of audio sources to generate an immersive audio experience. If you include too many concurrent audio sources that require the system to adapt audio sources to their location within a large space, the increased demand on system resources can lead to delays in the audio output.\nTo reduce the spatial audio work, limit:\nThe number of concurrently playing audio sources\nThe number of concurrently playing audio sources\nThe number of moving audio sources\nThe number of moving audio sources\nThe size of the soundstage\nThe size of the soundstage\nConsider creating a pool of audio players to limit the maximum number of players your app uses. Place players on stationary entities, instead of moving entities, when appropriate. Initializing several audio players at the same time causes a high overhead that affects other aspects of the system, such as rendering performance. Consider the other tasks the system completes during these allocations and space them out over time. For more information, seeCreate a great spatial playback experience.\nProfile custom materials for optimization\nUse the Metal System Trace template to profile your custom materials in isolation before adding more visual effects to them. Examine the Metal GPU cost and try to optimize for GPU ALU Instructions and GPU Texture reads and writes per frame. For more information on using this template, seeAnalyzing the performance of your Metal app.\nIn order to use the Metal Application instrument to profile your custom materials accurately, set a fixed performance state:\nClick and hold the record button and select Recording Options.\nClick and hold the record button and select Recording Options.\nSelect the options for the Metal Application instrument.\nSelect the options for the Metal Application instrument.\nSet the Counter Set to Performance Limiters.\nSet the Counter Set to Performance Limiters.\nSet the Performance State to Minimum or Medium.\nSet the Performance State to Minimum or Medium.\n\nA person\u2019s eye position, the distance from the person to the content, and the amount of content the app displays all impact the amount of GPU work done for custom materials from Reality Composer Pro. To compare traces, keep these factors as consistent as possible. For a custom material you use in a Fully Immersive Space, try to remove all other content from the scene while profiling to isolate the overhead of the material. For custom materials you use for other types of content, consider anchoring them to a person\u2019s head in a test scene so the distance from the person remains fixed.\nNote\nUsing an unlit or inexpensive custom material becomes even more important when your app usesMetaland theCompositor Servicesframework to present a fully immersive experience due to the number of pixels your app must render.\nSee Also\nPerformance",
        "https://developer.apple.com/documentation/visionos/happybeam": "visionOS\nHappy Beam\nHappy Beam\nHappy Beam\nHappy Beam\nOverview\nIn visionOS, you can create fun, dynamic games and apps using several different frameworks to create new kinds of spatial experiences: RealityKit, ARKit, SwiftUI, and Group Activities. This sample introduces Happy Beam, a game where you and your friends can hop on a FaceTime call and play together.\nYou\u2019ll learn the mechanics of the game where grumpy clouds float around in the space, and people play by making a heart shape with their hands to project a beam. People aim the beam at the clouds to cheer them up, and a score counter keeps track of how well each player does cheering up the clouds.\nDesign the game interface in SwiftUI\nMost apps in visionOS launch as a window that opens different scene types depending on the needs of the app.\nHere you see how Happy Beam presents a fun interface to people by using several SwiftUI views that display a welcome screen, a coaching screen that gives instructions, a scoreboard, and a game-ending screen.\nWelcome window\nInstructions\nScoreboard\nEnding window\n\n\n\n\nThe following shows you the primary view in the app that displays each phase of gameplay:\nWhen 3D content starts to appear, the game opens an immersive space to present content outside of the main window and in a person\u2019s surroundings.\nTheHappyBeamcontainer view declares a dependency onopenImmersiveSpace:\nIt later uses that dependency to open the space from the app\u2019s declaration when it\u2019s time to start showing 3D content:\nDetect a heart gesture with ARKit\nThe Happy Beam app recognizes the centralheart-shaped handsgesture using ARKit\u2019s support for 3D hand tracking in visionOS. Using hand tracking requires a running session and authorization from the wearer. It uses theNSHandsTrackingUsageDescriptionuser info key to explain to players why the app requests permission for hand tracking.\n\nHand-tracking data isn\u2019t available when your app is only displaying a window or volume. Instead, it\u2019s available when you present an immersive space, as in the previous example.\nYou can detect gestures using ARKit data with a level of accuracy that depends on your use case and intended experience. For example, Happy Beam could require strict positioning of finger joints to closely resemble a heart shape. Instead, however, it prompts people to make a heart shape and uses a heuristic to indicate when the gesture is close enough.\nThe following checks whether a person\u2019s thumbs and index fingers are almost touching:\nSupport several kinds of input\nTo support accessibility features and general user preferences, include multiple kinds of input in an app that uses hand tracking as one form of input.\nHappy Beam supports several kinds of input:\nInteractive hands input from ARKit with the custom heart gesture.\nDrag gesture input to rotate the stationary beam on its platform.\nAccessibility components from RealityKit to support custom actions for cheering up the clouds.\nGame Controller support to make control over the beam more interactive from Switch Control.\nDisplay 3D content with RealityKit\nThe 3D content in the app comes in the form of assets that you can export from Reality Composer Pro. You place each asset in theRealityViewthat represents your immersive space.\nThe following shows how Happy Beam generates clouds when the game starts, as well as materials for the floor-based beam projector. Because the game uses collision detection to keep score \u2014 the beam cheers up grumpy clouds when they collide \u2014 you make collision shapes for each model that might be involved.\nAdd SharePlay support for multiplayer gaming experiences\nYou use the Group Activities framework in visionOS to support SharePlay during a FaceTime call. Happy Beam uses Group Activities to sync the score, active players list, and the position of each player\u2019s projected beam.\nNote\nDevelopers using theApple Vision Pro developer kitcan test spatial SharePlay experiences on-device by installing thePersona Preview Profile.\nUse a reliable channel to send information that\u2019s important to be correct, even if it can be slightly delayed as a result. The following shows how Happy Beam updates the game model\u2019s score state in response to a score message:\nUse an unreliable messenger for sending data with low-latency requirements. Because the delivery mode is unreliable, some messages might not make it. Happy Beam uses the unreliable mode to send live updates to the position of the beam when each participant in the call chooses the Spatial option in FaceTime.\nThe following shows how Happy Beam serializes beam data for each message:\nSee Also",
        "https://developer.apple.com/documentation/visionos#iOS-migration-and-compatibility": "visionOS\nOverview\nvisionOS is the operating system that powers Apple Vision Pro. Use visionOS together with familiar tools and technologies to build immersive apps and games for spatial computing.\n\nDeveloping for visionOS requires a Mac with Apple silicon. Create new apps using SwiftUI to take full advantage of the spectrum of immersion available in visionOS. If you have an existing iPad or iPhone app, add the visionOS destination to your app\u2019s target to gain access to the standard system appearance, and add platform-specific features to create a compelling experience. To provide continuous access to your content in the meantime, deliver a compatible version of your app that runs in visionOS.\nExpand your app into immersive spaces\nStart with a familiar window-based experience to introduce people to your content. From there, addSwiftUIscene types specific to visionOS, such as volumes and spaces. These scene types let you incorporate depth, 3D objects, and immersive experiences.\nBuild your app\u2019s 3D content withRealityKitand Reality Composer Pro, and display it with aRealityView. In an immersive experience, useARKitto integrate your content with the person\u2019s surroundings.\n\nExplore new kinds of interaction\nPeople can select an element by looking at it and tapping their fingers together. They can also pinch, drag, zoom, and rotate objects using specific hand gestures.SwiftUIprovides built-in support for these standard gestures, so rely on them for most of your app\u2019s input. When you want to go beyond the standard gestures, useARKitto create custom gestures.\nTap to select\nPinch to rotate\nManipulate objects\nCreate custom gestures\nDive into featured sample apps\nExplore the core concepts for all visionOS apps with Hello World. Understand how to detect custom gestures using ARKit with Happy Beam. Discover streaming 2D and stereoscopic media with Destination Video. And learn how to build 3D scenes with RealityKit and Reality Composer Pro with Diorama and Swift Splash.\nTopics\nApp construction\nDesign\nSwiftUI\nRealityKit and Reality Composer Pro\nARKit\nVideo playback\nXcode and Simulator\nPerformance\niOS migration and compatibility\nEnterprise APIs for visionOS\nvisionOS\nOverview\nExpand your app into immersive spaces\nExplore new kinds of interaction\nDive into featured sample apps\nTopics",
        "https://developer.apple.com/documentation/visionos/adopting-best-practices-for-privacy": "visionOS\nAdopting best practices for privacy and user preferences\nAdopting best practices for privacy and user preferences\nAdopting best practices for privacy and user preferences\nAdopting best practices for privacy and user preferences\nOverview\nTo protect user privacy, the system handles camera and sensor inputs without passing the information to apps directly. Instead, the system enables your app to seamlessly interact with a user\u2019s surroundings and to automatically receive input from the user. For example, the system handles the eye- and hand-position data needed to detect interactions with your app\u2019s content. Similarly, the system provides a way to automatically alter a view\u2019s appearance when someone looks at it, without your app ever knowing what the user is looking at.\nIn the few cases where you actually need access to hand position or information about the user\u2019s surroundings, the system requires you to obtain authorization from the user first.\n\nImportant\nIt\u2019s your responsibility to protect any data your app collects, and to use it in responsible and privacy-preserving ways. Don\u2019t ask for data that you don\u2019t need, be transparent about how you use the data you acquire, and respect the choices of the person whose data it is.\nFor information about how to specify the privacy data your app uses, seeDescribing data use in privacy manifests. For general information about privacy, seeProtecting the User\u2019s Privacy.\nAdopt the system-provided input mechanisms\nOn Apple Vision Pro, people use their eyes and hands to interact with the items they see in front of them. Where they look determines where the system applies focus, and a tap gesture with either hand generates a touch event on that focused item. The system can also detect when someone\u2019s fingers interact with virtual items in the person\u2019s field of vision. When you adopt the standard UIKit and SwiftUI event-handling mechanisms, you get all of these interactions automatically.\nFor most apps, the system-provided gesture recognizers are sufficient for responding to interactions. Although you can get the position of someone\u2019s hands with ARKit, doing so isn\u2019t necessary for most apps. Collect hand-position data only when the system doesn\u2019t offer what you need. For example, you might use hand-position data to attach 3D content to the person\u2019s hands. Some other things to remember about hand-position data:\nPeople can deny your request for access to hand-position data. Be prepared to handle situations where the data isn\u2019t available.\nPeople can deny your request for access to hand-position data. Be prepared to handle situations where the data isn\u2019t available.\nYou must present an immersive space to access hand data. When you open an immersive space, the system hides other apps.\nYou must present an immersive space to access hand data. When you open an immersive space, the system hides other apps.\nFor information about how to handle the standard-system events, see theSwiftUIandUIKitdocumentation.\nProvide clear messaging around privacy-sensitive features\nThe following ARKit features require you to provide a usage description string in your app\u2019sInfo.plistfile:\nWorld-tracking data\nWorld-tracking data\nHand-tracking data\nHand-tracking data\nOther privacy-sensitive technologies in visionOS also require you to supply usage description strings. For example, you provide usage descriptions for the Core Location features you adopt. These strings communicate why your app needs the data, and how you plan to use the data to help the person using your app. The first time you request authorization to use the technology, the system prompts the person to grant or deny access to your app. The system includes your usage-description string in the dialog it displays.\nFor information about requesting access to ARKit data, seeARKit. For guidance on how to craft good messages around privacy-friendly features, seeHuman Interface Guidelines.\nSee Also\nDesign",
        "https://developer.apple.com/documentation/visionos/designing-realitykit-content-with-reality-composer-pro": "visionOS\nDesigning RealityKit content with Reality Composer Pro\nDesigning RealityKit content with Reality Composer Pro\nDesigning RealityKit content with Reality Composer Pro\nDesigning RealityKit content with Reality Composer Pro\nOverview\nUse Reality Composer Pro to visually design, edit, and preview RealityKit content. In Reality Composer Pro, you can create one or more scenes, which  act as a container for RealityKit content. Scenes contain hierarchies of entities, which are virtual objects such as 3D models.\n\nIn addition to helping you compose scenes, Reality Composer Pro also gives you the ability to add and configure components \u2014 even custom components that you\u2019ve written \u2014 to the entities in your scenes and also lets you create complex materials and effects using a node-based material editor called Shader Graph.\nLaunch Reality Composer Pro\nWhen you create a visionOS project in Xcode, it also contains a default Reality Composer Pro project namedRealityKitContentwithin the Packages folder, which is a Swift package. TheRealityKitContentpackage can include images, 3D models, and other assets like audio and video files. The assets you add to your project go in theRealityKitContent.rkassetsbundle, while your source code goes into its Sources directory. The package also contains a file calledPackage.realitycomposerpro, which is the actual Reality Composer Pro project.\nTo launch Reality Composer Pro, double-click thePackage.realitycomposerprofile in the Project navigator, or click the Open in Reality Composer Pro button. If your project doesn\u2019t already have a Reality Composer Pro project, you can launch Reality Composer Pro directly by choosing Xcode > Open Developer Tool > Reality Composer Pro.\nFor efficiency, store all of your RealityKit assets in Reality Composer Pro projects. Xcode compiles Reality Composer Pro projects into a more efficient format when you build your app.\nNote\nLoading assets from a.realityfile is considerably faster and more resource efficient than loading individual asset files.\nOrient yourself in Reality Composer Pro\nThe Reality Composer Pro window has several sections. The top-half displays the active scene. If you have multiple scenes, the window shows a tab bar at the top with one tab for each open scene. Ascenein Reality Composer Pro is an entity hierarchy stored in a.usdafile.\nThe left side of the top pane contains the hierarchy browser, which shows a tree representation of the entities in the active scene. You can toggle it using the top-left toolbar button to reveal errors and warnings. The middle pane is the 3D View, which shows a 3D representation of the active scene. The top-right is the inspector, which shows configurable values for the item selected in the 3D view, hierarchy view, or Shader Graph, depending on which has focus.\nTip\nA Reality Composer Pro scene can represent an entire RealityKit scene, and you can have multiple scenes in your Reality Composer Pro project, each driving a differentRealityViewin the same app. A scene can also contain a collection of entities to use as a building block. For example, if you had an airplane model, you might build a scene for it that contains its 3D model, a particle effect to make smoke come out its engine, and audio entities or components that represent the various sounds a plane makes. Your app could then load those combined assets and use them together anywhere it needs.\nThe bottom half of Reality Composer Pro contains the following four tabs:\nDisplays all of the assets in your project.\nAn advanced, node-based material editor.\nA tool for combining sound assets.\nInformation about the currently open scene, such as the number of entities, vertices, and animations it contains.\n\nReality Composer Pro projects start with a single empty scene calledScenewhich is stored in a file calledScene.usda. You can create as many additional scenes as you need by choosing File > New > Scene. New scenes open as tabs along the top of the window, and they also appear in the Project Browser as.usdafiles.\nIf you close a scene\u2019s tab and need to re-open it, double-click on the scene\u2019s.usdafile in the Project Browser. If you no longer need a scene, delete its.usdafile from the Project Browser or remove it from your project\u2019s.rkassetsbundle in Xcode.\nTo delete a scene:\nClose the scene tab by selecting File > Close Tab\nClose the scene tab by selecting File > Close Tab\nSelect the scene\u2019s.usdafile in the Project Browser\nSelect the scene\u2019s.usdafile in the Project Browser\nControl-click the scene\u2019s.usdafile  the Project Browser.\nControl-click the scene\u2019s.usdafile  the Project Browser.\nChoose Delete from the contextual menu.\nChoose Delete from the contextual menu.\nClick Move to Trash.\nClick Move to Trash.\nThis removes the scene\u2019s.usdaand the scene tab at the top of the window.\nAdd assets to your project\nIn Reality Composer Pro, you design scenes by first importing assets into your project. Then add assets to scenes and move, rotate, and scale them. The Project Browser tab displays all of the asset files in your project. You can add new assets by dragging them to the Project Browser or by choosing File > Import and select the assets to add to your project. To add an asset from the Project Browser to the current scene, drag it to the 3D view in the center of the window, or to the hierarchy view in the top-left of the window.\nNote\nReality Composer Pro projects can contain assets not used in any scene. Such assets are still compiled into your app and can be loaded at runtime and take full advantage of the efficient loading process for.realityfiles.\nReality Composer Pro can represent many assets as entities, but it can\u2019t represent all assets that way; for example:\nUSDZ models do become an entity or entity hierarchy when you add them to a scene.\nUSDZ models do become an entity or entity hierarchy when you add them to a scene.\nImage files do not become an entity. Reality Composer Pro only uses image assets indirectly, such as being the source texture for materials you build in Shader Graph. If you drag assets that Reality Composer Pro can\u2019t turn into an entity, nothing happens.\nImage files do not become an entity. Reality Composer Pro only uses image assets indirectly, such as being the source texture for materials you build in Shader Graph. If you drag assets that Reality Composer Pro can\u2019t turn into an entity, nothing happens.\nAdd any 3D models, animations, sounds, and image files you need to your project. You can organize your assets into subfolders to make the Project Browser more manageable as your project grows in size.\nReality Composer Pro has a library of assets that you can use in your own apps. You can access the library by clicking the Add button (+) in the toolbar. Click the icon of the down-arrow inside a circle next to an asset to download the asset to Reality Composer Pro. When the download finishes, you can double-click or drag the asset into your project.\n\nImportant\nReality Composer Pro treats your imported assets as read-only.\nChanges you make to assets in a scene only affect that scene\u2019s copy of the asset. The changes you make are stored in the scene\u2019s.usdafile, not in the original asset. That means you can work without fear of inadvertently changing other scenes. If you plan to make significant changes to an imported 3D model, such as by replacing its materials with dynamic Shader Graph materials, import the model as a.usdcfile instead of as a.usdzfile, and then separately import just the supporting assets you need to avoid Xcode compiling assets that you don\u2019t need into your app.\nCompose scenes from assets\nAll RealityKit entities in a scene exist at a specific position, orientation, and scale, even if that entity has no visual representation. When you click to select an entity in the 3D view or hierarchy view, Reality Composer Pro displays:\nA manipulator over the entity in the 3D view.\nA manipulator over the entity in the 3D view.\nAny configurable values from the entity\u2019s components in the inspector on the right.You can use the manipulator to move, rotate, and scale the selected entity.\nAny configurable values from the entity\u2019s components in the inspector on the right.\nYou can use the manipulator to move, rotate, and scale the selected entity.\nTo move the selected entity around the 3D scene, drag the small colored cone that corresponds to the axis you want to move it along. Alternatively, you can drag the entity itself to move it freely relative to your viewing angle.\nTo move the selected entity around the 3D scene, drag the small colored cone that corresponds to the axis you want to move it along. Alternatively, you can drag the entity itself to move it freely relative to your viewing angle.\nTo rotate the selected entity, click on the manipulator\u2019s rotation control, which looks like a circle, and drag in a circular motion.Reality Composer Pro\u2019s manipulator only shows one rotation control at a time.To rotate an entity on one of the other axes, click the cone corresponding to the axis you want to rotate. For example, if you want to rotate the entity on theXaxis, tap the red cone to bring up the red rotation handle for that axis.\nTo rotate the selected entity, click on the manipulator\u2019s rotation control, which looks like a circle, and drag in a circular motion.\nReality Composer Pro\u2019s manipulator only shows one rotation control at a time.\nReality Composer Pro\u2019s manipulator only shows one rotation control at a time.\nTo rotate an entity on one of the other axes, click the cone corresponding to the axis you want to rotate. For example, if you want to rotate the entity on theXaxis, tap the red cone to bring up the red rotation handle for that axis.\nTo rotate an entity on one of the other axes, click the cone corresponding to the axis you want to rotate. For example, if you want to rotate the entity on theXaxis, tap the red cone to bring up the red rotation handle for that axis.\nTo scale the selected entity uniformly, click the rotation circle and drag away from the entity origin to scale it up, or toward the entity origin to scale it down. Because it scales uniformly, it doesn\u2019t matter which rotation handle Reality Composer Pro is showing.\nTo scale the selected entity uniformly, click the rotation circle and drag away from the entity origin to scale it up, or toward the entity origin to scale it down. Because it scales uniformly, it doesn\u2019t matter which rotation handle Reality Composer Pro is showing.\nNote\nIn the manipulator, Red indicates the X axis, Green indicates the Y axis, and Blue indicates the Z axis.\nAlternatively, you can make the same changes to the selected entity by typing new values into the transform component of the inspector. The transform component stores the position, rotation, and scale for an entity. The manipulator is just a visual way to change the values on this component.\n\nActivate and deactivate scene entities\nReality Composer Pro scenes can get quite complex and sometimes contain overlapping entities, which can be difficult to work with. To simplify a scene, you can deactivate entities to remove them from the 3D view. Deactivate entities by Control-clicking them and selecting Deactivate from the contextual menu. The entity still exists in your project and is shown in the hierarchy view, albeit grayed out and without any child entities. It won\u2019t, however, appear in the 3D view. Xcode doesn\u2019t compile deactivated entities into your app\u2019s bundle, so it\u2019s important to re-activate any entities your app needs before saving your project. To reactivate an entity, Control-click the entity in the hierarchy view and select Activate from the contextual menu.\nAdd components to entities\nRealityKit follows a design pattern called Entity-Component-System (ECS). In ECS, you store data on an entity using components and then implement entity behavior by writing systems that use the data from those components. You can add and configure components to entities in Reality Composer Pro, including both built-in components likeParticleEmitterComponent, and custom components that you write and place in the Sources folder of your Reality Composer Pro Swift package. You can also create new components in Reality Composer Pro and edit them in Xcode.\nFor more information about ECS, seeUnderstanding the modular architecture of RealityKit.\nTo add a component to an entity, select that entity in the hierarchy view or 3D view. At the bottom-right of the inspector window, click Add Component. A list of available components appears with New Component at the top. If you select the first item, Reality Composer Pro creates a new component class in the Sources folder, and optionally a new system class. It also adds the component to the selected entity. If you select any other item in the list, it adds that component to the selected entity if it doesn\u2019t already have that component.\n\nCreate or modify entity hierarchies\nReality Composer Pro scenes are hierarchies of RealityKit entities. You can change the relationship between entities in the hierarchy browser except for parts of the hierarchy imported from a.usdzfile, which Reality Composer Pro treats as a read-only file.\nTo change the relationship between entities, or to create a relationship between two currently unrelated entities, use the hierarchy view and drag an entity onto the entity that you want it to be part of. If you want an entity to become a root entity, drag it to the Root transform at the top of the hierarchy view.\nModify or create new materials\nWhen you import a USDZ model into Reality Composer Pro, it creates a RealityKit material for every physically-based rendering (PBR) material the asset contains. Reality Composer Pro displays materials in the hierarchy view just like it displays entities, except it uses a paintbrush icon. Reality Composer Pro doesn\u2019t display materials in the 3D view.\nNote\nThe library in Reality Composer Pro contains materials for several common real-world surfaces like metal, wood, and denim that you can import into your project.\nIf you select a PBR material in the hierarchy view, you can edit it using the inspector. You can replace images, colors, or values for any of the PBR attributes with another image, color, or value of your choosing. Any changes you make to a material affects any entity that\u2019s bound to that material. You can also create new materials from scratch by clicking the Add button (+) at the bottom of the scene hierarchy and choosing Material.\n\nBuild materials in Shader Graph\nPBR materials are great at reproducing real-world surfaces. However, they can\u2019t represent nonrealistic materials like cartoon shaders, and they can\u2019t contain logic. This means that you can\u2019t animate a PBR material or have it react to input from your app.\nReality Composer Pro offers a second type of material called acustom material. You can build and edit custom materials using the Shader Graph tab. Shader Graph provides a tremendous amount of control over materials and allows you to do things that would otherwise require writing Metal shaders. For more information on writing Metal shaders, seeMetal.\nNote\nRealityKit doesn\u2019t represent Reality Composer Pro custom materials as an instance ofCustomMaterial, as you might expect. Instead, RealityKit represents these materials asShaderGraphMaterialinstances.\n\nThe materials you build in the editor can affect both the look of an entity and its shape. If you build a node graph and connect it to the Custom Surface pin on the output node, that node graph controls the surface appearance of the model and roughly equates to writing Metal code in a fragment shader. If you build a node graph and connect it to the Custom Geometry Modifier output pin, those nodes control the shape of the entity, which equates to Metal code running in a vertex shader.\nNodes represent values and operations and serve the same purpose as either a variable or constant, or a function in Metal. If you need the sine of a value, for example, connect the value\u2019s output node to the input pin of aSinnode. Add new nodes to the graph by double-clicking the background of the Shader Graph view or click the New Node button on the right side of the screen.\nImportant\nSome nodes, likeSin, are universal and can be used with either output pin. Other nodes are specific to either the Custom Surface or Geometry Modifier outputs. If a node name starts with Geometry Modifier, you can only connect it to the Geometry Modifier output pin. If the node\u2019s name starts with \u201cSurface\u201d, you can only connect it to the Custom Surface output pin.\nTo unlock the real power of Shader Graph, you need to be able to change values on the material from Swift code. Shader Graph allows you to do this by creatingpromoted inputs, which are parameters you can set and read from Swift to change your material at runtime. If you have a feature that you want to turn on and off, you might create a Boolean input parameter and have conditional logic based on its value. If you want to smoothly interpolate between two colors, you might create aFloatinput parameter and use it to control how to interpolate between the two colors. You can Control-click on a constant node and select Promote to turn it into a promoted input. You can also turn a promoted input back into a constant by Control-clicking it and selecting Demote.\nIf you don\u2019t have an existing constant to promote, you can create new promoted inputs using the inspector. The New Input button only shows up in the inspector when you select a material in the hierarchy view but have no nodes selected in the Shader Graph tab.\n\nTo change the value of an input parameter from Swift code, usesetParameter(name:value:), passing the name of the parameter and the new value. Note that parameter names are case sensitive, so yournamestring must exactly match what you called the parameter in Shader Graph.\nFor examples of Shader Graph use, seeDioramaandHappy Beam.\nUse references to reuse assets\nIf your project has multiple scenes that share assets, you can use references to avoid creating duplicate assets. Areferenceacts like an alias in Finder \u2014 it points to the original asset and functions just as if it were another copy of that asset.\nCreate references using the inspector. By default, the references section is hidden for entities and materials that don\u2019t have any references. To add a new reference to an asset or material that doesn\u2019t have one, choose Reality Composer Pro > Settings and uncheck Hide Empty References.\n\nTo add a reference, click the Add button (+) at the bottom of the references section in the inspector, choose the.usdafile for the scene that contains the asset, then choose the asset you want to link to. After you do that, the selected entity or material becomes a copy of the one you linked to.\nImportant\nIf you make changes to a linked asset, those changes will affect every linked reference.\nPreview scenes on device\nIf you have an Apple Vision Pro connected to your Mac, choose Preview > Play or click the preview button in the Reality Composer Pro toolbar to view your scene on device. The Preview button is the left-most button on the right side of the toolbar \u2014 the one with an Apple Vision Pro icon. If you have multiple Apple Vision Pro devices connected, choose which device to use by clicking the pull-down menu next to the Preview button.\nLoad Reality Composer Pro scenes in RealityKit\nLoading a Reality Composer Pro scene is nearly identical to loading a USDZ asset from your app bundle, except you have to specify the Reality Composer Pro package bundle instead. You typically do this in themakeclosure of aRealityViewinitializer. Reality Composer Pro packages define a global constant that points to its bundle, which is named after the project with \u201cBundle\u201d appended to it. In the default Xcode visionOS template, the Reality Composer Pro project is calledRealityKitContent, so the global bundle variable is calledrealityKitContentBundle:\nNote\nThe code above saves a reference to the root node. This isn\u2019t required, but withRealityView, unlikeARViewon iOS and macOS, you don\u2019t have ready access to the scene content, so it\u2019s often handy to maintain your own reference to the root entity of your scene in your app\u2019s data model.\nWhen RealityKit finishes loading the scene, thescenevariable contains the root entity of the scene you specified. Add it tocontentand RealityKit displays it to the user.\nSee Also\nRealityKit and Reality Composer Pro",
        "https://developer.apple.com/documentation/visionos/building_local_experiences_with_room_tracking": "visionOS\nBuilding local experiences with room tracking\nBuilding local experiences with room tracking\nBuilding local experiences with room tracking\nBuilding local experiences with room tracking\nOverview\nThis sample allows your app to keep track of rooms as discrete, identifiable places, and enables you to provide a customized virtual experience inside a specific room, and to get notified when someone enters or leaves the room. These customizations can be as simple as knowing when to stop room-specific animations, or to support the creation of location-specific virtual content such as in-game treasures, effects, or even portals to virtual worlds that contain other content.\nThis sample demonstrates how to use room tracking by enabling a person to place spheres in a space and continuously query the framework as to whether those spheres are in the same room as the person. As someone moves into, through, and out of the room, ARKit deliversRoomAnchorupdates that represent the latest knowledge of the current room. This structure provides acontains(_:)query method that you use to determine if the spheres are in the current room, and highlight them accordingly.\nThe app has anocclusion mode, in which the room geometry the framework renders is a transparent occluder that hides virtual objects outside the room. It also has awall selection mode, in which someone may select a specific wall for the purpose of replacing it with a video or virtual portal.\nNote\nThis app requires Xcode 16 and visionOS 2 or later, and an Apple Vision Pro. ARKit room tracking isn\u2019t supported in Simulator.\nEnsure all data providers are in an authorized state\nYour app must request permission to use certain visionOS capabilities before being able to access data associated with them. For example, attempting to access theRoomTrackingProviderdisplays a permission sheet asking the user to authorize your app\u2019s access. If the user has previously denied this request, the app displays an error message in the scene. For information about using aRoomTrackingProvider, seeSetting up access to ARKit data. For information about best practices for privacy, seeAdopting best practices for privacy and user preferences.\nNote\nTo use the room tracking capabilities in visionOS in your app, you need to provide theNSWorldSensingUsageDescriptionkey in your app\u2019sInfo.plistalong with a description of why your app uses this feature. This sample already provides this key and description.\nConfigure room tracking\nSet up room tracking by first configuring anARKitSessioninstance, then add aWorldTrackingProviderand aRoomTrackingProviderto the session as shown in the following example:\nIn addition to instantiating the world and room tracking providers in theAppState, you need to create storage for the in-room anchors the app tracks:\nYou also need to create the materials the framework uses to render the in-room anchors:\nAllow a person to place room tracking anchors\nPlacing aroomAnchorobject in the room consists of two processes. The first phase allows the person to review the anchor, which the sample renders as a sphere in front of the device from the person\u2019s perspective:\nThe second phase allows a person to place the sphere (aWorldAnchor) in their surroundings  with a tap gesture. Gestures such as this are SwiftUI view modifiers you apply to the room\u2019sView, as shown below:\nAs a person places spheres in the room, they appear in green to indicate they\u2019re anchors in the current room. If a person leaves the room, all of the room anchors in the previous room dim and become red to indicate a person has left the room. If there are anchors in the room a person enters into, they change color to indicate the person is currently in the room.\nThis changing state and the property of a room beingcurrentis what allows an app to make decisions about what actions, animations, or other processes make sense in a specific location.\nCheck the current room and respond to updates\nAs a person moves from room to room, ARKit\u2019s room tracking process checks to see which room is current and reports back changes to the app through theRoomTrackingProviderpropertyanchorUpdates, which is an asynchronous sequence of all anchor updates. As these updates come in, aTaskview modifier in the app\u2019sWorldAndRoomViewcalls a method that looks for anchors to update, as demonstrated here:\nFind and select walls\nRoom tracking also enables someone to find and select walls in the current room. You can use this as an additional interaction surface, such as creating a \u201cportal\u201d to another virtual space. The process of selecting a wall in a room is split into two modes: anunlocked modewhere actively looking at a specific wall causes ARKit to highlight it in blue, andlocked modewhere a person has selected a wall and it receives continuous updates from theRoomTrackingProvider. Theunlocked moderequires performing a ray cast query in the direction of the a person\u2019s head, which returns the first wall that it hits, as shown here:\nKeep focus on the current room\nRoom tracking operates only in the current room a person is in. If someone leaves one room and enters another, the previous room is no longer valid, and the framework only updates mesh-room associations and plane-room associations for the current room. Only use the current room anchor and discard any noncurrent rooms.\nBe aware of limitations\nClutter in a room, large furniture elements, and very large spaces may interfere with ARKit\u2019s ability to accurately detect walls and fully detect the dimensions of a room. In the case of very large indoor spaces, or in rooms with low-light conditions, the framework may only provide a floor mesh. Additionally, visionOS doesn\u2019t support using room tracking outdoors or when Apple Vision Pro is in Travel Mode. In these cases, there\u2019s no current room. For more information on implementing immersive experiences, see Human Interface Guidelines >Immersive experiences.\nWarning\nBe mindful of how much content you include in immersive scenes that use themixedstyle. Content that fills a significant portion of the screen, even if that content is partially transparent, can prevent the person from seeing potential hazards in their surroundings. If you want to immerse the person in your content, configure your space with thefullstyle. For more information, seeCreating fully immersive experiences in your app.\nSee Also\nARKit",
        "https://developer.apple.com/documentation/visionos/enabling-video-reflections-in-an-immersive-environment": "visionOS\nEnabling video reflections in an immersive environment\nEnabling video reflections in an immersive environment\nEnabling video reflections in an immersive environment\nEnabling video reflections in an immersive environment\nOverview\nRealityKit and Reality Composer Pro provide the tools to build immersive media viewing environments in visionOS. TheDestination Videosample uses these features to build a realistic custom environment called Studio. The environment adds to its realism and makes the video player feel grounded in the space by applying reflections of the player\u2019s content onto the surfaces of the scene.\nRealityKit and Reality Composer Pro support two types of video reflections:\nSpecular reflections provide a direct reflection of the video content, and are typically useful to apply to glossy surfaces like metals and water.\nSpecular reflections provide a direct reflection of the video content, and are typically useful to apply to glossy surfaces like metals and water.\nDiffuse reflections provide a softer falloff of video content, and are useful to apply to rougher, more organic surfaces.\nDiffuse reflections provide a softer falloff of video content, and are useful to apply to rougher, more organic surfaces.\nThis article describes how to adopt reflections in your own environment, and shows how Destination Video\u2019s Studio environment supports these effects to create a compelling media viewing experience.\nDefine a video docking location\nApps that useAVPlayerViewControllerto present video participate in system docking behavior. When you play a full-window video inside an immersive space, the system docks the video screen into a fixed location and presents streamlined playback controls. By default, the system determines the docking location for the scene, but starting in visionOS 2, you can customize this location by specifying a custom docking region.\nThe Studio environment defines a custom docking region that anchors the player to the walkway at the top of the staircase like shown below.\n\nTo create the docking region, the project defines aPlayerentity that contains aDockingRegionComponent. This component defines the bounding region for the player, which has a depth of 0 and uses a fixed 2.4:1 aspect ratio. You configure the docking region\u2019s size through itswidthproperty, and you can optionally specify a preview video to display in the docking region\u2019s space within Reality Composer Pro.\n\nTo provide an optimal viewing experience, the Studio environment minimizes objects between the viewer and the video. Additionally, it provides a comfortable viewing angle to avoid causing strain or discomfort during longer viewing sessions. Using Reality Composer Pro to define the docking region is a great way to visualize how it looks in context, but always review your environment on Apple Vision Pro to get a true sense of layout and scale.\nNote\nReality Composer Pro provides a template to set up a docking region and default video reflection configuration. You can access this template from the Insert menu by selecting Insert > Environment > Video Dock.\nDisplay specular video reflections\nSpecular reflections, like shown below, provide a direct reflection of the video\u2019s content onto surrounding surfaces. You typically apply this type of reflection to glossy surfaces such as metals, mirrors, and water.\n\nTo enable this type of reflection, you define a material with theReflection Specular (RealityKit)node connected and apply it to a surface in your scene. The system automatically calculates the appropriate reflection based on your viewing angle relative to the docking region.\n\nThe output of this node contains the reflected color in the RGB channels, and a blend factor in the alpha channel, which you can use to composite the reflection with your existing material.\nDestination Video uses subtle specular reflections in its custom environment like shown below. Applying specular reflections helps to add depth and space to the experience. To learn more about how the environment uses specular reflections, open the Studio project in Reality Composer Pro to view its configuration.\n\nProvide diffuse video reflections\nDiffuse reflections provide a softer falloff of media content, which can be useful to apply to rougher, more organic surfaces like a concrete or wood floor. The image below shows a diffuse reflection from a video screen.\n\nYou enable diffuse reflections by adding a material on a surface with theReflection Diffuse (RealityKit)node connected.\n\nThis node requires the following inputs:\nThis UV samples the system-generated emitter texture that contains low-frequency light and color information from the docked video. The diffuse reflection node uses the UV to calculate where to show the soft light reflection.\nThis UV samples the provided attenuation mask texture. An attenuation texture contains a soft falloff mask that\u2019s used to shape the light from the emitter. Use a higher bit-depth texture format, such as.exr,to reduce any possible banding artifacts.\nDestination Video\u2019s custom environment applies diffuse reflections to the surfaces immediately surrounding the docked video screen as shown below:\n\nEnabling diffuse reflections enhances the level of immersion by making the video player feel grounded in the experience.\nTo calculate Emitter UVs, iterate over each vertex of the surface mesh, and sample a set number of random points on the docking region. The u-value and v-value of each of the random sample points on the docking region are weighted by measuring both the distance and the angle to the mesh vertex. The resulting emitter UV set is the average of the weighted docking region UV values.\nA visualization of the emitter UVs generated from the docking region.\nAn example that uses a debug texture to show how different colors from the docking region map on to the surface mesh.\nImportant\nThe number of random points sampled from the docking region can have a large impact on the overall computation time when generating emitter UVs. You can configure how many samples to use when calculating emitter UVs with theComputeDiffuseReflectionUVspython script.\nAttenuation UVs are a top-down projection of the attenuation texture onto the input geometry (UV-coordinate system). An attenuation texture contains a soft falloff mask that shapes the light from the emitter.\nA visualization of the attenuation UVs generated from the docking region.\nReality Composer Pro\u2019s default attenuation texture on the visualization.\nThe attenuation texture contains a falloff pattern that shapes the the diffuse reflection on to the surface mesh. The image below shows the default Reality Composer Pro attenuation texture.\n\nThe default falloff pattern doesn\u2019t extend all the way to the edges of the texture. In order to generate the attenuation UV set, calculate the edges of the falloff pattern from the texture. The image below shows the default falloff pattern in a standard UV-coordinate system, with the top-left point equal to(0,0)and the bottom-right point equal to(1,1).\n\nThe following four values define the attenuation UV set:\nThe UV-space value where the sharp line of the falloff pattern starts horizontally.\nThe UV-space value where the sharp line of the falloff pattern ends horizontally.\nThe UV-space value where the sharp line starts vertically.\nThe UV-space value where the falloff pattern ends in black.\nAfter calculating the attenuation texture, map it to the geometry. To visualize the attenuation texture mapping, the image below shows a square red mesh as the custom surface mesh that extends towards the user with sides that are equal to the width of the docking region.\n\nThe attenuation UVs are calculated from mapping the surface mesh, in world space, to the area defined by theuStart,uEnd,vStart, andvEndvalues, in the UV-coordinate space. The image below shows the surface mesh with the attenuation texture applied.\n\nNote\nWhen using theComputeDiffuseReflectionUVspython script for mapping using a custom attenuation texture, you only need to measure the theuStart,uEnd,vStart, andvEndvalues of your attenuation texture. If you\u2019re using the default attenuation texture in Reality Composer Pro, the script uses the default values.\nTo learn more about how the environment sets up and applies diffuse reflections, open the Studio project in Reality Composer Pro to view its configuration.\nSee Also",
        "https://developer.apple.com/documentation/visionos/reducing-the-rendering-cost-of-your-ui-on-visionos": "visionOS\nReducing the rendering cost of your UI on visionOS\nReducing the rendering cost of your UI on visionOS\nReducing the rendering cost of your UI on visionOS\nReducing the rendering cost of your UI on visionOS\nOverview\nProvide an enjoyable experience and maintain a sense of immersion on Apple Vision Pro by minimizing visual choppiness and interaction latency. Performance bottlenecks that prevent timely rendering and responsive feedback interfere with the spatial experience overall and can cause disorientation or discomfort if they persist over an extended period of time. Your app\u2019s processing and its views have an impact on the work the system does and its ability to meet rendering deadlines. To address bottlenecks in your SwiftUI or UIKit interfaces, first analyze your apps performance, then implement some of the following strategies to reduce CPU and GPU overhead. For more information on performance analysis, seeAnalyzing the performance of your visionOS app.\nMinimize transparency in overlapping views\nIf you have overlapping UI windows, avoid adding translucency to them. In SwiftUI, avoid setting the value of your view\u2019sopacity(_:)below 1. In UIKit, avoid setting the value of your view\u2019salphabelow 1. Subviews inheritalpha.\n\nWhen a view with transparent pixels overlaps another view, the system performs extra work to composite those views together. The GPU always renders foreground content, but when foreground content is transparent the GPU also renders the UI behind it. When the foreground content is fully opaque, the GPU doesn\u2019t do this rendering.\nThe Translucent UI Meshes metric in the Core Animation section of the RealityKit Metrics instrument timeline helps you identify translucent UI content your app uses:\n\nOther visual effects that involveoverdraw, the need to draw pixels multiple times to produce a final result, also increase rendering work. In the Shared Space, overdraw can result from interactions with the content from other apps, so minimizing translucent content might have a greater impact. For design guidance, seeHuman Interface Guidelines > Windows. Visual effects can also cause offscreen passes. To reduce offscreen passes, seeReducing the rendering cost of your UI on visionOS.\nReduce the size of static UI views\nTo lower the GPU overhead of static UI content, reduce the size of UI elements in your view hierarchy. Making your UI content appear larger in a space requires rendering more pixels which requires more rendering work. People still have control over re-sizing content, so use sizes that are large enough for people to be comfortable interacting with, but not so large that they require unnecessary demand from the GPU.\nTo identify areas in your app where rendering your static UI content creates a lot of overhead for the GPU, check the RealityKit Metrics instrument for 3D Render GPU bottlenecks. Content you display in 2D windows still renders in a space with a 3D mesh. If you expect people to frequently launch multiple windows, account for the rendering cost of this in your design and profile your app with multiple windows open. For design guidance, seeHuman Interface Guidelines > Spatial layout.\nConsider the impact of dynamic content scaling\nThe system can provide sharper visuals from any angle and distance by altering the resolution of text or vector-based UI content based on where people are looking. Doing so requires drawing content more frequently and at potentially higher scales. SwiftUI and UIKit views enable this by default. To opt in with your custom Core Animation or Core Graphics rendering, enable thewantsDynamicContentScalingproperty of anyCALayerobject. Consider the performance and memory trade-offs and profile your app with this feature on and off to determine if the cost is worth the quality improvement.\nFor more information on dynamic content scaling, seeDrawing sharp layer-based content in visionOSand the section on Dynamic content scaling in the videoExplore rendering for spatial computing.\nReduce redraw and offscreen rendering\nThe performance cost of numerous redraws and offscreen render passes adds up. Offscreen passes can also contribute to additional overdraw. Some complex renderers require offscreen passes but you can avoid them in many cases. Learn more about offscreen render passes inCustomizing Render Pass Setup. To reduce the number of redraw and offscreen render passes your app performs:\nLower the update rates of animations.\nLower the update rates of animations.\nPause or stop animations.\nPause or stop animations.\nReduce the number of different views your app uses.\nReduce the number of different views your app uses.\nAvoid layouts that require redrawing overlapping layers when redrawing a different layer.\nAvoid layouts that require redrawing overlapping layers when redrawing a different layer.\nUse more efficient alternatives thanUIVisualEffectView. For example, use background colors in your SwiftUI and UIKit apps.\nUse more efficient alternatives thanUIVisualEffectView. For example, use background colors in your SwiftUI and UIKit apps.\nSimilar to other Apple platforms, app updates done in response to input events, timed animations, or other sources initiate UI redraw work in the render server. On visionOS, dynamic content scaling can cause redraw to be frequent in the absence of these updates. This makes it more important to reduce updates and animation timers.\nTo reduce the cost of redraws and render passes:\nAvoid large layers that might require redrawing a large number of pixels.\nAvoid large layers that might require redrawing a large number of pixels.\nMinimize your use of vector-based media content during active scrolling and animated interactions. Animating large vector-based media content is often expensive.\nMinimize your use of vector-based media content during active scrolling and animated interactions. Animating large vector-based media content is often expensive.\nReduce the resolution, type, and number of images in your content that scrolls or animates during interactions.\nReduce the resolution, type, and number of images in your content that scrolls or animates during interactions.\nThe number of offscreen render passes can negatively impact performance. Visual effects, like shadows, masking, rounded rectangles, blurs, and vibrancy increase the number of offscreen passes the system requires to render your content.\nTo identify frequent or expensive UI redraws, check the RealityKit Metrics instrument for Core Animation Encoding (CPU), Core Animation GPU (GPU), Core Animation Server Update (CPU), and Core Animation Client Commit (CPU) bottlenecks.\nMinimize view layouts and updates in your SwiftUI, UIKit, or custom Core Animation and Core Graphics rendering when you see a bottleneck related to UI redraw to make your app more efficient for the system to render.\n\nReview the Offscreen Prepares and Render Passes metrics in the Core Animation Render section of the RealityKit Metrics Instrument to identify the number of potential offscreen render passes and total render passes the render server does on behalf of your app. The section includes metrics on render passes for both offscreen visual effects and for each region of UI content to redraw.\nTo learn more about these offscreen passes, watch the videoDemystify and eliminate hitches in the render phase.\nAvoid expensive updates on the main thread\nTo avoid visible hitches and delays while people scroll and resize, reduce time consuming layout and view creations that occur on the app\u2019s main thread. The SwiftUI Instrument template includes the View Body, View Properties, Core Animation Commits, Time Profiler, and Hangs instruments. Use the data these instruments collect to debug expensive commits and updates on your app\u2019s main thread. The Core Animation Commits and Hangs instruments can help you locate areas of expensive work and updates on the app\u2019s main thread that cause rendering delays:\n\nTo learn more about analyzing Hangs with Instruments, watchAnalyze hangs with Instruments.\nThe View Body and View Properties instruments provide metrics on the number of view body creations and property updates that occur:\n\nFor debugging purposes, you can add a call to the internal methodSelf._printChanges()from the body of the view to log information about the property that caused the view to update.\nSee Also",
        "https://developer.apple.com/documentation/visionos#Xcode-and-Simulator": "visionOS\nOverview\nvisionOS is the operating system that powers Apple Vision Pro. Use visionOS together with familiar tools and technologies to build immersive apps and games for spatial computing.\n\nDeveloping for visionOS requires a Mac with Apple silicon. Create new apps using SwiftUI to take full advantage of the spectrum of immersion available in visionOS. If you have an existing iPad or iPhone app, add the visionOS destination to your app\u2019s target to gain access to the standard system appearance, and add platform-specific features to create a compelling experience. To provide continuous access to your content in the meantime, deliver a compatible version of your app that runs in visionOS.\nExpand your app into immersive spaces\nStart with a familiar window-based experience to introduce people to your content. From there, addSwiftUIscene types specific to visionOS, such as volumes and spaces. These scene types let you incorporate depth, 3D objects, and immersive experiences.\nBuild your app\u2019s 3D content withRealityKitand Reality Composer Pro, and display it with aRealityView. In an immersive experience, useARKitto integrate your content with the person\u2019s surroundings.\n\nExplore new kinds of interaction\nPeople can select an element by looking at it and tapping their fingers together. They can also pinch, drag, zoom, and rotate objects using specific hand gestures.SwiftUIprovides built-in support for these standard gestures, so rely on them for most of your app\u2019s input. When you want to go beyond the standard gestures, useARKitto create custom gestures.\nTap to select\nPinch to rotate\nManipulate objects\nCreate custom gestures\nDive into featured sample apps\nExplore the core concepts for all visionOS apps with Hello World. Understand how to detect custom gestures using ARKit with Happy Beam. Discover streaming 2D and stereoscopic media with Destination Video. And learn how to build 3D scenes with RealityKit and Reality Composer Pro with Diorama and Swift Splash.\nTopics\nApp construction\nDesign\nSwiftUI\nRealityKit and Reality Composer Pro\nARKit\nVideo playback\nXcode and Simulator\nPerformance\niOS migration and compatibility\nEnterprise APIs for visionOS\nvisionOS\nOverview\nExpand your app into immersive spaces\nExplore new kinds of interaction\nDive into featured sample apps\nTopics",
        "https://developer.apple.com/documentation/visionos/implementing-object-tracking-in-your-visionos-app": "visionOS\nImplementing object tracking in your visionOS app\nImplementing object tracking in your visionOS app\nImplementing object tracking in your visionOS app\nImplementing object tracking in your visionOS app\nOverview\nWhen you implement object tracking in your visionOS app, you can seamlessly integrate real-world objects in people\u2019s surroundings to enhance their immersive experiences. By tracking the 3D position and orientation of an object, or several objects, your app can augment them with virtual content.\nYou can use object tracking to provide virtual interactions with objects in a person\u2019s surroundings, such as:\nGuiding someone through using an item\u2019s features, reading about its history, or learning about its behaviors when they look at it in their surroundings.\nGuiding someone through using an item\u2019s features, reading about its history, or learning about its behaviors when they look at it in their surroundings.\nHelping people troubleshoot issues with household items and appliances with a virtual manual.\nHelping people troubleshoot issues with household items and appliances with a virtual manual.\nCreating an immersive storytelling experience to make collectables and toys come to life.\nCreating an immersive storytelling experience to make collectables and toys come to life.\nTo integrate object tracking into your app, you start with a 3D model of a physical object, train a machine learning model in Create ML with that 3D model asset to obtain a reference object file, and then use the resulting reference object file to track the physical object in your app. The reference object file is a file format with a.referenceobjectextension, specifically for object tracking in visionOS.\n\nImplementing object tracking requires an Apple Vision Pro with visionOS 2 or later, and a Mac with Apple silicon and macOS 15 or later for the machine learning training in Create ML.\nEnsure your objects are suitable for object tracking\nObject tracking performs optimally for a specific set of object characteristics. For object tracking to work best in your app, make sure your object is rigid, nonsymmetrical, and stationary.\nSelect an object that maintains its shape and appearance during tracking. For example, a pair of scissors is challenging to track because it changes shape while a person uses it.\nSelect an object with a nonsymmetrical shape or texture, so that when you rotate the object, it doesn\u2019t have the same appearance from different angles. For instance, a globe has a symmetrical shape, but has a nonsymmetrical texture on all sides, making it a suitable object. In contrast, a styrofoam cup has the same appearance on all sides when you rotate it, making it challenging to track.\nSelect an object that\u2019s mostly stationary in a person\u2019s surroundings. If you\u2019re tracking a moving object, there can be a delay in following its position. For example, a pickleball racket constantly moves in different directions while a person plays with it, making it challenging to track.\nObtain a 3D model of your object\nYou useCreate MLto begin the machine learning training to obtain your reference object file. Create ML requires a 3D model asset in the USDZ file format that represents your real-world object. You can obtain your 3D model using computer-aided design (CAD) software to accurately model an object\u2019s geometry and apply physically based rendering (PBR) materials to it, and save it in the USDZ file format. Using this method, the 3D model can realistically represent objects that consist of multiple parts made from different materials, like glass, metal, plastic, wood, and other common materials. This method is helpful for capturing objects that are entirely or partly transparent, shiny, or reflective. The better the 3D model represents the appearance of the physical object, the better the quality of tracking is in visionOS.\nAnother way to create your 3D model is by using the Object Capture feature in the Reality Composer app in iOS or iPadOS. You can use your iPhone or iPad to capture images of an object, and then save the USDZ file to import into your app. For more information about using the Object Capture feature to create a 3D model, seeMeet Object Capture for iOSandScanning objects using Object Capture.\nBefore beginning the training process in Create ML with the 3D model asset, keep the following guidelines in mind to ensure it works well for object tracking in visionOS:\nEnsure the 3D model is as photorealistic as possible \u2014 essentially a digital twin of your real-world object.\nEnsure the 3D model is as photorealistic as possible \u2014 essentially a digital twin of your real-world object.\nEnsure the scale of the 3D model is as precise as possible and matches its specified units. If the scale doesn\u2019t match the real-world object, the augmentation appears offset in the viewing direction, and may appear either in front of or behind the object.\nEnsure the scale of the 3D model is as precise as possible and matches its specified units. If the scale doesn\u2019t match the real-world object, the augmentation appears offset in the viewing direction, and may appear either in front of or behind the object.\nNote\nWhile training the machine learning model with the 3D model asset, Create ML ignores any animations, virtual cameras, and lights within the asset, treating them as static.\nTrain a machine learning model with the 3D model asset in Create ML\nObject tracking requires a reference object file to track the spatial location and orientation of the corresponding real-world object. You use Create ML to train a machine learning model to create a reference object file unique to your object. The training of machine learning models with your 3D asset and the creation of the reference object file both run locally on your Mac.\nTo set up the training:\nOpen Xcode and choose Xcode > Open Developer Tool > Create ML.\nOpen Xcode and choose Xcode > Open Developer Tool > Create ML.\nIn the dialog that appears, click New Document.\nIn the dialog that appears, click New Document.\nIn the Choose a Template dialog, select the Spatial category in the left pane, select the Object Tracking template, and click Next.\nIn the Choose a Template dialog, select the Spatial category in the left pane, select the Object Tracking template, and click Next.\nEnter your project name and other information, and click Next.\nEnter your project name and other information, and click Next.\nSelect a location for your project, and click Create.\nSelect a location for your project, and click Create.\nCreate ML opens a training configuration view with an empty 3D viewport. Drag the USDZ file of your 3D model asset into the 3D viewport.\nCreate ML opens a training configuration view with an empty 3D viewport. Drag the USDZ file of your 3D model asset into the 3D viewport.\nThe 3D viewport is an interactive space where you can view your 3D model asset from different angles. After it appears in the viewport, check the appearance of the 3D model asset and confirm that it matches the absolute dimensions of your real-world object. Also make sure that the dimensions of the 3D model asset at the bottom right of the viewport match the actual dimensions of your object. If the scale doesn\u2019t match, one option is to use Reality Composer Pro to rescale the 3D model and then add the adjusted USDZ file to Create ML.\n\nThe next step is to select the best viewing angle for your real-world object. Consider how people view and interact with the object in your app, and decide which angle you need for tracking it. The \u201cViewing angles\u201d setting appears below the 3D viewport, and has three viewing angles you can use: All Angles, Upright, or Front. It\u2019s important to choose the best option for your object.\n\nThe All Angles option includes views from every angle. It works best for tracking objects that have a distinct and unique appearance from all sides, such as a patterned Christmas ornament that people see from all sides as it hangs on a tree.\nThe Upright option works only for tracking objects that stand upright on a surface, such as a microscope that sits on a counter and stays in the same position as people interact with it. This option disables tracking from the bottom viewing angle.\nThe Front option works only for tracking objects that stand upright on a surface where the back of the object isn\u2019t visible, such as a coffee machine that sits on a counter while people operate it from the front. This option disables tracking from both the bottom and rear viewing angles.\nNote\nOnly choose the All Angles option if you want to track your object from all sides. The more restricted the viewing angle is, the more accurate the object tracking is in visionOS.\nIf there\u2019s an object in a person\u2019s surroundings that\u2019s similar to the object you want to track, the object-tracking feature might recognize it and track it instead of your object. To prevent this from happening, add the similar object as a negative example when training the machine learning model with your reference object. Below the 3D viewport, choose More Options > Objects to avoid. Use this section to add USDZ samples of similar items to ensure the machine learning model doesn\u2019t identify them as the object you want to track.\n\nCreate ML supports training multiple machine learning models in the same object-tracking project. In the Model Sources section in the left pane, you can click the Add button (+) to add more 3D model assets to your Create ML project. Use this feature to track multiple objects in your app at the same time.\n\nNote\nYou can track up to 10 different reference objects simultaneously without an impact to performance.\nAfter inspecting your 3D model asset and configuring the training settings, click Train to begin the training process. A progress bar indicates the amount of time until the machine learning training is complete. The machine learning training can take a few hours, depending on the configuration of your Mac. A more advanced processor and additional RAM significantly improve the training time.\nExport the reference object file\nWhen training is complete, Create ML provides the reference object file for you to use in your app. Click the Output tab and save the resulting reference object file.\nThe reference object file contains the machine learning model you trained, packaged with the 3D model asset, in the USDZ file format. You can use the USDZ file for visualizing the tracking quality by rendering it as an overlay on the real-world object, and as a guide for adding immersive effects. The USDZ file may take up a lot of space in your app if your 3D model asset is large, so you can remove it from the reference object file if you need to optimize space.\nYou use the Reference Object Compiler in Xcode to remove the USDZ data from the reference object file during the build process. Select your project in Xcode, click the Build Settings tab, and enable the Strip USDZ Files from Reference Object option. This setting contains theREFERENCEOBJECT_STRIP_USDZbuild flag. The default setting of the flag isNo, so Xcode copies any reference object files you add to the project as-is unless you change the setting.\n\nIntegrate the reference object file into your app\nAfter you generate the reference object file, you can set up object tracking in your app using Reality Composer Pro, RealityKit, or ARKit. For more information about each of these methods, seeUsing a reference object with Reality Composer Pro,Using a reference object with RealityKit, andUsing a reference object with ARKit.\nNote\nObject tracking works only in anImmersiveSpacewithin Xcode. Attempting to use object tracking in a window or volume results in a silent failure.\nFor more information about object tracking, seeExplore object tracking for visionOS. For an example of using ARKit for object tracking, seeExploring object tracking with ARKit.\nTopics\nObject tracking within an app\nSee Also\nRealityKit and Reality Composer Pro",
        "https://developer.apple.com/documentation/visionos#Overview": "visionOS\nOverview\nvisionOS is the operating system that powers Apple Vision Pro. Use visionOS together with familiar tools and technologies to build immersive apps and games for spatial computing.\n\nDeveloping for visionOS requires a Mac with Apple silicon. Create new apps using SwiftUI to take full advantage of the spectrum of immersion available in visionOS. If you have an existing iPad or iPhone app, add the visionOS destination to your app\u2019s target to gain access to the standard system appearance, and add platform-specific features to create a compelling experience. To provide continuous access to your content in the meantime, deliver a compatible version of your app that runs in visionOS.\nExpand your app into immersive spaces\nStart with a familiar window-based experience to introduce people to your content. From there, addSwiftUIscene types specific to visionOS, such as volumes and spaces. These scene types let you incorporate depth, 3D objects, and immersive experiences.\nBuild your app\u2019s 3D content withRealityKitand Reality Composer Pro, and display it with aRealityView. In an immersive experience, useARKitto integrate your content with the person\u2019s surroundings.\n\nExplore new kinds of interaction\nPeople can select an element by looking at it and tapping their fingers together. They can also pinch, drag, zoom, and rotate objects using specific hand gestures.SwiftUIprovides built-in support for these standard gestures, so rely on them for most of your app\u2019s input. When you want to go beyond the standard gestures, useARKitto create custom gestures.\nTap to select\nPinch to rotate\nManipulate objects\nCreate custom gestures\nDive into featured sample apps\nExplore the core concepts for all visionOS apps with Hello World. Understand how to detect custom gestures using ARKit with Happy Beam. Discover streaming 2D and stereoscopic media with Destination Video. And learn how to build 3D scenes with RealityKit and Reality Composer Pro with Diorama and Swift Splash.\nTopics\nApp construction\nDesign\nSwiftUI\nRealityKit and Reality Composer Pro\nARKit\nVideo playback\nXcode and Simulator\nPerformance\niOS migration and compatibility\nEnterprise APIs for visionOS\nvisionOS\nOverview\nExpand your app into immersive spaces\nExplore new kinds of interaction\nDive into featured sample apps\nTopics",
        "https://developer.apple.com/documentation/visionos/positioning-and-sizing-windows": "visionOS\nPositioning and sizing windows\nPositioning and sizing windows\nPositioning and sizing windows\nPositioning and sizing windows\nOverview\nvisionOS and macOS enable people to move and resize windows. In some cases, your app can use scene modifiers to influence a window\u2019s initial geometry on these platforms, as well as to specify the strategy that the system employs to place minimum and maximum size limitations on a window. This kind of configuration affects both windows and volumes, which are windows with thevolumetricwindow style.\nYour ability to configure window size and position is subject to the following constraints:\nThe system might be unable to fulfill your request. For example, if you specify a default size that\u2019s outside the range of the window\u2019s resizability, the system clamps the affected dimension to keep it in range.\nThe system might be unable to fulfill your request. For example, if you specify a default size that\u2019s outside the range of the window\u2019s resizability, the system clamps the affected dimension to keep it in range.\nAlthough you can change the window\u2019s content, you can\u2019t directly manipulate window position or size after the window appears. This ensures that people have full control over their workspace.\nAlthough you can change the window\u2019s content, you can\u2019t directly manipulate window position or size after the window appears. This ensures that people have full control over their workspace.\nDuring state restoration, the system restores windows to their previous position and size.\nDuring state restoration, the system restores windows to their previous position and size.\nNote\nWindows in iPadOS occupy the full screen, or share the screen with another window in Slide Over or Split View. You can\u2019t programmatically affect window geometry on that platform.\nSpecify initial window position\nmacOS\nvisionOS\nIn macOS, the first time your app opens a window from a particular scene declaration, the system places the window at the center of the screen by default. For scene types that support multiple simultaneous windows, the system offsets each additional window by a small amount to avoid fully obscuring existing windows.\nYou can override the default placement of the first window in macOS by applying thedefaultPosition(_:)scene modifier to indicate where to place the window relative to the screen bounds. For example, you can request that the system place a new window in the bottom trailing corner of the screen.\nThe system aligns the point in the window that corresponds to the specifiedUnitPointwith the point in the screen that corresponds to the same unit point. You can use a built-in unit point, likebottomTrailingin the above example, or define a custom one.\nYou can also usedefaultWindowPlacement(_:)to place windows.\nIn visionOS, the system places new windows automatically depending on the situation:\nWhen someone first launches an app from the Home View, the system places the app\u2019s window where they\u2019re looking.\nWhen someone first launches an app from the Home View, the system places the app\u2019s window where they\u2019re looking.\nWhen a running app opens a new window, the system places the new window in front of one of the app\u2019s existing windows, offsetting each additional window by a small amount to avoid fully obscuring existing windows.\nWhen a running app opens a new window, the system places the new window in front of one of the app\u2019s existing windows, offsetting each additional window by a small amount to avoid fully obscuring existing windows.\nYou can override the default placement of the window by applying thedefaultWindowPlacement(_:)scene modifier to indicate where to place the window. For example, you can request that the system place a new window on the trailing edge of the existing window.\nUse one of theWindowPlacement.Positionenumerations to choose the position of the window.\nSpecify initial window size\nYou can indicate a default initial size for a new window that the system creates from aScenedeclaration by applying one of the default size scene modifiers, likedefaultSize(width:height:). For example, you can request that new windows that aWindowGroupgenerates occupy 600 points in the x-dimension and 400 points in the y-dimension.\nThe system might clamp the actual size of the window, depending on both the window\u2019s content and resizability settings.\nSpecify window resizability\nBoth macOS and visionOS provide interface controls that enable people to resize windows within certain limits. For example, people can use the control that appears when they look at the corner of a visionOS window to resize a window on that platform.\nYou can specify how the system limits window resizability. The default resizability for all scenes isautomatic. With that strategy,Settingswindows use thecontentSizestrategy, where both the minimum and maximum window size match the respective minimum and maximum sizes of the content that the window contains. Other scene types usecontentMinSizeby default, which retains the minimum size restriction, but doesn\u2019t limit the maximium size.\nYou can specify one of these resizability strategies explicitly by adding thewindowResizability(_:)scene modifier to a scene. For example, people can resize windows from the following window group to between 100 and 400 points in both dimensions because the frame modifier imposes those bounds on the content view:\nYou can take this even further and enforce a specific size for a window with content that has a fixed size.\nSpecify a volume size\nWhen you create a volume, which is a window with thevolumetricstyle, you can specify the volume\u2019s size using one of the three-dimensional default size modifiers, likedefaultSize(width:height:depth:in:). The following code creates a volume that\u2019s one meter on a side:\nThe volume maintains this size for its entire lifetime. People can\u2019t change the size of a volume at runtime.\nAlthough you can specify a volume\u2019s size in points, it\u2019s typically better to use physical units, like the above code, which specifies a size in meters. This is because the system renders a volume with fixed scaling rather than dynamic scaling, unlike a regular window, which means the volume appears more like a physical object than a user interface. For information about the different kinds of scaling, seeSpatial layout.\nSee Also\nSwiftUI",
        "https://developer.apple.com/documentation/visionos/destination-video": "visionOS\nDestination Video\nDestination Video\nDestination Video\nDestination Video\nOverview\nDestination Video is a multiplatform video-playbackSwiftUIapp for iOS, iPadOS, macOS, tvOS, and visionOS. People get a familiar media-browsing experience navigating the library\u02bcs content and playing videos they find interesting.\nThe sample uses theTabViewstructure in SwiftUI to create an immersive, full-screen browsing experience with rich navigation hierarchy. While the app shares many of its views across platforms, it leverages platform-specific features to create a playback experience native to each platform. For example, it uses the SwiftUI window and scene customization APIs to create a more engaging and natural experience in macOS. This sample also demonstrates how to useSwiftDatato persist app data in a SwiftUI app.\nIn visionOS, the sample demonstrates how to play video within an immersive environment configured withReality Composer Pro. It also uses theGroup Activitiesframework to enable shared viewing experiences.\nImplement tab navigation\nDestination Video uses tab navigation with thesidebarAdaptablestyle, which optimizes the content browsing experience for each platform. In iPadOS, theTabViewwithsidebarAdaptablestyle allows people to toggle between the sidebar and tab bar. The full-screen browsing experience of a tab bar brings content to the forefront while the sidebar allows for easy access to deeper navigation hierarchy.\niPadOS\niOS\nmacOS\ntvOS\nvisionOS\n\n\n\nTo implement tab navigation, first declare aTabViewwith an explicit selection value using theinit(selection:content:)initializer. Add tabs within aTabViewby initializingTabstructures. Destination Video uses theinit(_:systemImage:value:content:)initializer to create each tab, then groups tabs within aTabSectionto declare a secondary tab hierarchy in theTabView.\nYou can also enable customization by adding thetabViewCustomization(_:)modifier to theTabViewand thecustomizationID(_:)modifier to each tab. Customization in Destination Video allows people to drag tabs from the sidebar to the tab bar, hide nonessential tabs, and rearrange tabs in the sidebar.\nFor more information, seeEnhancing your app\u2019s content with tab navigation.\nCustomize windows in macOS\nIn macOS, the app supports multiple windows including a main window that shows the video collections and a separate video player window. You can customize the appearance and function of each window to create a more engaging experience.\n\nThe main window displays the app content \u2014 collections of videos \u2014 in aTabViewnavigation presented as a sidebar. Because the app doesn\u2019t contain any additional toolbar items and the sidebar provides a visual indication of where a person is in the navigation hierarchy, the toolbar isn\u2019t needed and unnecessarily takes up space. This sample removes the toolbar title and background using thetoolbar(removing:)andtoolbarBackgroundVisibility(_:for:)modifiers. This creates a full-window browsing experience for Destination Video running in macOS.\nOther window customizations in Destination Video include extending a window\u2019s drag region, participating in a window\u2019s zoom action, and modifying a window\u2019s state restoration behavior. For more information, seeCustomizing window styles and state-restoration behavior in macOS.\nDisplay horizontally scrollable cards in tvOS\nDestination Video presents video cards in a horizontally scrollable list in the Watch Now tab. When a person taps on a video card, the app navigates to a view that shows detailed information about the video. In tvOS, each card implements thecardbutton style. When a person hovers on a card, it fully scales and lifts up.\nThis sample prevents the scroll view from clipping its content when the card expands using thescrollClipDisabled(_:)modifier. Additionally, this sample provides a title for the list by placing theScrollViewwithin aSectioncontainer and passing the title into theinit(content:header:)initializer. This allows the title to also lift and move as the card expands and lifts upon when a person hovers on it.\nFor more information about displaying content in tvOS, seeCreating a tvOS media catalog app in SwiftUI.\nPresent an immersive space\nBuilding video playback apps for visionOS provides new opportunities to enhance the viewing experience beyond the bounds of the player window. To add a greater level of immersion, this sample presents an immersive space that displays a scene around a person as they watch the video.\n\nIt defines the immersive space in theDestinationVideoapp structure.\nTheImmersiveSpacepresents an instance ofImmersiveEnvironmentView, which maps a texture to the inside of a sphere that it displays around a person. The app presents it using the.progressiveimmersion style, which lets people change the amount of immersion they experience by turning the Digital Crown on the device.\nPlay video in a full-window player\nOne of the most exciting features of visionOS is its ability to play 3D video along with Spatial Audio, which adds a deeper level of immersion to the viewing experience. Playing 3D content in your app requires that you displayAVPlayerViewControllerfull window. When you present the player this way, the system automatically docks it into the ideal viewing position, and presents streamlined playback controls that keep the person\u2019s focus on the content.\n\nNote\nIn iOS or tvOS, you typically present video in a full-screen presentation using thefullScreenCover(isPresented:onDismiss:content:)modifier. This API is available in visionOS; however, the recommended way to present the player for full-window playback is to set it as the root view of your app\u2019s window group.\nDestination Video\u2019sContentViewdisplays the app\u2019s library by default. It observes changes to the player model\u2019spresentationproperty, which indicates whether the app requests inline or full-window playback. When the presentation state changes tofullWindow, the view redraws the UI to display the player view in place of the library.\nWhen someone selects the Play Video button on the detail view, the app calls the player model\u2019sloadVideo(_: presentation:)method requesting thefullWindowpresentation option.\nAfter the player model successfully loads the video content for playback, it updates itspresentationvalue tofullWindow, which causes the app to replaceDestinationTabswithPlayerView.\nTo dismiss the full-window player in visionOS, people tap the Back button in the player UI. To handle this action, the app\u2019sPlayerViewControllerDelegatetype defines anAVPlayerViewControllerDelegateobject that handles the dismissal.\nWhen the delegate receives this call, it clears the media from the player model and resets the presentation state back to its default value, which results in the Destination Video app redisplaying theDestinationTabsview.\nConfigure the Spatial Audio experience\nMedia playback apps require common configuration of their capabilities and audio session. In addition to performing the steps outlined inConfiguring your app for media playback, Destination Video also adopts newAVAudioSessionAPI to customize a person\u2019s Spatial Audio experience.\nAfter the app successfully loads a video for playback, it configures the Spatial Audio experience for the current presentation. For the inline player view, it sets the experience to a small, focused sound stage where the audio originates from the location of the view. When displaying a video full window, it sets the experience to a large, fully immersive sound stage.\nCustomize an environment using RealityKit and Reality Composer Pro\nIn visionOS, Destination Video provides a custom environment, called Studio.\nTo optimize the viewing experience in the Studio environment, this sample implements the following:\nCustomizes the docking location for the video player in a custom environment.\nEnhances the reflections of the video content on glossy surfaces in the surrounding environment.\nEnhances the reflections of the video content on organic surfaces in the surrounding environment.\nConfigures the virtual scene lighting.\nApplies reverb for enhanced audio immersion.\nIn visionOS, a person can select the environment in which they watch a video by tapping on the environment picker menu presented byAVPlayerViewController. The Studio environment has light and dark variants. This sample adds them to the list of environments that appear in the environment picker menu using theimmersiveEnvironmentPicker(content:)modifier.\nFor more information, seeBuilding an immersive media viewing experienceandEnabling video reflections in an immersive environment.\nProvide a shared viewing experience\nOne of the best ways to enhance your app\u2019s playback experience is to make that experience shareable with others. You can use theAVFoundationand theGroup Activitiesframeworks to buildSharePlayexperiences that bring people together even when they can\u2019t be in the same location.\nThe Destination Video app creates an experience where people can watch videos with others across devices and platforms. It defines a group activity calledWatchingActivitythat adopts theGroupActivityprotocol.  When people have a FaceTime call active and they play a video in the full-window player, it becomes eligible for playback for everyone on the call.\nThe app\u2019sWatchingCoordinatoractor manages Destination Video\u2019s SharePlay functionality. It observes the activation of newWatchingActivitysessions. After aWatchingActivitysession starts, theWatchingCoordinatorsets theGroupSessioninstance on the player object\u2019sAVPlaybackCoordinator.\nWith the player configured to use the group session, when the app loads new videos, they become eligible to share with people in the FaceTime call.\nSee Also",
        "https://developer.apple.com/documentation/visionos/understanding-transforms": "visionOS\nUsing transforms to move, scale, and rotate entities\nUsing transforms to move, scale, and rotate entities\nUsing transforms to move, scale, and rotate entities\nUsing transforms to move, scale, and rotate entities\nOverview\nRealityKitEntityobjects exist in a tree, and each entity can have any number of subentities. (The entities themselves can standalone, or can be in a single container.) Every entity in the tree stores its own transform component. The transform contains thetranslation,scale, andorientationrelative to its container entity. Therootof each tree is an entity without a container entity.\nEach entity exists in its own coordinate system that defines the origin and orientation of the three ordinal directions (the x, y, and z axes). The coordinate system is relative to its container coordinate system and is defined by its transform.\nArrange entities with transforms\nA root entity has no parent entity. Its location in the scene is either controlled by SwiftUI or placed via aSpatialTrackingSession. SwiftUI provides a root entity for the volume defined by theRealityView. The root entity defines the root coordinate system.\nNote\nIn addition to a spatial tracking session, apps can use anARSessionwith any number of data providers. The available list can be found in the typeDataProvider, and a full list of anchor types is found inAnchoringComponent.Target.\nEach entity added to the tree adds a new coordinate system defined by itstransformand is relative to its container entity. Each of the coordinate systems relate to each other by the hierarchy of entities and their transforms. For example a hierarchy of entities built with this code:\nThis reality view has three entitiesB,A, and the root entity. These three entities form a tree, with one root entity at the center of the reality view\u2019s volume. Entity A is a subentity of the root, and B is a subentity of A.\n\nThe reality view provides the root entity, which is located at the center of a volumetric window or near the floor in an immersive space. Use theadd(_:Entity)method on thecontentsupplied by the reality view to add entities as subentites of that root entity. The coordinate system defined byBis0.1units along thex-axisof the coordinate system defined byA. The coordinate system defined byAis0.05units along thex-axisdefined by the root. With three entities there are three coordinate systems.\n\nIn this example there are two cubes. Each cube has eight corners, and each corner is0.025units away from the origin. The cubes appear in different locations in the scene because the system applies thetransformto each corner of the cubes moving them from the local coordinate system (also calledmodel space) to the world coordinate system. For example, the top, right, forward corner of the cube is at{0.025, 0.025, 0.025}inmodel space. The entity is translated by{0.05, 0.0, 0.0}The top-right-forward corner is then at{0.075, 0.025, 0.025}.\nBuild a simple entity to experiment with\nTo be visible, an entity must have aMeshDescriptorand aMaterial. AMeshDescriptorcontains the description of a mesh. In this case, the mesh contains all of the vertices and how they connect into triangles. A Material specifies the color and appearance of the entity.\nThe previous example usedgenerateBox(size:)to generate the mesh. This convenience obscures what the transform does. The remaining examples use a mesh built from scratch.\nAll entities have a coordinate space, often calledmodel space. This coordinate system determines the location of thevertices.\nThe code below builds an entity with the following properties:\nThe entity has one material.\nThe entity has one material.\nThe mesh has 8 vertices and 12 triangles. Each vertex is one corner of the cube. Each triangle is one half of each side and involves three of the vertices. There are six sides, with two triangles each, for a total of 12 triangles. These vertices are in the model space coordinate system. This function builds the entity.\nThe mesh has 8 vertices and 12 triangles. Each vertex is one corner of the cube. Each triangle is one half of each side and involves three of the vertices. There are six sides, with two triangles each, for a total of 12 triangles. These vertices are in the model space coordinate system. This function builds the entity.\nNote\nFor more information about constructing meshes, seeMeshDescriptor. When you set thetransformon an entity, the system transforms the mesh vertices to the new coordinate system.\nAdd the cube entity to a reality view\nYou add thecubeentity to the volumetric window via SwiftUI like this:\nThe cube entity appears at the center of the volume, the origin of the volume\u2019s root entity.\nMove the cube with a transform\nTo move the cube use theTransformcomponent with thetranslationargument:\nApplying thisTransformto the cube moves all eight vertices in thexdirection by0.1.\nThe system moves the entity from its \u2018model space\u2019 origin to the location in world space. To achieve that effect, RealityKit performs some linear algebra behind the scenes to \u2018transform\u2019 the points into world space. The left matrix is theTransformconverted to a matrix. The right vertex is the list of vertices. Here is the full multiplication for the transform and the first vertex.\n\n\nThe left matrix is a direct representation of theTransformyou made earlier and applied to thecube. The right matrix is the first vertex from the cube represented by a vector with1.0in the last position. Performing that multiplication (thedot(_:_:)product of each row of the matrix with the vertex) yields:\n\nThe net effect is that the new vertices have0.1added to theirxcomponent. This approach generalizes to all other forms of transformation that you use to manipulate entities in RealityKit:\nScale the cube with a transform\nTo scale an entity use thetransformproperty. To apply a uniform scale of 2 to the entity change the code, like this:\nThat yields a matrix multiplication that looks like this:\n\nAfter the multiplication yields a transformed vertex like this:\n\nAfter multiplying all of the vertices by the scale matrix, the cube is twice as large in each direction (0.2versus0.1):\nCombine transforms\nThese two operations combine into a single operation with theTransformtype like this:\nThat transform yields a matrix multiplication for all the vertices, laid out as column vectors. The multiplication looks like this:\n\nThe order is important: scale first then translate.\nImportant\nMultiplying matrixes isn\u2019t commutative, which means thatA*Bis not equal toB*A.\nMultiplying these two transformation matrices in the order shown above yields this result:\n\nThe result scales the model by2uniformly and translates the model by0.1in thexdirection:\nSwitching that order yields a different matrix:\n\nThis resulting matrix yields a similar uniform scale of2, but the translation is scaled by2as well. The net result of this matrix is to scale the model uniformly by2and move it in the positivexdirection by0.2:\nImportant\nMatrix multiplication is associative, which means that you can move the parenthesis around. SoA*B*Ccan be done asA*  (B*C)  or (A*B) *C. This allows thetransformto be one matrix application instead of two.\nMultiply thescalematrix by thetranslationmatrix to get the combinedtransformmatrix. RealityKit then applies the combined matrix to the vertices:\n\nWhich yields a matrix like this:\n\nThe scaled and translated vertices yield a cube that is twice as large in each direction and moved0.1units to the right.\nRotate entities\nTo rotate the cube 45\u00b0 (\u03c0/4 radians), use theTransformtype with therotationargument like this:\nThis causes the cube to rotate 45\u00b0 around its origin along thex-axis. The matrix for this rotation looks like this:\nRotation around any other axis is achieved in the same way. For example, to rotate 45\u00b0 around the axis through the top-right corner of the cube you could use:\nImportant\nThenormalize(_:)function returns a vector pointing in the same direction with a length of 1.0. Make sure to normalize theaxisargument when creating quaternions.\nThat code performs a rotation that looks like this:\nApplying this transformation matrix to the full set of vertices yields this new set of transformed vertices:\n\nNotice that the fourth and sixth vertex didn\u2019t change. The axis of rotation goes through those two vertices so nothing changes on that axis.\nCombine rotation, translation, and scale in one transform\nRotation combined with other transforms might yield unexpected results depending on the order of the application. You can combine all three transformations in theTransforminitializer like this:\nThe order of these transforms istranslationfollowed byrotationthenscale.\nSee Also\nRealityKit and Reality Composer Pro",
        "https://developer.apple.com/documentation/visionos/drawing-sharp-layer-based-content": "visionOS\nDrawing sharp layer-based content in visionOS\nDrawing sharp layer-based content in visionOS\nDrawing sharp layer-based content in visionOS\nDrawing sharp layer-based content in visionOS\nOverview\nIf your app uses Core Animation layers directly, update your layer code to draw a high-resolution version of your content when appropriate. SwiftUI and UIKit views use Core Animation layers to manage interface content efficiently. When a view draws its content, the underlying layer captures that content and caches it to improve subsequent render operations.\nCore Animation on most Apple platforms rasterizes your layer at the same resolution as the screen, but Core Animation on visionOS can rasterize at different resolutions to maximize both content clarity and performance. The system follows the person\u2019s eyes and renders content immediately in front of them at the highest possible resolution. Outside of this focal area, the system renders content at progressively lower resolutions to reduce GPU workloads. Because the content is in the person\u2019s peripheral vision, these lower resolutions don\u2019t impact the content\u2019s clarity. As the person\u2019s eyes move around, the system redraws content at different resolutions to match the change in focus.\nA figure at 2x resolution\nA figure at 8x resolution\nIf you deliver content using customCALayerobjects, you can configure your custom layers to support drawing at different resolutions. If you don\u2019t perform this extra configuration step, each layer rasterizes its content at a @2x scale factor, which is good enough for most content and matches what the layer provides on a Retina display. However, if you opt in to drawing at different resolutions, the layer rasterizes its content at up to @8x scale factor in visionOS, which adds significant detail to text and vector-based content.\nRequest dynamic scaling for custom layers\nDynamic content scaling is off by default for all Core Animation layers, and frameworks or apps must turn on this support explicitly. If your interface uses only SwiftUI or UIKit views, you don\u2019t need to do anything to support this feature. SwiftUI and UIKit enable it automatically for views that benefit from the added detail, such as text views and image views with SF Symbols or other vector-based artwork. However, the frameworks don\u2019t enable the feature for all views, includingUIViewandView.\nIf your visionOS interface includes custom Core Animation layers, you can enable thewantsDynamicContentScalingproperty of anyCALayerobjects that contain vector-based content. Setting this property totruetells the system that you support rendering your layer\u2019s content at different resolutions. However, the setting is not a guarantee that the system applies dynamic content scaling to your content. The system can disable the feature if your layer draws using incompatible functions or techniques.\nThe following example shows how to enable this feature for aCATextLayerobject. After configuring the layer, set thewantsDynamicContentScalingproperty totrueand add the layer to your layer hierarchy.\nDynamic content scaling works best when the layer contains text or vector-based content. Don\u2019t enable the feature if you do any of the following in your layer:\nYou set the layer\u2019s content using thecontentsproperty.\nYou set the layer\u2019s content using thecontentsproperty.\nYou draw primarily bitmap-based content.\nYou draw primarily bitmap-based content.\nYou redraw your layer\u2019s contents repeatedly over a short time period.\nYou redraw your layer\u2019s contents repeatedly over a short time period.\nTheCAShapeLayerclass ignores the value of thewantsDynamicContentScalingproperty and always enables dynamic content scaling. For other Core Animation layers, you must enable the feature explicitly to take advantage of it.\nDraw the layer\u2019s content dynamically\nDynamic content scaling requires you to draw your layer\u2019s contents using one of the prescribed methods. If you define a custom subclass ofCALayer, draw your layer\u2019s content in thedraw(in:)method. If you use aCALayerDelegateobject to draw the layer\u2019s content, use the delgate\u2019sdraw(_:in:)method instead.\nWhen you enable dynamic content scaling for a layer, the system captures your app\u2019s drawing commands for playback later. As the person\u2019s eyes move, the system draws the layer at higher resolutions when someone looks directly at it, or at lower resolutions otherwise. Because the redraw operations implicitly communicate what the person is looking at, the system performs them outside of your app\u2019s process. Letting the system handle these operations maintains the person\u2019s privacy while still giving your app the benefits of high-resolution drawing.\nSome Core Graphics routines are incompatible with dynamic content scaling. Even if you enable dynamic content scaling for your layer, the system automatically disables the feature if your layer uses any of the following:\nCore Graphics shaders.\nCore Graphics shaders.\nAPIs that set intent, quality, or other bitmap-related properties. For example, don\u2019t callCGContextSetInterpolationQuality.\nAPIs that set intent, quality, or other bitmap-related properties. For example, don\u2019t callCGContextSetInterpolationQuality.\nACGBitmapContextto draw content.\nACGBitmapContextto draw content.\nIf your app creates timer-based animations, don\u2019t animate layer changes using your drawing method. CallingsetNeedsDisplay()on your layer repeatedly in a short time causes the system to draw the layer multiple times in quick succession. Because visionOS needs a little extra time to draw a layer at high resolution, each redraw request forces it to throw away work. A better option is to animate layer-based properties to achieve the same effect, or use aCAShapeLayerto animate paths when needed.\nModify layer hierarchies to improve performance\nThe backing store for a layer consumes more memory at higher resolutions than at lower resolutions. Measure your app\u2019s memory usage before and after you enable dynamic content scaling to make sure the increased memory cost is worth the benefit. If your app\u2019s memory usage increases too much, limit which layers adopt dynamic content scaling. You can also reduce the amount of memory each layer uses in the following ways:\nMake your layer the smallest size possible. Larger layers require significantly more memory, especially at higher resolutions. Make the size of the layer match the size of your content by eliminating padding or extra space.\nMake your layer the smallest size possible. Larger layers require significantly more memory, especially at higher resolutions. Make the size of the layer match the size of your content by eliminating padding or extra space.\nSeparate complex content into different layers. Instead of drawing everything in a single layer, build your content from multiple layers and arrange them hierarchically to achieve the same result. Enable dynamic content scaling only in the layers that actually need it.\nSeparate complex content into different layers. Instead of drawing everything in a single layer, build your content from multiple layers and arrange them hierarchically to achieve the same result. Enable dynamic content scaling only in the layers that actually need it.\nApply special effects using layer properties whenever possible. Applying effects during drawing might require you to increase the layer\u2019s size. For example, apply scale and rotation effects to the layer\u2019stransformproperty, instead of during drawing.\nApply special effects using layer properties whenever possible. Applying effects during drawing might require you to increase the layer\u2019s size. For example, apply scale and rotation effects to the layer\u2019stransformproperty, instead of during drawing.\nDon\u2019t draw your layer\u2019s content at different resolutions in advance and cache the images. Maintaining multiple images requires more memory. If you do cache images, draw them only at @2x scale factor.\nDon\u2019t draw your layer\u2019s content at different resolutions in advance and cache the images. Maintaining multiple images requires more memory. If you do cache images, draw them only at @2x scale factor.\nDon\u2019t use your drawing code to draw a single image. If your layer\u2019s content consists of an image, assign that image to the layer\u2019scontentsproperty directly.\nDon\u2019t use your drawing code to draw a single image. If your layer\u2019s content consists of an image, assign that image to the layer\u2019scontentsproperty directly.\nComplex drawing code can also lead to performance issues. A layer with many strokes can render quickly at lower scale factors, but might be computationally too complex to render at larger scales. If a complex layer doesn\u2019t render correctly at higher resolutions, turn off dynamic content scaling and measure the render times again.\nSee Also\nApp construction",
        "https://developer.apple.com/documentation/visionos#topics": "visionOS\nOverview\nvisionOS is the operating system that powers Apple Vision Pro. Use visionOS together with familiar tools and technologies to build immersive apps and games for spatial computing.\n\nDeveloping for visionOS requires a Mac with Apple silicon. Create new apps using SwiftUI to take full advantage of the spectrum of immersion available in visionOS. If you have an existing iPad or iPhone app, add the visionOS destination to your app\u2019s target to gain access to the standard system appearance, and add platform-specific features to create a compelling experience. To provide continuous access to your content in the meantime, deliver a compatible version of your app that runs in visionOS.\nExpand your app into immersive spaces\nStart with a familiar window-based experience to introduce people to your content. From there, addSwiftUIscene types specific to visionOS, such as volumes and spaces. These scene types let you incorporate depth, 3D objects, and immersive experiences.\nBuild your app\u2019s 3D content withRealityKitand Reality Composer Pro, and display it with aRealityView. In an immersive experience, useARKitto integrate your content with the person\u2019s surroundings.\n\nExplore new kinds of interaction\nPeople can select an element by looking at it and tapping their fingers together. They can also pinch, drag, zoom, and rotate objects using specific hand gestures.SwiftUIprovides built-in support for these standard gestures, so rely on them for most of your app\u2019s input. When you want to go beyond the standard gestures, useARKitto create custom gestures.\nTap to select\nPinch to rotate\nManipulate objects\nCreate custom gestures\nDive into featured sample apps\nExplore the core concepts for all visionOS apps with Hello World. Understand how to detect custom gestures using ARKit with Happy Beam. Discover streaming 2D and stereoscopic media with Destination Video. And learn how to build 3D scenes with RealityKit and Reality Composer Pro with Diorama and Swift Splash.\nTopics\nApp construction\nDesign\nSwiftUI\nRealityKit and Reality Composer Pro\nARKit\nVideo playback\nXcode and Simulator\nPerformance\niOS migration and compatibility\nEnterprise APIs for visionOS\nvisionOS\nOverview\nExpand your app into immersive spaces\nExplore new kinds of interaction\nDive into featured sample apps\nTopics",
        "https://developer.apple.com/documentation/visionos/displaying-video-from-connected-devices": "visionOS\nDisplaying video from connected devices\nDisplaying video from connected devices\nDisplaying video from connected devices\nDisplaying video from connected devices\nOverview\nApple\u2019s audiovisual frameworks allow your visionOS app to access video from USB video class (UVC) devices connected with theDeveloper Strapfor Apple Vision Pro. You can use this functionality to display realtime video in your app. For example, a medical researcher can view the output from an endoscopic camera during a procedure. This article outlines the requirements to access UVC devices in visionOS, while the sample code project shows a picker for every device connected to Vision Pro and displays the selected device\u2019s video feed.\nConfigure the sample code project\nIn the Xcode project, replaceEnterprise.licensewith your license file. The sample app requires a valid license file to display the selected video feed.\nRequest the entitlement\nUVC device access is a part of enterprise APIs for visionOS, a collection of APIs that unlock capabilities for enterprise customers. To use UVC device access, apply for theUVC Device Access on visionOSentitlement. For more information, including how to apply for this entitlement, seeBuilding spatial experiences for business apps with enterprise APIs for visionOS.\nAdd usage descriptions for camera access\nTo help protect people\u2019s privacy, visionOS limits app access to cameras and other sensors in Apple Vision Pro. You need to add anNSCameraUsageDescriptionto your app\u2019s information property list to provide a usage description that explains how your app uses the data these sensors provide. People see this description when your app prompts for access to camera data.\nCreate the device picker\nUse anAVCaptureDevice.DiscoverySessionobtain an array of connected devices.\nNext, observewasConnectedNotificationandwasDisconnectedNotificationto update the array when a device connects or disconnects.\nRender a picker with an option for each device:\nDisplay the selected device\u2019s video feed\nConfigure anAVCaptureSessionto captureAVCaptureDeviceInputfrom the selected device and output it to anAVCaptureVideoDataOutput.\nCallstartRunning()on the capture session to start the flow of data from the capture session\u2019s inputs to its outputs.\nAVCaptureSessiondelivers a steady stream of updates to theAVCaptureVideoDataOutputSampleBufferDelegateassigned to theAVCaptureVideoDataOutput. Each update includes aCMSampleBufferthat contains the latest video frame from the device. Render theCMSampleBufferto anAVSampleBufferDisplayLayerusing the layer\u2019sAVSampleBufferVideoRenderer.\nAdd theAVSampleBufferDisplayLayerto aUIViewand use aUIViewRepresentableto display theUIViewin a SwiftUI view.\nDisplay an error when denying access to the camera\nIf the person hasn\u2019t granted camera access, the sample app prompts people to grant access in the Settings app. For more information about providing camera access in your app, seeRequesting authorization to capture and save media.\nSee Also\nEnterprise APIs for visionOS",
        "https://developer.apple.com/documentation/visionos#Dive-into-featured-sample-apps": "visionOS\nOverview\nvisionOS is the operating system that powers Apple Vision Pro. Use visionOS together with familiar tools and technologies to build immersive apps and games for spatial computing.\n\nDeveloping for visionOS requires a Mac with Apple silicon. Create new apps using SwiftUI to take full advantage of the spectrum of immersion available in visionOS. If you have an existing iPad or iPhone app, add the visionOS destination to your app\u2019s target to gain access to the standard system appearance, and add platform-specific features to create a compelling experience. To provide continuous access to your content in the meantime, deliver a compatible version of your app that runs in visionOS.\nExpand your app into immersive spaces\nStart with a familiar window-based experience to introduce people to your content. From there, addSwiftUIscene types specific to visionOS, such as volumes and spaces. These scene types let you incorporate depth, 3D objects, and immersive experiences.\nBuild your app\u2019s 3D content withRealityKitand Reality Composer Pro, and display it with aRealityView. In an immersive experience, useARKitto integrate your content with the person\u2019s surroundings.\n\nExplore new kinds of interaction\nPeople can select an element by looking at it and tapping their fingers together. They can also pinch, drag, zoom, and rotate objects using specific hand gestures.SwiftUIprovides built-in support for these standard gestures, so rely on them for most of your app\u2019s input. When you want to go beyond the standard gestures, useARKitto create custom gestures.\nTap to select\nPinch to rotate\nManipulate objects\nCreate custom gestures\nDive into featured sample apps\nExplore the core concepts for all visionOS apps with Hello World. Understand how to detect custom gestures using ARKit with Happy Beam. Discover streaming 2D and stereoscopic media with Destination Video. And learn how to build 3D scenes with RealityKit and Reality Composer Pro with Diorama and Swift Splash.\nTopics\nApp construction\nDesign\nSwiftUI\nRealityKit and Reality Composer Pro\nARKit\nVideo playback\nXcode and Simulator\nPerformance\niOS migration and compatibility\nEnterprise APIs for visionOS\nvisionOS\nOverview\nExpand your app into immersive spaces\nExplore new kinds of interaction\nDive into featured sample apps\nTopics",
        "https://developer.apple.com/documentation/visionos/understanding-the-realitykit-modular-architecture": "visionOS\nUnderstanding the modular architecture of RealityKit\nUnderstanding the modular architecture of RealityKit\nUnderstanding the modular architecture of RealityKit\nUnderstanding the modular architecture of RealityKit\nOverview\nRealityKit is a 3D framework designed for building apps, games, and other immersive experiences. Although it\u2019s built in an object-oriented language and uses object-oriented design principles, the architecture of RealityKit avoids heavy use of composition \u2014 where objects are built by adding instance variables that hold references to other objects \u2014 in favor of a modular design based on a paradigm called Entity Component System (ECS) that divides application objects into one of three types.\nFollowing the ECS paradigm allows you to re-use the functionality contained in a component in many different entities, even if they have very different inheritance chains. Even if two objects have no common ancestors other thanEntity, you can add the same components to both of them and give them the same behavior or functionality.\nStart with entities\nEntities are the core actors of RealityKit. Any object that you can put into a scene, whether visible or not, is an entity and must be a descendent ofEntity. Entities can be 3D models, shape primitives, lights, or even invisible items like sound emitters or trigger volumes. Add components to entities to let them store additional state relevant to a specific type of functionality. Entities themselves contain relatively few properties: Nearly all entity state is stored on an entity\u2019s components.\nRealityKit provides a number of entity types you use to represent different kinds of objects. For example, aModelEntityrepresents a 3D model, such as one imported from a.usdzor.realityfile. These provided entities are essentially just anEntitywith certain components already added to them. Adding aModelComponentto an instance ofEntity, for example, results in an entity with identical functionality to aModelEntity.\nAdd components to entities\nComponents are modular building blocks that you add to an entity; they identify which entities a system will act on, and maintain the per-entity state that systems rely on. Components can contain logic, but limit component logic to code that validates its property values or sets its initial state. Use systems for any logic that affects the behavior of entities or that potentially changes their state on every frame. To add accessibility information to an entity, for example, add aAccessibilityComponentto it and populate its fields with the information the accessibility system needs, such as putting the description that VoiceOver reads into itslabelproperty.\nKeep in mind that an entity can only hold one copy of any particular type of component at a time. So, for example, you can\u2019t add two accessibility components to one entity. If you add an accessibility component to an entity that already has one, the new component replaces the previous one.\nCreate systems to implement entity behavior\nASystemcontains code that RealityKit calls on every frame to implement a specific type of entity behavior or to update a particular type of entity state. Systems use components to store their entity-specific state and query for entities to act on by looking for ones with a specific component or combination of components.\nFor example, a game might have a damage system that monitors and updates the health of every entity that can be damaged or destroyed. Systems typically work together with one or more components, so that damage system might use a health component to keep track of how much damage each entity has taken and how much each one is able to take before it\u2019s destroyed. It might also interact with other components. For example, an entity might have an armor component that provides protection to the entity, and the damage system would also need to use the state stored in that component.\nEvery frame, the damage system queries for entities that have the health component and updates values on those entities\u2019 components based on the current state of the app. If an entity has taken too much damage, the system might trigger a specific animation or remove the entity from the scene.\nWriting entity logic in a system avoids duplication of work. Using traditional OOP design patterns, where this type of logic would reside on the entity class, can often result in the same calculations being performed multiple times, once for every entity potentially affected. No matter how many entities the calculation potentially impacts the system only has to do the calculation once.\nFor more information on creating systems, seeImplementing systems for entities in a scene\nSee Also\nRealityKit and Reality Composer Pro",
        "https://developer.apple.com/documentation/visionos/bringing-your-arkit-app-to-visionos": "visionOS\nBringing your ARKit app to visionOS\nBringing your ARKit app to visionOS\nBringing your ARKit app to visionOS\nBringing your ARKit app to visionOS\nOverview\nIf you use ARKit to create an augmented reality experience on iPhone or iPad, you need to rethink your use of that technology when bringing your app to visionOS. ARKit plays a crucial role in delivering your content to the display in iPadOS and iOS. In visionOS, you use ARKit only to acquire data about the person\u2019s surroundings, and you do so using a different set of APIs.\nIn visionOS, you don\u2019t need a special view to display an augmented reality interface. Build windows with your app\u2019s content using SwiftUI or UIKit. When you display those windows, visionOS places them in the person\u2019s surroundings for you. If you want to control the placement of any 2D or 3D content in the person\u2019s surroundings, build your content using SwiftUI and RealityKit.\nWhen migrating your app to visionOS, reuse as much of your app\u2019s existing content as you can. visionOS supports most of the same technologies as iOS, so you can reuse project assets, 3D models, and most custom views. Don\u2019t reuse your app\u2019s ARKit code or any code that relies on technologies visionOS doesn\u2019t support.\nFor general guidance on how to port apps to visionOS, seeBringing your existing apps to visionOS.\nAdopt technologies available in both iOS and visionOS\nTo create a single app that runs in both iOS and visionOS, use technologies that are available on both platforms. While ARKit in iOS lets you create your interface using several different technologies, the preferred technologies in visionOS are SwiftUI and RealityKit. If you\u2019re not currently using RealityKit for 3D content, consider switching to it before you start adding visionOS support. If you retain code that uses older technologies in your iOS app, you might need to re-create much of that code using RealityKit when migrating to visionOS.\nIf you useMetalto draw your app\u2019s content, you can bring your code to visionOS to create content for 2D views or to create fully immersive experiences. You can\u2019t use Metal to create 3D content that integrates with the person\u2019s surroundings. This restriction prevents apps from sampling pixels of the person\u2019s surroundings, which might contain sensitive information. For information on how to create a fully immersive experience with Metal, seeDrawing fully immersive content using Metal.\nNote\nIn visionOS 2.0 and later, you can create a mixed immersive experience with Metal as well. WatchRender Metal with passthrough in visionOSfor more information and sample code.\nConvert 3D assets to the USDZ format\nThe recommended format for 3D assets in iOS and visionOS is USDZ. This format offers a compact single file for everything, including your models, textures, behaviors, physics, anchoring, and more. If you have assets that don\u2019t use this format, use the Reality Converter tool that comes with Xcode to convert them for your project.\nWhen building 3D scenes for visionOS, use Reality Composer Pro to create your scenes that incorporate your USDZ assets. With Reality Composer Pro, you can import your USD files and edit them in place, nondestructively. If your iOS app applies custom materials to your assets, convert those materials to shader graphs in the app.\nAlthough you can bring models and materials to your project using USDZ files, you can\u2019t bring custom shaders you wrote using Metal. Replace any custom shader code with MaterialX shaders. Many digital content creation tools support the MaterialX standard, and let you create dynamic shaders and save them with your USDZ files. Reality Composer Pro and RealityKit support MaterialX shaders, and incorporate them with your other USDZ asset content. See theMaterialXsite for more information.\nUpdate your interface to support visionOS\nIn visionOS, you manage your app\u2019s content, and the system handles the integration of that content with the person\u2019s surroundings. This approach differs from iOS, where you use a special ARKit view to blend your content and the live camera content. Bringing your interface to visionOS therefore means you need to remove this special ARKit view and focus only on your content.\nIf you can display your app\u2019s content using SwiftUI or UIKit views, build a window with those views and present it from your visionOS app. If you use other technologies to incorporate 2D or 3D content into the person\u2019s surroundings, make the following substitutions in the visionOS version of your app.\nIf you create your AR experience using:\nUpdate to:\nRealityKit andARView\nRealityKitandRealityView\nSceneKit andARSCNView\nRealityKitandRealityView\nSpriteKit andARSKView\nRealityKitorSwiftUI\nARealityViewis a SwiftUI view that manages the content and animations you create using RealityKit and Reality Composer Pro. You can add aRealityViewto any of your app\u2019s windows to display 2D or 3D content. You can also add the view to anImmersiveSpacescene, which you use to integrate your RealityKit content into the person\u2019s surroundings.\nNote\nYou can load iOS storyboards into a visionOS app, but you can\u2019t customize your interface for visionOS or include 3D content. If you want to share interface files between iOS and visionOS, adopt SwiftUI views or create your interface programmatically.\nFor more information about how to useRealityViewand respond to interactions with your content, seeAdding 3D content to your app.\nReplace your ARKit code\nARKit provides different APIs for iOS and visionOS, and the way you use ARKit services on the platforms is also different. In iOS, you must use ARKit to put your content onscreen, and you can also use it to manage interactions between your content and a person\u2019s surroundings. In visionOS, the system puts your content onscreen, so you only use ARKit to manage interactions with the surroundings. Because of this more limited usage, some apps don\u2019t need ARKit at all in visionOS.\nThe only time you use ARKit in visionOS is when you need one of the following services:\nPlane detection\nPlane detection\nImage tracking\nImage tracking\nScene reconstruction\nScene reconstruction\nHand tracking\nHand tracking\nWorld tracking and device-pose prediction\nWorld tracking and device-pose prediction\nUse plane detection, image tracking, and scene reconstruction to facilitate interactions between your app\u2019s virtual content and real-world items. For example, use plane detection to detect a tabletop on which to place your content. Use world tracking to record anchors that you want to persist between launches of your app. Use hand tracking if your app requires custom hand-based input.\nImportant\nIn visionOS 2.0 and later, useSpatialTrackingSessionfor available AR data instead.\nTo start ARKit services in your app, create anARKitSessionobject and run it with the data providers for each service. Unlike ARKit in iOS, services in visionOS are independent of one another, and you can start and stop each one at any time. The following example shows how to detect horizontal and vertical planes. Data providers deliver new information using an asynchronous sequence.\nIf you use the world-tracking data provider in visionOS, ARKit automatically persists the anchors you add to your app\u2019s content. You don\u2019t need to persist these anchors yourself.\nFor more information about how to use ARKit, seeARKit.\nIsolate ARKit features not available in visionOS\nIf your app uses ARKit features that aren\u2019t present in visionOS, isolate that code to the iOS version of your app. The following features are available in iOS, but don\u2019t have an equivalent in visionOS:\nFace tracking\nFace tracking\nBody tracking\nBody tracking\nGeotracking and placing anchors using a latitude and longitude\nGeotracking and placing anchors using a latitude and longitude\nObject detection\nObject detection\nApp Clip Code detection\nApp Clip Code detection\nVideo frame post-processing\nVideo frame post-processing\nAlthough whole body tracking isn\u2019t available in visionOS, you can track the hands of the person wearing the device. Hand gestures are an important way of interacting with content in visionOS. SwiftUI handles common types of interactions like taps and drags, but you can use custom hand tracking for more complex gestures your app supports.\nIf you use ARKit raycasting in iOS to detect interactions with objects in the person\u2019s surroundings, you might not need that code in visionOS. SwiftUI and RealityKit handle both direct and indirect interactions with your app\u2019s content in 3D space, eliminating the need for raycasting in many situations. In other situations, you can use the features of ARKit and RealityKit to manage interactions with your content. For example, you might use ARKit hand tracking to determine where someone is pointing in the scene, and use scene reconstruction to build a mesh you can integrate into your RealityKit content.\nSee Also\niOS migration and compatibility",
        "https://developer.apple.com/documentation/visionos#Explore-new-kinds-of-interaction": "visionOS\nOverview\nvisionOS is the operating system that powers Apple Vision Pro. Use visionOS together with familiar tools and technologies to build immersive apps and games for spatial computing.\n\nDeveloping for visionOS requires a Mac with Apple silicon. Create new apps using SwiftUI to take full advantage of the spectrum of immersion available in visionOS. If you have an existing iPad or iPhone app, add the visionOS destination to your app\u2019s target to gain access to the standard system appearance, and add platform-specific features to create a compelling experience. To provide continuous access to your content in the meantime, deliver a compatible version of your app that runs in visionOS.\nExpand your app into immersive spaces\nStart with a familiar window-based experience to introduce people to your content. From there, addSwiftUIscene types specific to visionOS, such as volumes and spaces. These scene types let you incorporate depth, 3D objects, and immersive experiences.\nBuild your app\u2019s 3D content withRealityKitand Reality Composer Pro, and display it with aRealityView. In an immersive experience, useARKitto integrate your content with the person\u2019s surroundings.\n\nExplore new kinds of interaction\nPeople can select an element by looking at it and tapping their fingers together. They can also pinch, drag, zoom, and rotate objects using specific hand gestures.SwiftUIprovides built-in support for these standard gestures, so rely on them for most of your app\u2019s input. When you want to go beyond the standard gestures, useARKitto create custom gestures.\nTap to select\nPinch to rotate\nManipulate objects\nCreate custom gestures\nDive into featured sample apps\nExplore the core concepts for all visionOS apps with Hello World. Understand how to detect custom gestures using ARKit with Happy Beam. Discover streaming 2D and stereoscopic media with Destination Video. And learn how to build 3D scenes with RealityKit and Reality Composer Pro with Diorama and Swift Splash.\nTopics\nApp construction\nDesign\nSwiftUI\nRealityKit and Reality Composer Pro\nARKit\nVideo playback\nXcode and Simulator\nPerformance\niOS migration and compatibility\nEnterprise APIs for visionOS\nvisionOS\nOverview\nExpand your app into immersive spaces\nExplore new kinds of interaction\nDive into featured sample apps\nTopics",
        "https://developer.apple.com/documentation/visionos/world": "visionOS\nHello World\nHello World\nHello World\nHello World\nOverview\nYou can use visionOS scene types and styles to share information in fun and compelling ways. Features like volumes and immersive spaces let you put interactive virtual objects into people\u2019s environments, or put people into a virtual environment.\nHello World uses these tools to teach people about the Earth \u2014 the planet we call home. The app shows how the Earth\u2019s tilt creates the seasons, how objects move as they orbit the Earth, and how Earth appears from space.\nThe app uses SwiftUI to define its interface, including both 2D and 3D elements. To create, customize, and manage 3D models and effects, it also relies on the RealityKit framework and Reality Composer Pro.\nCreate an entry point into the app\nHello World constructs the scene that it displays at launch \u2014 the first scene that appears in theWorldAppstructure \u2014 using aWindowGroup:\nLike other platforms \u2014 for example, macOS and iOS \u2014 visionOS displays a window group as a familiar-looking window. In visionOS, people can resize and move windows around the Shared Space. Even if your app offers a sophisticated 3D experience, a window is a great starting point for an app because it eases people into the experience. It\u2019s also a good place to provide instructions or controls.\nTip\nThis particular window group uses theplainwindow style to maintain control over the glass background effect that visionOS would otherwise automatically add.\nPresent different modules using a navigation stack\nAfter you watch a brief introductory animation that shows the text Hello World typing in, theModulesview that defines the primary scene\u2019s content presents options to explore different aspects of the world. This view contains a table of contents at the root of aNavigationStack:\nA visionOS navigation stack has the same behavior that it has in other platforms. When it first appears, the stack displays its root view. When someone chooses an embeddedNavigationLink, the stack draws a new view and displays a back button in the toolbar. When someone taps the back button, the stack restores the previous view.\n\nThe trailing closure of thenavigationDestination(for:destination:)view modifier in the code above displays a view when someone activates a link based on amoduleinput that comes from the corresponding link\u2019s initializer:\nThe possiblemodulevalues come from a customModuleenumeration:\nDisplay an interactive globe in a new scene\nTheglobemodule opens with a few facts about the Earth in the main window next to a decorative, flat image that supports the content. To help people understand even more, the module includes a button titled View Globe that opens a 3D interactive globe in a new window.\n\nTo be able to open multiple scene types, Hello World includes theUIApplicationSceneManifestkey in itsInformation Property Listfile. The value for this key is a dictionary that includes theUIApplicationSupportsMultipleSceneskey with a value oftrue:\nDeclare a volume for the globe\nWith the key in place, the app makes use of a secondWindowGroupin itsAppdeclaration. This new window group uses theGlobeview as its content:\nThis window group creates avolume\u2014 which is a container that has three dimensions and behaves like a transparent box \u2014 because Hello World uses thevolumetricwindow style scene modifier. People can move this box around the Shared Space like they move other window types, and the content remains fixed inside. ThedefaultSize(width:height:depth:in:)modifier specifies a size for the volume in meters, including a depth dimension.\nTheGlobeview inside the volume contains 3D content, but is still just a SwiftUI view. It contains two elements in aZStack: a subview that draws a model of the Earth, and another that provides a control panel that people can use to configure the model\u2019s appearance.\nOpen and dismiss the globe volume\nThe globe module presents a View Globe button that people can tap to display or dismiss the volume, depending on the current state. Hello World achieves this behavior by creating aTogglewith the button style, and embedding it in a customGlobeToggleview.\n\nWhen someone taps the toggle, theisShowingGlobestate changes, and theonChange(of:initial:_:)modifier calls theopenWindowordismissWindowaction to open or dismiss the volume, respectively. The view gets these actions from the environment and uses an identifier that matches the volume\u2019s identifier.\nDisplay objects that orbit the Earth\nYou use windows in visionOS the same way you do in other platforms. But even 2D windows in visionOS provide a small amount of depth you can use to create 3D effects \u2014 like elements that appear in front of other elements. Hello World takes advantage of this depth to present small models inline with 2D content.\nThe app\u2019s second module, Objects in Orbit, provides information about objects that go around the Earth, like the Moon and artificial satellites. To give a sense of what these objects look like, the module displays 3D models of these items directly inside the window.\n\nHello World loads these models from the asset bundle using aModel3Dstructure inside a customItemView. The view scales and positions the model to fit the available space, and applies optional orientation adjustments:\nThe app uses thisItemViewonce for each model, placing each in an overlay that only becomes visible based on the current selection. For example, the following overlay displays the satellite model with a small amount of tilt in the x-axis and z-axis:\nTheVStackthat contains the models also contains aPickerthat people use to select a model to view:\nWhen you add 3D effects to a 2D window, keep this guidance in mind:\nDon\u2019t overdo it.These kinds of effects add interest, but can unintentionally obscure important controls or information as people view the window from different directions.\nDon\u2019t overdo it.These kinds of effects add interest, but can unintentionally obscure important controls or information as people view the window from different directions.\nEnsure that elements don\u2019t exceed the available depth.Excess depth causes elements to clip. Account for any position or orientation changes that might occur after initial placement.\nEnsure that elements don\u2019t exceed the available depth.Excess depth causes elements to clip. Account for any position or orientation changes that might occur after initial placement.\nAvoid models intersecting with the backing glass.Again, account for potential movement after initial placement.\nAvoid models intersecting with the backing glass.Again, account for potential movement after initial placement.\nShow Earth\u2019s relationship to its satellites in an immersive space\nPeople can visualize how satellites move around the Earth because the app\u2019s orbit module displays the Earth, the Moon, and a communications satellite together as a single system. People can move the system anywhere in their environment or resize it using standard gestures. They can also move themselves around the system to get different perspectives.\n\nNote\nTo learn about designing with gestures in visionOS, readGesturesinHuman Interface Guidelines.\nTo create this visualization, the app displays theOrbitview \u2014 which contains a singleRealityViewthat models the entire system \u2014 in anImmersiveSpacescene with themixedimmersion style:\nAs with any secondary scene in a visionOS app, this scene depends on having theUIApplicationSupportsMultipleSceneskey in theInformation Property Listfile. The app also opens and closes the space using a toggle view that resembles the one used for the globe:\nThere are a few key differences from the version that appears in the sectionOpen and dismiss the globe volume:\nOrbitToggleusesopenImmersiveSpaceanddismissImmersiveSpacefrom the environment, rather than the window equivalents.\nOrbitToggleusesopenImmersiveSpaceanddismissImmersiveSpacefrom the environment, rather than the window equivalents.\nThe dismiss action in this case doesn\u2019t require an identifier, because people can only open one space at a time, even across apps.\nThe dismiss action in this case doesn\u2019t require an identifier, because people can only open one space at a time, even across apps.\nThe open and dismiss actions for spaces operate asynchronously, and so they appear inside aTask.\nThe open and dismiss actions for spaces operate asynchronously, and so they appear inside aTask.\nView the solar system from space using full immersion\nThe app\u2019s final module gives people a sense of the Earth\u2019s place in the solar system. Like other modules, this one includes information and a decorative image next to a button that leads to another visualization \u2014 in this case so people can experience Earth from space.\nWhen a person taps the button, the app takes over the entire display and shows stars in all directions. The Earth appears directly in front, the Moon to the right, and the Sun to the left. The main window also shows a small control panel that people can use to exit the fully immersive experience.\n\nTip\nPeople can always close the currently open immersive space by pressing the device\u2019s Digital Crown, but it\u2019s typically useful when you provide a built-in mechanism to maintain control of the experience within your app.\nThe app uses another immersive space scene for this module, but here with thefullimmersion style that turns off the passthrough video:\nThis scene depends on the sameUIApplicationSupportsMultipleSceneskey that other secondary scenes do, and is activated by aSolarSystemTogglethat\u2019s similar to the ones that the app uses for the other scenes:\nThis control appears in the main window to provide a way to begin the fully immersive experience, and separately in the control panel as a way to exit the experience. Because the app uses this control as two distinct buttons rather than as a toggle in one location, it\u2019s composed of aButtonwith behavior that changes depending on the app state rather than as a toggle with a button style.\nTo reuse the main window for the solar system controls, Hello World places both the navigation stack and the controls in aZStack, and then sets the opacity of each to ensure that only one appears at a time:\nSee Also"
    },
    "reddit_comments": [
        {
            "link": "https://www.reddit.com/r/VisionPro/comments/1b5j7u6/i_made_an_app_that_lets_you_see_the_matrix/",
            "title": "I made an app that lets you see the Matrix (literally)",
            "selftext": "",
            "comments": [
                {
                    "author": "SoSKatan",
                    "text": "All I see is a blonde brunette redhead."
                },
                {
                    "author": "trivertx",
                    "text": "This would be a cool boot up sequence for any mixed reality headset."
                },
                {
                    "author": "BeskarHunter",
                    "text": "Looks cool. Or as Neo would say. \u201cWhoa\u201d\n\nBut when I went to impulse buy, the $13 price tag for something I\u2019ll use for 5 mins made me rethink sadly.\n\n![gif](giphy|3rVfBUa9f0RErtMZBH)"
                },
                {
                    "author": "xpr60",
                    "text": "Did you make this through RealityKit?"
                },
                {
                    "author": "ravedog",
                    "text": "0.99 or 1.99\n.\n.\n.\nProfit"
                },
                {
                    "author": "GOD_RaZoR",
                    "text": "Cool background but \u2026for 10 mins of usage max is $2"
                },
                {
                    "author": "Maroczy-Bind",
                    "text": "I would love to use it! But too expensive"
                },
                {
                    "author": "astrorobb",
                    "text": "pricing is insane."
                },
                {
                    "author": "Odium-Squared",
                    "text": "$12.99? Ouch\u2026"
                },
                {
                    "author": "warrior178",
                    "text": "$13\u2026 way overpriced my guy. You\u2019ve posted this here before."
                },
                {
                    "author": "Trip_b3",
                    "text": "Agree with the comments would love to play with it but $13 is too expensive. Would pay a couple of dollars and maybe even pay another couple of dollars for each new filter you create to change the room. Enough cool filters and I may have actually paid more than $13, but entry price is just too high. I have a feeling that you would make more money by lowering the price."
                },
                {
                    "author": "chrysky",
                    "text": "Change it to $4.99 or less. You\u2019ll obviously make more money if you charge less."
                },
                {
                    "author": "term_vr",
                    "text": "Yikes bro, what a cash grab.  It's cool don't get me wrong, but for maybe 3 minutes of entertainment you want $13?  Big nope."
                },
                {
                    "author": "Readdit_1",
                    "text": "This is the beer mug iPhone app of the AVP"
                },
                {
                    "author": "DeathByVlog",
                    "text": "$13.00\u2026 Cash grab much?"
                },
                {
                    "author": "therealbrrrr",
                    "text": "Great work, very cool app. 4.99 I think it will be the \u201cibeer\u201d of AVP"
                },
                {
                    "author": "WoosleWuzzle",
                    "text": "Okay cool demo.  Now do it in a kitchen"
                },
                {
                    "author": "XCrucio5150",
                    "text": "Would buy at cheaper price. Long term utility is nil so novelty pricing should be used not enterprise work app pricing."
                },
                {
                    "author": "pksdg",
                    "text": "That is so cool - that said. I\u2019d never pay more than .99 for this. lol"
                },
                {
                    "author": "GreenLanturn",
                    "text": "Congrats my dude! \n\n(Inb4 /u/underbyte accuses you of plagiarizing the code from the Matrix)"
                },
                {
                    "author": "Drawerpull",
                    "text": "Everyone commenting here including me would probably buy this if it was only $5 and you\u2019d make more money bruh"
                },
                {
                    "author": "KeyPhotojournalist96",
                    "text": "Insta but at 99c. Otherwise, forget it."
                },
                {
                    "author": "pumpuppthevolume",
                    "text": "next they fire and u stop the bullets by lifting your hand \u270b\ufe0f"
                },
                {
                    "author": "subdep",
                    "text": "OP, every AVP owner would buy this if it were $0.99. \n\nYou could make way more money in the long run selling it cheaper."
                },
                {
                    "author": "JoelMDM",
                    "text": "Holy shit you charge $13 for this?\nThere are actual games and pieces of software that people spend month making that go for that amount. This could be made in a day or two.\nThat\u2019s just a scam."
                },
                {
                    "author": "funkedelic_bob",
                    "text": "Very nice detail that it starts moving down the room to fill up. Maybe have it start even further back so you get more of that effect.\n\nBut these are the little details that set good devs/designers apart. Well done."
                },
                {
                    "author": "Samantha_2024",
                    "text": "Wow, I like this one"
                },
                {
                    "author": "outcoldman",
                    "text": "Just made a video recording of the Matrix demo in my house, used Owl3D to make it spatial video, and published it on ImmersiShare - https://loshadki.app/immersishare/"
                },
                {
                    "author": "Enginerdiest",
                    "text": "This is awesome! Nicely done. Really drawing parallels to early iPhone or iPad apps that were \u201cgimmicky\u201d but showed what you can do with the brand new tech. Remember the beer drinking apps? Or virtual lighters and lightsabers?\n\nPrice wise, I actually think you\u2019re good despite most people here saying it\u2019s too much. Vision Pro market isn\u2019t mature like iPhones. People forget that those beer drinking apps were $4-5 at first too. I think I had an iPad interactive periodic table app that was $29 at launch.\u00a0\n\nThe only people with Vision Pro right now are people with money. $10-$15 for a cool demo to show my friends? Yeah sure.\u00a0"
                },
                {
                    "author": "Deleted",
                    "text": "[deleted]"
                },
                {
                    "author": "drewbaumann",
                    "text": "Love it. Nice work!"
                },
                {
                    "author": "Low-Presentation7206",
                    "text": "I own it already is this a new feature?"
                },
                {
                    "author": "muhammadalijr",
                    "text": "Do you think it\u2019s real money you\u2019re paying with?"
                },
                {
                    "author": "MeredithMcKay",
                    "text": "A few weeks ago I posted a comment (which I've now deleted) criticizing the pricing for this app, before I had even tried it. Now that I've purchased a copy and have seen how much fun it is, I am ready to eat humble pie and *deeply* apologize for my skepticism. This app is ***wonderful***, and might convince me to buy an AVP if I didn't already own one. I'm now spreading the word, and am looking forward to seeing whatever new environments you come up with. (As you suggested, I tried joining your Discord using the in-app link you provided, but got a message that the link is invalid.)"
                },
                {
                    "author": "my_shoes_hurt",
                    "text": "Really neat, but this is not like a daily driver app or anything, it\u2019s a fun little gimmick app that you play with a few times, maybe when you put a friend in guest mode, and that\u2019s it. I won\u2019t be considering this purchase unless the price drops by at least half. The value proposition just isn\u2019t there."
                },
                {
                    "author": "symonty",
                    "text": "CoolApp but the dev does not understand price elasticity curve, at $13 you sell X and at $1 you would sell 20x, since there is fixed production and distribution costs .99c app is going to make you more money."
                },
                {
                    "author": "montvious",
                    "text": "You know, I thought the same thing about this the first time you posted it: really cool concept, but the pricing is way too high.\n\nThere\u2019s nothing inherently wrong with that, the user base for the Apple Vision Pro is a lot lower so you would need to charge more to overcome that. However, many people don\u2019t see the value proposition in spending thirteen dollars for an app that has minimal practical use cases, myself included. Hoping the price comes down someday, because it is a cool app (but sort of gimmicky), but the value proposition isn\u2019t there at this point."
                },
                {
                    "author": "corkycorkyhey",
                    "text": "LOL $13.  Tell me you are an a-hole without telling me you are an a-hole. \n\nHARD PASS.  and shame on you."
                },
                {
                    "author": "Deleted",
                    "text": "TBH in AVP is passthrough so technically you are looking at simulated reality inside AVP"
                },
                {
                    "author": "iamgarffi",
                    "text": "At that price it better come with a trilogy in 3D."
                },
                {
                    "author": "lebriquetrouge",
                    "text": "LOL $13 for a wallpaper that gives me a headache"
                },
                {
                    "author": "GOD_RaZoR",
                    "text": "Did you delete your post about sadness? I was writing a detailed description why do we think it's overpriced to let you calm down. Anyway, I highly suggest you to down the price, and make additional backgrounds for extra bucks"
                },
                {
                    "author": "71-is-the-new-69",
                    "text": "That's INCREDIBLE !!!"
                },
                {
                    "author": "samuelson82",
                    "text": "Ok that\u2019s cool. You win."
                },
                {
                    "author": "FriendlyStory7",
                    "text": "Why it looks so low res?"
                },
                {
                    "author": "No-Kangaroo3140",
                    "text": "This app lets you walk around your house in complete darkness"
                },
                {
                    "author": "ensoniq0902",
                    "text": "Just got it - love it :-) Make some more"
                },
                {
                    "author": "Big-Extension-7357",
                    "text": "He did it"
                },
                {
                    "author": "car-tv",
                    "text": "Unreal cool."
                },
                {
                    "author": "ping-maestro",
                    "text": "That\u2019s really dope! Now put me back in the simulation!"
                },
                {
                    "author": "SWISS_KISS",
                    "text": "I created this almost 10 years ago for Hololens - there is still an app for free to download... And if you google you'll find the source code for the shader for free...\u00a0"
                },
                {
                    "author": "ASkepticalPotato",
                    "text": "$13? Wow\u2026 not a chance. $1.99 at MOST."
                },
                {
                    "author": "ASCanilho",
                    "text": "Really cool. good Job."
                },
                {
                    "author": "SpacemanChad7365",
                    "text": "I personally don\u2019t own the headset, but this looks amazing\n\nYour hard work has paid off, my friend"
                },
                {
                    "author": "Ok-Extension6498",
                    "text": "Dope as hell. Take my money"
                },
                {
                    "author": "eceertrey1",
                    "text": "this is what DMT is like"
                },
                {
                    "author": "tracyhenry400",
                    "text": "hey all - after lots of hacking, I finally got this out and [kept my promise](https://www.reddit.com/r/VisionPro/comments/1at50gg/comment/kquzvm0/) :) It\u2019s not perfect but I hope it\u2019s a good first attempt.\n\nSome notes:\n\n* This digital rain effect is in the latest version of [Magic Room](https://apps.apple.com/app/apple-store/id6477834941?pt=126555106&ct=rvpmatrix&mt=8), existing users can just update to get it.\n* Human meshes are for the demo and are NOT in the app. But you can request a TestFlight with the discord link in the app.\n* You can also try meshing real humans. They should be wrapped with codes if they stay still. If not, run.\n* In rare cases, the effect might look glitchy on first uses. See [FAQ](https://www.notion.so/Magic-Room-Support-59eb256c82d04e3ea55784cf67641fff?pvs=21) for simple fixes.\n* The effect works the best with flat surfaces such as walls and ceilings. It should also wrap around irregular objects reasonably well.\n* Please suggest new room transformation ideas - would love to make popular requests happen!\n\nCheers"
                },
                {
                    "author": "cphpc",
                    "text": "This is awesome but why would someone pay for this. People who paid $4000 for AVP are rich, not retarded."
                },
                {
                    "author": "AHApps",
                    "text": "Cool. Got it.\n\n I don't get all the shaming. $13 is optional. The other option is not getting the app. \n\nGiven how barren the Vision Pro App Store is, it's good to get more stuff on there"
                },
                {
                    "author": "Drawerpull",
                    "text": "These posts always get a suspiciously high amount of uploads as well, I suspect OP may be buying votes"
                },
                {
                    "author": "haiviseo",
                    "text": "wow.. I got dizzy watching them @@"
                },
                {
                    "author": "MjN-Nirude",
                    "text": "Very cool. Animate the middle guy (Smith) to shoot and then the bullet will fly very slowly and cause those ripples."
                },
                {
                    "author": "Steelass98",
                    "text": "There's a Meta version anywhere?"
                },
                {
                    "author": "Memeorise",
                    "text": "Surely this is a quick port to the Quest 3 haha?"
                },
                {
                    "author": "Tashum",
                    "text": "I was looking forward to you running and tackling into them only to pass through and hurt yourself lol."
                },
                {
                    "author": "WoosleWuzzle",
                    "text": "Op why not make the IAMRICH app and call it a day?"
                },
                {
                    "author": "MetaFedo",
                    "text": "We\u2019ve been doing this for a while in Magic Leap and HoloLens, but cool to see it in VPro too, good work!"
                },
                {
                    "author": "castpergers",
                    "text": "Forgot I took lsd before bed once and woke up to literally this"
                },
                {
                    "author": "C_Dragons",
                    "text": "I get a message that  says \"This video cannot be played\" a couple seconds in, so I'm not sure what the world looks like when the overlay is complete. Can you read signage or is every surface given the gimmick skin? Any settings to adjust for people vs fixed objects?"
                },
                {
                    "author": "TomatilloFearless154",
                    "text": "Always wondered why the matrix is in katakana"
                },
                {
                    "author": "jefmwols",
                    "text": "It\u2019s got hundreds of five star reviews"
                },
                {
                    "author": "DumbChineseGuy",
                    "text": "LitErALly!!"
                },
                {
                    "author": "btumpak",
                    "text": "Super cool, worth the spend IMO. Let's pay Devs who build cool shit. There's nothing else like this yet."
                },
                {
                    "author": "Deleted",
                    "text": "One of the biggest advantages I imagined that Apple would have would be big-budget developer support, with incredible software for this futuristic device. It appears I was wrong, since all I'm seeing are these amateur tech demos for ridiculous prices...."
                },
                {
                    "author": "Naus1987",
                    "text": "I\u2019m torn on the price thing lol. \n\nBecause it ironically is very comparable to the Vision Pro itself. Very expensive for a gimmick at the moment. \n\nBut the vision pro is going to be refined, and cheaper models will come out. \n\nIf op does something like that, it might be fine. Charge 10 dollars for the first year. Then run sales.  Add more content and make it better over time. \n\n\u2014\n\nI know personally, I don\u2019t buy shit at crazy prices if I don\u2019t get the value. I didn\u2019t even buy the Vision Pro and will wait for the 2nd gen. \n\nAnd frankly, for what I see, this app is 5 bucks at most. No promises of new content. No settings to change color, font, content. Speed?\n\nAs a pc gamer, I refuse to pay full price for an unfinished product. But if I saw this on sale for like 3 bucks in a few years, I could imagine impulse buying it. \n\n\u2014\n\nAnother fun though a very niche feature would be a wedding proposal. Imagine as asking your partner to try the app. \n\nIt\u2019s all words, then suddenly there\u2019s a line of code that\u2019s blue instead of red. She squints to read it. It gets bigger. \u201cWill you marry me?\u201d\n\nShe smiles and glances towards you, and you\u2019re a glowing green matrix dude holding a ring that shines with the power of the sun. \n\nStill super niche though lol."
                },
                {
                    "author": "EasternFly2210",
                    "text": "And this is why Vision Pro has no future"
                },
                {
                    "author": "Deleted",
                    "text": "The Matrix is 0s and 1s not Asian characters \u2026"
                },
                {
                    "author": "rather-oddish",
                    "text": "I love your app! Can\u2019t wait to see what kind of effects you add next."
                },
                {
                    "author": "kwxl",
                    "text": "THE killer app."
                },
                {
                    "author": "Deleted",
                    "text": "[deleted]"
                },
                {
                    "author": "zacware",
                    "text": "Link?"
                },
                {
                    "author": "Deleted",
                    "text": "this is the killer app. I want the vision pro NOW"
                },
                {
                    "author": "ubzy0",
                    "text": "i need this"
                },
                {
                    "author": "Certain_Customer4983",
                    "text": "Wow how can I get that ? Thanks"
                },
                {
                    "author": "Certain_Customer4983",
                    "text": "Thanks see store link now"
                },
                {
                    "author": "GuyNamedLindsey",
                    "text": "I now want one, just for this."
                },
                {
                    "author": "WhateverGreg",
                    "text": "I've seen multiple forums where people note this happened after installing Zeiss lenses. If that's the case, I wonder if this is related to VisionOS trying to pay attention to a dominant eye. Like when recording on the Quest, you set the dominant eye, and that's the eye that does the recording for a 2D video - the off-center/angled windows looks the same to my... eye.\n\nEdit: You guys choose the oddest times to downvote."
                },
                {
                    "author": "SnooEpiphanies1293",
                    "text": "Money well spent!\ud83e\udd23"
                },
                {
                    "author": "feoen",
                    "text": "I\u2019m DM\u2019d you about hiring you for a potential app but I did not receive a reply. Is there any interest? I promise it is an incredible app idea and could be built off of what you are displaying here.\u00a0"
                },
                {
                    "author": "GeneralZaroff1",
                    "text": "YES hahaha this looks so cool"
                },
                {
                    "author": "veeno__",
                    "text": "Are you able to watch the Matrix movies while in the Matrix?\n\nOr watching the Matrix while on the Nebuchadnezzar would be \ud83d\udd25\ud83d\udd25\ud83d\udd25"
                },
                {
                    "author": "nebulous_eye",
                    "text": "Very cool!"
                },
                {
                    "author": "nebulous_eye",
                    "text": "If the Vision Pro is already capable of laying text over walls and surfaces extremely well, why doesn\u2019t the UI take more advantage of this?"
                },
                {
                    "author": "JohnColes",
                    "text": "I\u2019d love it to show the detected surfaces too (like the old demo video you had)"
                },
                {
                    "author": "Genialissime-Dav",
                    "text": "Super cool! What\u2019s the name of the app?"
                },
                {
                    "author": "imagin8zn",
                    "text": "What time to be alive."
                },
                {
                    "author": "CalzonePillow",
                    "text": "Dude\u2026"
                },
                {
                    "author": "AlergiaFunda1",
                    "text": "This is brilliant"
                },
                {
                    "author": "ChromiumProtogen42",
                    "text": "this is the coolest use I have ever seen, gotta toss that on the app store."
                },
                {
                    "author": "Ok_loop",
                    "text": "That\u2019s cool af"
                },
                {
                    "author": "BoringWozniak",
                    "text": "![gif](giphy|kiAGnxwS0qPCg)"
                },
                {
                    "author": "72012122014",
                    "text": "That\u2019s effin baddass"
                },
                {
                    "author": "Oferlaor",
                    "text": "Looks like the beginning of a full blown matrix app. Next is bullet time?"
                },
                {
                    "author": "Upper-Seat2598",
                    "text": "Can't wait to see people parkouring roof tops with headsets on, LOL!"
                },
                {
                    "author": "Infamous_Ad_6793",
                    "text": "Am I tripping or is it showing the far walls through the walls?"
                },
                {
                    "author": "trammel11",
                    "text": "Bro"
                },
                {
                    "author": "Fantastic-Towel-383",
                    "text": "I want it!!"
                },
                {
                    "author": "Cameront9",
                    "text": "I don\u2019t know, $13 for a Korean cookbook isn\u2019t bad."
                },
                {
                    "author": "OK_Tha_Kidd",
                    "text": "Cops about to have a field day with this"
                },
                {
                    "author": "Hendogg99",
                    "text": "Can you make the scene when you learn karate"
                },
                {
                    "author": "Turbo6666",
                    "text": "Does the phone ring?"
                },
                {
                    "author": "TomatilloFearless154",
                    "text": "Now this is why i would buy the avp lol"
                },
                {
                    "author": "trashpanda2night",
                    "text": "Crazy expensive"
                },
                {
                    "author": "clarkcox3",
                    "text": "Two nitpicks:\n- It doesn\u2019t look like the characters are changing. Each time the \u201craindrop\u201d falls, it should be laying down new characters.\n- the katakana characters should be mirrored"
                },
                {
                    "author": "bettyx1138",
                    "text": "where can one get it? want a beta tester?"
                },
                {
                    "author": "kibblerz",
                    "text": "Do you mind explaining how you were able to do this? I attempted to do something like this with both the scene reconstruction and plane detection APIs, but I couldn\u2019t get a model entity to conform to the proper dimensions. Did you just manually write code to convert the geometry information from the mesh or plane anchors? Or is there some magical method I missed?\n\nFrom what I found, I could only get collision shapes to generate from the detected surroundings. So I\u2019ve been trying to convert the geometry info to meshbuffers.. Not going so well for me lol"
                },
                {
                    "author": "JoelMDM",
                    "text": "I am a little confused why it\u2019s katakana and not just binary, but the effect itself does look cool."
                }
            ]
        },
        {
            "link": "https://www.reddit.com/r/VisionPro/comments/1ai37t7/working_in_the_vision_pro/",
            "title": "Working in the Vision Pro",
            "selftext": "",
            "comments": [
                {
                    "author": "jgreg728",
                    "text": "Bruh my mind went kablooey when he showed us the other screens behind him lol."
                },
                {
                    "author": "aerialbyte",
                    "text": "If the headset is turned off and then back on, are all of the apps still in the same location?"
                },
                {
                    "author": "Mikewold58",
                    "text": "Absolutely insane footage here...downright freaky. I could see a future when everyone has a smaller version of this and all our \"monitors\" and \"screens\" can be shared with others. Basically an entire visual world you can only see if you have something like this on. Which would give someone the ability to unplug and not see any screens whatsoever."
                },
                {
                    "author": "dv8gaming",
                    "text": "You have dozens of reviews talking about the big three: passthrough, FOV, and comfort\n\nThen you have someone actually pushing the limitations of what this device can do. \n\nThank you so much for your demonstration!"
                },
                {
                    "author": "ANE_Scribe",
                    "text": "Apple should pay you to incorporate this video into their marketing ops"
                },
                {
                    "author": "EverydayPhilisophy",
                    "text": "This 1 minute video did more to sell me on a Vision Pro than anything else. I already own one but this made me want to go buy another. \ud83d\ude02"
                },
                {
                    "author": "HamMcStarfield",
                    "text": "Anybody not taking this as the most disruptive technology since the cell phone is in for a big suprise.  I'm so tempted to pay on time for one of these, but I know it'll simply be a better and cheaper -- more refined -- tech in a couple of years.  DAYUM."
                },
                {
                    "author": "Specialist_Union_612",
                    "text": "how do i make my mouse move over to the vision apps? my mac cursor wont move to the vision apps"
                },
                {
                    "author": "Sherringdom",
                    "text": "Is the blurring around the hands a product of the screen record or is that genuinely how it looks when you\u2019re wearing it?\n\nAlmost every review I\u2019ve seen the hands look terrible (this is one of the better ones) but everyone seems to rave about it."
                },
                {
                    "author": "Condimenting",
                    "text": "Have you been able to do serious work with it? Mine hurts to wear so I can't really focus. I want so badly to love it but I think I'm going to take it back."
                },
                {
                    "author": "Papafynn",
                    "text": "The only thing I find lacking about the Vision Pro\u2026.actually 2 things.\n\n1. It\u2019s impossible to share your experience with another person. It\u2019s such a singular magical experience. You say \u201cwow\u201d a lot but others around can never share the moment with you.\n\n2. Price\u2026.$4k is a LOT of money. A lot!"
                },
                {
                    "author": "Deleted",
                    "text": "[deleted]"
                },
                {
                    "author": "losvedir",
                    "text": "I bought mine with the idea it might work something like this, and for proofs of concept and demos like this it's absolutely incredible. But actually using it I've run into some issues.\n\nThe main issue is that holding the crown button resets your view. This is actually pretty nice because you can have your workflow around your laptop, move to the couch, hold that button, and have all the windows snap back around the laptop where they were. But that will also move the windows you want fixed in place (eg on the fridge).\n\nThere's also no \"expose\" type functionality to quickly explode out all your windows and peek at them. When I put windows all over, it was fun and cute, but then you kind of forget which ones are where, and while it's neat to have your grocery list on the fridge, it sucks to have to get up and walk to the fridge to see if something is on it, like we're in the 90s again.\n\nI think this video shows where we're headed, but I don't think we're quite there yet. VisionOS needs to grow a bit more functionality, but we'll get there. The first iPhone didn't have copy/paste, but someone from back then using an iPhone 15 would be overwhelmed since it was a new paradigm and all its idioms hadn't been internalized yet."
                },
                {
                    "author": "random_topix",
                    "text": "Thank you for this. I was starting to really worry and second guess my purchase (two weeks to go). The pass through looked good to me. Better than my Quest 3. And the FOV seemed decent as well.  I\u2019m even more excited now."
                },
                {
                    "author": "NegotiationOk7535",
                    "text": "Yes. This how I aim to use it. To replace everything.\nBut my question is why? Studio display, mac studio, ipad pro, lg 55 oled, all works well."
                },
                {
                    "author": "Fargle_Bargle",
                    "text": "While this looks slick, all these \u201cworkflow\u201d demos pretty much just seem like people opening safari and messages. For casual stuff like this it seems ideal, but for more serious work I can\u2019t see how being stuck with pro apps confined to one larger Mac window and iPad-level apps running around it is anything but a step down from a two monitor setup for a lot of people. I guess it depends though."
                },
                {
                    "author": "No_Fox7954",
                    "text": "Thanks for this overview. I\u2019m interested in this headset for productivity. I have a 57\u201d ultrawide monitor strapped to an M2 Max Studio. Vision Pro would not replace the 57\u201d for me, unless some sort of multi-monitor or alternative resolution support comes, but has anyone tried working with a physical monitor via pass-through? I imagine the experience would be subpar, but I am curious. Perhaps a physical monitor can be effectively augmented with VPro apps."
                },
                {
                    "author": "Hero0fTheFallen",
                    "text": "Circle desk , sit in the middle, swirl! \n\nYou could have everything open !!!"
                },
                {
                    "author": "seizethedayboys",
                    "text": "I really did try to use it for work but found it just didn't help, if anything it hindered. The Mac connection worked well enough but the head and eye movement was just too much to see everything on my screen. The foveated rendering also made parts of my Mac display blurry if I wasn't looking directly at it. But the most annoying thing was somehow my MacBook's keyboard suddenly became so laggy. Typing was a chore. Perhaps in the future it will be usable for productivity but not yet."
                },
                {
                    "author": "-6h0st-",
                    "text": "Waiting for version 2 or 3"
                },
                {
                    "author": "cgcmh1",
                    "text": "He said he was using a mouse? I thought they would not work with the AVP\u2026"
                },
                {
                    "author": "AKMtnr",
                    "text": "My main issue is the persistence of the windows. Will all of these placements remain this way, even after a reboot? After multiple reboots? I do a lot of beer brewing, I would love to have independent seven day timers over every fermentation tank that persist and countdown over the weeks, but it doesn\u2019t seem like something like this is possible right now."
                },
                {
                    "author": "ELCHOCOCLOCO",
                    "text": "Wow, just got mine and I'm so excited to unbox and try this out!"
                },
                {
                    "author": "Ghost_412345",
                    "text": "I\u2019m buying 2"
                },
                {
                    "author": "dramafan1",
                    "text": "I think this is the best \"in the life\" of using Vision Pro yet I've seen. This really shows the \"spatial computing\" Apple was trying to talk about."
                },
                {
                    "author": "Financial-Customer87",
                    "text": "I\u2019m very curious has anyone found something that you can\u2019t do with AVP ?"
                },
                {
                    "author": "Currymillerlee",
                    "text": "amazing"
                },
                {
                    "author": "InterstellarReddit",
                    "text": "I was adamant about apples use of spatial computer until now. This makes complete sense."
                },
                {
                    "author": "The21stPM",
                    "text": "For less than half the money you could buy multiple devices and lay them out in front of you for the exact same experience. Except you won\u2019t have a sore head, you\u2019ll have saved money and most importantly you won\u2019t look like an idiot."
                },
                {
                    "author": "Reelevant",
                    "text": "Memory Palace"
                },
                {
                    "author": "Mclarenrob2",
                    "text": "Who needs expensive interior design, you could just live in a shipping container with a basic bed and chair and everything else is fake xD"
                },
                {
                    "author": "pjsoul",
                    "text": "Something i haven't heard anyone talk about is the fact that all the apps are touch operated like an ipad. So if the app is in arms length you dont need to look and pinch, you can touch.."
                },
                {
                    "author": "Alexis-FromTexas",
                    "text": "And now I see why apple never got into the tv market. I can see TVs always being around but not as much as they are today. Once I get all my screens up and running I\u2019m going to have trouble living life without AVP"
                },
                {
                    "author": "Unwitting_Observer",
                    "text": "Ok my question is: if your roommate has one, can you share (some) screens? Meaning: keep the same screen in the same position between two headsets?"
                },
                {
                    "author": "CaptainLoneRanger",
                    "text": "I spent all  day in it today. They crossed the threshold in a way I think only Apple could. It\u2019s like someone over there finally channeled Jobs himself; saw a beautiful concept, a vision that made sense as a viable product, and pushed a company to make it happen. Marketing was lackluster, but the end result for us is remarkable.\n\nI\u2019m back to watching Interstellar in stunning detail\u2026in the snowy mountains. Y\u2019all f*** off."
                },
                {
                    "author": "PeskyFerret",
                    "text": "It\u2019s amazing that screens can be pinned like that. I didn\u2019t know it could do that"
                },
                {
                    "author": "Deleted",
                    "text": "I just don\u2019t see the hype for more serious work. I\u2019m a design aerothermal engineer. I need to have CFD/Ansys and other resources\n\nIf the job consists of emails/PowerPoints I guess this is ideal"
                },
                {
                    "author": "ohiocardsfan",
                    "text": "This is pure smoke. The real experience sucks. The device is heavy. I have one. I am returning mine asap."
                },
                {
                    "author": "Necessary_Ad_9800",
                    "text": "Neck strain hello?"
                },
                {
                    "author": "darkspd96",
                    "text": "Pretty cool, not worth $3,500"
                },
                {
                    "author": "Adityanpradhan",
                    "text": "don\u2019t forget binocular view"
                },
                {
                    "author": "Deleted",
                    "text": "You are mentally ill"
                },
                {
                    "author": "myfeltboots",
                    "text": "i have my significant other throw me objects for no reason too"
                },
                {
                    "author": "Deleted",
                    "text": "You literally can do this on a quest 3"
                },
                {
                    "author": "Hopeemmanuel",
                    "text": "Gosh it\u2019s beautiful"
                },
                {
                    "author": "Deleted",
                    "text": "I love my Samsung Ark monitor and how it curves, how do I enabled curved windows?"
                },
                {
                    "author": "Deleted",
                    "text": "That is pretty sick."
                },
                {
                    "author": "cameronpetitti",
                    "text": "Thank you so much man! More helpful video than most of the reviews!"
                },
                {
                    "author": "nusodumi",
                    "text": "If two people have them on, can you share TV screens to watch movies and stuff on the living room wall?\n\nIf she walks in, will she see the porn playing on your private window?"
                },
                {
                    "author": "ChickenStripEater",
                    "text": "When you look at the \u201cvirtual\u201d screens, is the text blurry at all? I know with the few VR headsets I\u2019ve used there\u2019s a small blur to everything which would make reading a lot of text cumbersome."
                },
                {
                    "author": "Mast3rCylinder",
                    "text": "This is insane."
                },
                {
                    "author": "AleyahhhhK",
                    "text": "When we get a few more updates this would be so worth the purchase"
                },
                {
                    "author": "ThePatientIdiot",
                    "text": "How did you get the screen to computer screen to appear in your VP window"
                },
                {
                    "author": "jacropolis",
                    "text": "So when you take it off does it remember where everything was? Or do you have to go walk around your place and set up every window again?"
                },
                {
                    "author": "Harvey-Zoltan",
                    "text": "The passthrough looks fine to me in this video. From the comments some people have been making I was expecting it to be terrible."
                },
                {
                    "author": "Mukke1807",
                    "text": "Looks cool and all, but what is the actual benefit?\n\nHaving multiple windows and applications open is cool, but I can do that on any device already. \n\nHaving the notes for the groceries on the fridge is nice, but how does that help me in the shopping process?\n\nWhy would I NEED a VR headset for work? Work doesn\u2019t need to be immersive, it needs to be productive. And none of these features increase your productivity.\n\nGames are very different kind of thing and I see the benefit there, but working via VR just transfers your desk from one computer to another."
                },
                {
                    "author": "Ttmdrew",
                    "text": "Cool asf"
                },
                {
                    "author": "durangojim",
                    "text": "Cool demonstration! Is it more efficient though than having some of those things on a Mac and just having a normal tv? It seems kind of like a hassle to have to turn your body to see different apps or to have music across the room. Very cool showing its capabilities but wondering how likely it is to actually to continue to use it that way."
                },
                {
                    "author": "durangojim",
                    "text": "Do all the things stay in place when you take the AVP off and put it back on the next day?"
                },
                {
                    "author": "mightylordredbeard",
                    "text": "What\u2019s the app you download for the cute wife overlay that you had pinned to the other room?"
                },
                {
                    "author": "JCatNY",
                    "text": "Excellent demonstration, and my passthrough is about same quality of what you're showing."
                },
                {
                    "author": "Nice_Surprise3595",
                    "text": "Very nice\nRealized i can do this in my quest 3 or pro...still cool though"
                },
                {
                    "author": "SteveCantScuba",
                    "text": "Honestly thought people looked goofy when I saw them at store. Even goofier with 2-3 hour charge and a 1st gen device\u2026 Have to admit this is a cool video. Concerned about privacy though. Basically letting a company map your house and life. That data is sensitive."
                },
                {
                    "author": "Thisisnow1984",
                    "text": "Was the girlfriend real or AR?"
                },
                {
                    "author": "N05L4CK",
                    "text": "The one thing about workflow stuff I don\u2019t like, is how hard it is to do when you\u2019re in an environment.  I want to do my work by the lake, but when I transport there I\u2019d like to be able to see my keyboard and desk as well, without having to go halfway out of the immersion."
                },
                {
                    "author": "LeNomReal",
                    "text": "Why does the woman throw you a ball?"
                },
                {
                    "author": "snowdn",
                    "text": "This is cool, it\u2019s just not worth $4,000."
                },
                {
                    "author": "Prize_Bar_5767",
                    "text": "Do you need a MacBook connected for a Mac to work? Or it comes inbuilt with the macOS?"
                },
                {
                    "author": "Ghost_412345",
                    "text": "How is linked though , do you have a subscription to Vision Pro"
                },
                {
                    "author": "Name_goez_here",
                    "text": "Okay this is cool AF to bad I live in a small arse house lol"
                },
                {
                    "author": "Time-Elevator-6142",
                    "text": "nice try apple"
                },
                {
                    "author": "markworsnop",
                    "text": "I\u2019ve only had a few hours playing around with my Vision Pro and I had no idea it would do all of that. Very very cool."
                },
                {
                    "author": "trantaran",
                    "text": "You guys make money from walking around the house and catching tennis balls? Jealous!!"
                },
                {
                    "author": "Deleted",
                    "text": "But..but I don\u2019t *HAVE* $3500 for a AVP\ud83d\ude14\ud83d\ude22"
                },
                {
                    "author": "Relief-Old",
                    "text": "This is gonna make my iron man dreams come true, sans the flying bit"
                },
                {
                    "author": "GeneSplitter0x0",
                    "text": "I\u2019m so pissed that there is an APPLE ID requirement to use Mac with AVP. Obviously companies aren\u2019t going to give their employees a AVP but I use a MAC at work and would love to have the screen features\u2026. Unfortunately this restriction impacts a lot of people besides myself."
                },
                {
                    "author": "4hoenix",
                    "text": "Is the text on the screens hard to read at all?"
                },
                {
                    "author": "Rakaniam",
                    "text": "You, my friend, are a genius!"
                },
                {
                    "author": "Astronomer_Various",
                    "text": "Wait you didn't show us the pinned screen in the bathroom \ud83d\ude02\n\nI know there's one in there \ud83d\ude2d\ud83d\ude02\ud83d\ude02"
                },
                {
                    "author": "Deleted",
                    "text": "That\u2019s better AD than Apple\u2019s itself!"
                },
                {
                    "author": "RobinGoods",
                    "text": "limits to one external desktop tho! So sad. I\u2019ll wait for the next one"
                },
                {
                    "author": "The-Sherpa",
                    "text": "For anyone that gets dizzy with VR sets, motion blur, does anyone know if the VP produces the same symptoms being that things arent actually moving?"
                },
                {
                    "author": "Slowmac123",
                    "text": "Cool af butI will wait 10 years when tech has advanced far enough to get this down into the size snd weight of a pair of glasses"
                },
                {
                    "author": "Medialunch",
                    "text": "The way I compute and watch stuff that thing would get really hot on my face."
                },
                {
                    "author": "RumBo11om",
                    "text": "Gabe doesn\u2019t work at Pied Piper anymore"
                },
                {
                    "author": "Deleted",
                    "text": "Nice to see the virtual set up. I hope you can get some real practical work done with the headset but if not, it\u2019s a learning experience and it will help them develop something that will do that.  It would be killer to have this headset work in Microsoft flight simulator, and DCS world. If you\u2019ve never flown a simulator in VR before it\u2019s spectacular and I know the Vision Pro would make the experience even better if it weren\u2019t on PC. Because of the hand tracking and better graphics, you could look down and see the labels on your dials and be able to flip the switches much easier and more naturally than the other headset.  If I remember correctly, X-PLANE 11 works on Mac, so maybe I\u2019ll see a review on YouTube of someone trying that sooner or later.  That\u2019s not as good as being fully immersed and being able to look around the cockpit, which is absolutely amazing if you\u2019ve never tried it before"
                },
                {
                    "author": "Rckid",
                    "text": "That's dope as FUUUUUUUUCK"
                },
                {
                    "author": "Capitaclism",
                    "text": "If it only works with a Mac it's pretty useless to most people."
                },
                {
                    "author": "Sudden-Struggle-",
                    "text": "I'm conflicted. On one side this is very cool and useful in some work environments.\n but on the other side you're having all your biometric data and scans of your living space all nicely collected and stored by Apple"
                },
                {
                    "author": "Accurate_Noise3731",
                    "text": "Wtf\ud83d\ude26"
                },
                {
                    "author": "-Riskbreaker-",
                    "text": "Whoa. Does this need a high end MacBook to run the various windows etc and then send to the AVP or does this all work from within the AVP itself (keyboard/mouse too)?"
                },
                {
                    "author": "ALLINXS",
                    "text": "Glad people ignorant to what\u2019s been current in ar/vr are finally catching up to it. When you have floating windows with glasses/contacts that will be the real future. This is like the big computers that took up a whole room."
                },
                {
                    "author": "Deleted",
                    "text": "All this features, for a low low prices of 4000$"
                },
                {
                    "author": "Sad_Ad4916",
                    "text": "New to VR ?"
                },
                {
                    "author": "Callisto778",
                    "text": "Amazing!"
                },
                {
                    "author": "ThirdEyeButterfly",
                    "text": "\u2026and pretty soon we will be walking around in our homes angrily swatting away floating ads for 15% off matching curtain tiebacks at Amazon."
                },
                {
                    "author": "Numerous-Roof-7544",
                    "text": "this thing gets old quick"
                },
                {
                    "author": "TimmG218",
                    "text": "Can you walk and type on virtual keyboard well?"
                },
                {
                    "author": "Deleted",
                    "text": "this further confirms 80% of people will be watching porn at all-times"
                },
                {
                    "author": "WithinAForestDark",
                    "text": "Killer app"
                },
                {
                    "author": "Unverifiablethoughts",
                    "text": "Are we not going to talk about the fact that something peed on the bedroom floor?"
                },
                {
                    "author": "PharmADD",
                    "text": "This is very cool - I just wonder if something more along the lines of HoloLens is more appropriate for this specific type of application. \n\nEven with low latency, it\u2019s a bit uncomfortable to think about navigating the real world through camera input displayed on a screen. It feels like somehow projecting the overlays onto an otherwise clear lens would be more ideal and useable for what this person is trying to demonstrate. I believe this is how HoloLens works, I\u2019m just not sure why it never really caught on."
                },
                {
                    "author": "Old-Boysenberry-3664",
                    "text": "Just googled \"average office space cost per employee or year\" and it's about $3800 in Atlanta. \n\nIf the price point keeps going down on these and capabilities keep increasing, this will definitely make it harder than it already is for corporations to justify holding onto office space."
                },
                {
                    "author": "wizardinthewings",
                    "text": "Do you have to search the whole house to find the auto-play YouTube video you left open yesterday?  \u201cOh god I left it at Steve\u2019s house!)\u201d\n\n(J/k for those haunted by auto play vids in your too-many tab nightmare)\n\nDefinitely interested in how it handles all the clutter, there must be a management UI?"
                },
                {
                    "author": "curiousclay",
                    "text": "bruvvvvvv yesssss this is what i've been trying to explain to people, but great job displaying it all thank you"
                },
                {
                    "author": "szzzn",
                    "text": "Can you still get your computer monitor with it in clamshell mode? \n\nI have kind shit and plugged into an Apple Studio Display most of the time. I\u2019m hoping it just gives me the option when I look at the studio display screen."
                },
                {
                    "author": "Appropriate-Role9361",
                    "text": "Would be cool for cooking, being able to put the recipe up beside you. I normally bring my Mac over to the counter but this would be more efficient with space"
                },
                {
                    "author": "Deago78",
                    "text": "Does that pinning remain if you power down the headset/unplug the battery pack?"
                },
                {
                    "author": "People4America",
                    "text": "Oh look, NFT use cases."
                },
                {
                    "author": "rhetoric9",
                    "text": "That\u2019s sick"
                },
                {
                    "author": "Cric1313",
                    "text": "If this actually meant much, people would already have their homes littered with more tvs than they already do"
                },
                {
                    "author": "Deleted",
                    "text": "After the goggles are turned off and back on again, do the apps resume at the same position they were left prior?"
                },
                {
                    "author": "2001skydog10",
                    "text": "My first intro to the Apple universe was the iPhone. I had a cell phone and an MP3 player & when my daughter came to visit from college with an iPhone 4 I was blown away and went and got one right away in spite of others mocking me because of the price, but I and have never looked back. Most of those who ridiculed me also have iPhones now. \nI have problems using a PC/Mac due to back & neck issues. I also have problems with the straight keyboard and use an ergonomic one. When the iPad was first announced, I may have been first in line to place an order. When it came, people laughed at me for paying that kind of money and couldn\u2019t see the point. Now you see iPads everywhere. The number of apps available compared to the start is amazing.\nThe type of work I do the AVP would be nice except for the keyboard issue. I\u2019m not a gamer, and I never sit down to watch a full movie or anything at one time so an AVP is not an advantage there either. At some point, possibly next GEN I will get one, just because I love cool tech to play with & the AVP is very special."
                },
                {
                    "author": "davejdesign",
                    "text": "I was told, at an in-store demo, that the apple magic keyboard works but the magic mouse does not. What mouse are you using in this video? Also, they said the apple track pad works, go figure."
                },
                {
                    "author": "_B_Little_me",
                    "text": "I\u2019m legit impressed."
                },
                {
                    "author": "foundmonster",
                    "text": "All of those things can be done fine with existing methods. \n\nHow is it better to do it with vision? Why not watch tv with the tv? Why not put a list of notes on paper on your fridge?"
                },
                {
                    "author": "ContributionComplete",
                    "text": "This one minute justifies AVPs existence more than the 300 minutes of reviews I've seen. Now I have something to link my friends to."
                },
                {
                    "author": "Baikken",
                    "text": "You sound like Jared from Silicon Valley!"
                },
                {
                    "author": "sleepingsnow99",
                    "text": "Bro this is giving me ideas of ready player one. Imagine virtual scapes and realms where you left it as is."
                },
                {
                    "author": "Commercial_Drama6104",
                    "text": "Apple going to 10 trillion dollar company after this... I'm absolutely blown away... This is coming from someone that thinks apple product has been unimpressive for the last 10 years."
                },
                {
                    "author": "Sorry_Garlic",
                    "text": "I think Apple did not spend much on marketing deliberately as these ppl are pushing its limit and showing the possibilities."
                },
                {
                    "author": "Loon_Cheese",
                    "text": "U/drstemsell\nI haven\u2019t even opened mine because I don\u2019t use most of apples software. Doing a demo tomorrow\u2026 what I really want to know is, can you have multiple screens of safari open? Can you change the ratio that your computer  display outputs to ultra wide? How is slack working?"
                },
                {
                    "author": "geniium",
                    "text": "Doh, this is amazing! This is the missing ad for Apple!"
                },
                {
                    "author": "SpellGlittering1901",
                    "text": "Oh so it sticks. But my question is : if I activate travel mode and puts the apps a certain way in front of me (let\u2019s say YouTube in front, messages on the right, notes on top) does it sticks like this in front of me while I move ?"
                },
                {
                    "author": "danbedford",
                    "text": "You can see the windows through the walls of the physical environment, and it seems the headset is \u201caware\u201d that it\u2019s seeing those windows through the wall by fading the windows in some way\u2026 possibly? I\u2019m not too sure, since we don\u2019t actually see the transition for the windows blocked by the walls of the room the other person was in.\n\nIf this is true, are they treated differently because they are seen through a wall, and can you still interact with them in this state?"
                },
                {
                    "author": "n0_gods_no_masters",
                    "text": "Apple didnt mention that you could pin screens like that in their showcase, or did I miss that? This footage shows more productivity and functionality than Apple did."
                },
                {
                    "author": "Curious397",
                    "text": "It is really nice. Too bad it is not so clear for me with the optical inserts, even though when I hold them to my eyes they work perfectly. The actual external monitor is often clearer. Also get a headache from continued use.\n\nSo this is a really cool demo. Question is, how long can he stand \u201cworking\u201c in that setup?"
                },
                {
                    "author": "That-SoCal-Guy",
                    "text": "From this screen recording the pass through looks fine to me. \u00a0I\u2019ve seen the Quest\u2019s pass through in completion. I don\u2019t know what people are complaining about. \u00a0"
                },
                {
                    "author": "Creepy-Difference808",
                    "text": "cool"
                },
                {
                    "author": "sujovian",
                    "text": "What\u2019s the resolution of iPad apps in VisionPro? I\u2019m particularly interested in DuetAir, and if it can be a functional working environment for WindowsPC in VisionOS"
                },
                {
                    "author": "shaneakus",
                    "text": "\u201cWorking\u201d"
                },
                {
                    "author": "Coeruleus_",
                    "text": "Does it make your eyes bleed? I hear it does"
                },
                {
                    "author": "cwhit122",
                    "text": "I\u2019m waiting to see the actual work flow being done. Can\u2019t  even use business apps via MS since it doesn\u2019t support intune"
                }
            ]
        },
        {
            "link": "https://www.reddit.com/r/VisionPro/comments/1b25jmr/had_an_app_idea_this_weekend_its_a_virtual_window/",
            "title": "Had an app idea this weekend, it's a virtual window for viewing panoramas. I'm calling it Windora...looking for some testers",
            "selftext": "",
            "comments": [
                {
                    "author": "frsti",
                    "text": "What a great idea!"
                },
                {
                    "author": "ellenich",
                    "text": "Sign me up! Great idea."
                },
                {
                    "author": "jimmypopjr",
                    "text": "I'm on TestFlight and would love to help you test. I've been waiting for someone to make an app like this."
                },
                {
                    "author": "jnorris441",
                    "text": "FYI I didn't get a public Beta approved for it yet...I am just inviting some internal testers right now to see if there are any problems. I will update if there is a public beta link."
                },
                {
                    "author": "dogsaybark",
                    "text": "Looks cool!  I\u2019ve got a buddy on a ski trip this weekend and I told him to send me some killer panos from the slopes!  I\u2019ll give this a go if you still need testers."
                },
                {
                    "author": "XiXMak",
                    "text": "I would love to test it"
                },
                {
                    "author": "GenghisFrog",
                    "text": "That sounds incredible. I\u2019ve been taking lots of panoramas recently. I\u2019d love to try it."
                },
                {
                    "author": "virtual_adam",
                    "text": "Non AVP user here: would the device / SDK allow you to be with your head \u201cout\u201d of the window? And then back \u201cin\u201d? Just by walking. Or is it always 2 feet ahead of you\u00a0"
                },
                {
                    "author": "drew1027",
                    "text": "Sounds like a good idea, panoramas from photo albums viewed on Vision Pro are amazing"
                },
                {
                    "author": "las7chance",
                    "text": "There is someone thinking with their brain. Simple but genius :)"
                },
                {
                    "author": "Arnav33",
                    "text": "Would love to test it!"
                },
                {
                    "author": "iLife87",
                    "text": "I\u2019ll try it"
                },
                {
                    "author": "NewShadowR",
                    "text": "Just wondering, why do you raise your hand to the position of icons to pinch? Isn't selection done by eye tracking?"
                },
                {
                    "author": "fraize",
                    "text": "This is a great idea. I returned my AVP but I would definitely use this when / if I get it back."
                },
                {
                    "author": "JoeyDee86",
                    "text": "It\u2019s like the Iconian Gateway from Star Trek :D"
                },
                {
                    "author": "thinkingperson",
                    "text": "Love this app ... can see this changing small apartments dynamics!! Too bad I have a pico 4 and not AVP ... ..."
                },
                {
                    "author": "johnnyteknoska",
                    "text": "I would love to have multiple windows with the same panorama behind. The goal will be to draw the windows where I have my real ones and change the videos of my home."
                },
                {
                    "author": "igerard8",
                    "text": "Count me in!"
                },
                {
                    "author": "camXmac",
                    "text": "Soon we will live in concrete boxes with fake windows. Entering the matrix!"
                },
                {
                    "author": "Brick_Lab",
                    "text": "Damn so good and so simple. I'm up for it"
                },
                {
                    "author": "Nicinus",
                    "text": "Love it"
                },
                {
                    "author": "Irritated_Koala",
                    "text": "This is a very nice concept. I am really excited to see this develop!"
                },
                {
                    "author": "Due_Leadership5858",
                    "text": "Public service announcement: When selecting a panorama from your own library, be sure and check the edges of the image. I think that Kielbasa is a little bit embarrassed about my selection in this case. \ud83d\udc36\n\nhttps://youtu.be/An-n1SVVnRM?si=jWa5TXYkeKvbqbPm"
                },
                {
                    "author": "benji10047",
                    "text": "Man, this is beyond impressive. Love how it looks! Best of luck succeeding."
                },
                {
                    "author": "SirCaptainReynolds",
                    "text": "Love this idea. I was thinking about something similar where people could pay to have environments that are more than just what\u2019s currently offered. Being able to walk around in really cool spaces you might never get to check out or visit."
                },
                {
                    "author": "chosen2nd",
                    "text": "Man it\u2019d be awesome if there was movement like birds or a deer that rarely shows"
                },
                {
                    "author": "CoMmOn-SeNsE-hA",
                    "text": "So cool\u2026reminds me of Netflix on oculus"
                },
                {
                    "author": "joeo24",
                    "text": "Would love to test this! Been waiting for someone to make this app a reality :)"
                },
                {
                    "author": "Equivalent_Owl_5644",
                    "text": "This guy wins Vision Pro. What an outstanding idea!"
                },
                {
                    "author": "itsnandy",
                    "text": "Down to give some feedback!"
                },
                {
                    "author": "GOD_RaZoR",
                    "text": "Im in too if actual"
                },
                {
                    "author": "mtran1210",
                    "text": "I just got my Vision Pro and would love to test!"
                },
                {
                    "author": "jnorris441",
                    "text": "Windora is on the app store now. https://apps.apple.com/us/app/windora/id6478598855"
                },
                {
                    "author": "Curious397",
                    "text": "Fantastic idea. I\u2019m available to test."
                },
                {
                    "author": "Flo_rian2340",
                    "text": "Hi there, this is a novel concept. Happy to join the test flight if you still have spots open."
                },
                {
                    "author": "Emotion-Aggravating",
                    "text": "I\u2019d love to test it out geat idea"
                },
                {
                    "author": "tf1gom",
                    "text": "Just saw this on the App Store today and remembered this post. Congrats!!"
                },
                {
                    "author": "iqandjoke",
                    "text": "Similar to Bill Gate\u2019s idea in 1995!\n\nhttps://youtu.be/fs-YpQj88ew?t=5m45s"
                },
                {
                    "author": "No-Cream8785",
                    "text": "HOLY CRAP PLEASE SIGN ME UP IVE BEEN WAITING FOR THIS FOR SO LONG"
                },
                {
                    "author": "DoctorProfessorTaco",
                    "text": "Holy shit genius, I gotta try this"
                },
                {
                    "author": "Public-Big8482",
                    "text": "I\u2019d love to test it"
                },
                {
                    "author": "Batting1k",
                    "text": "Would love to sign up!"
                },
                {
                    "author": "BowieXu",
                    "text": "Looks pretty cool! Will be great if I can test it!  Apple ID: [buyi.xu@oppo.com](mailto:buyi.xu@oppo.com), thanks in advance."
                },
                {
                    "author": "mb194dc",
                    "text": "Total Recall wants its idea back"
                },
                {
                    "author": "afearisthis",
                    "text": "I feel like you need a window pane effect or someone is going to hit their head trying to stick it out the window\u2026 great idea though"
                },
                {
                    "author": "7stringjazz",
                    "text": "All the shaking and moving windows woukd give me a headache, probably fuck with my sleep cycle and effect my psychological stability."
                },
                {
                    "author": "rieboldt",
                    "text": "Trash"
                },
                {
                    "author": "elliotttate",
                    "text": "I'd love to test it!"
                },
                {
                    "author": "D0NTEXPECTMUCH",
                    "text": "This is really clever, I\u2019d like to try it too"
                },
                {
                    "author": "mupepe9",
                    "text": "I\u2019m up for it if you\u2019re still looking for testers"
                },
                {
                    "author": "veltche9364",
                    "text": "Would love to test"
                },
                {
                    "author": "BlueGalaxy1000",
                    "text": "I would love to test it!! Thank you!"
                },
                {
                    "author": "mlitkey",
                    "text": "Would love to test if you are still looking for testers"
                },
                {
                    "author": "ray120",
                    "text": "Would like to test."
                },
                {
                    "author": "tmkins",
                    "text": "i'm in - please share a testflight link!"
                },
                {
                    "author": "Alternative-Bat-2462",
                    "text": "Happy to help"
                },
                {
                    "author": "akfourty7",
                    "text": "I'd love to test for ya, lmk if you are still looking"
                },
                {
                    "author": "speeduae",
                    "text": "id like to test it"
                },
                {
                    "author": "Pretzeloid",
                    "text": "Awesome!  I would love to test this!!"
                },
                {
                    "author": "RAL7004",
                    "text": "Would love to test it, too!"
                },
                {
                    "author": "sgtkellogg",
                    "text": "You should just call it \"Windows\""
                },
                {
                    "author": "tchock23",
                    "text": "Count me in for testing it out"
                },
                {
                    "author": "Commercial-Frame-773",
                    "text": "I\u2019ll try it"
                },
                {
                    "author": "dr_nick_riveria",
                    "text": "Would love to test as well!"
                },
                {
                    "author": "Staff_Mission",
                    "text": "Is the scene 3D?"
                },
                {
                    "author": "achilleshightops",
                    "text": "How hard was it to code this?"
                },
                {
                    "author": "yroc44",
                    "text": "This is sick! Would love a TestFlight link \ud83d\ude4f"
                },
                {
                    "author": "Magnus919",
                    "text": "I\u2019m interested"
                },
                {
                    "author": "Agreeable_Bonus725",
                    "text": "That is so cool! sign me up!"
                },
                {
                    "author": "krevdditn",
                    "text": "Oh shit you\u2019ll be able to tap into your home security cameras and doorbell."
                },
                {
                    "author": "SkiMTBCO",
                    "text": "Very Cool, I\u2019m in."
                },
                {
                    "author": "formerairline",
                    "text": "I\u2019m interested"
                },
                {
                    "author": "Kwhyc",
                    "text": "Really awesome idea! If you need any more testers, let me know! Otherwise I look forward to seeing it on Testflight for a larger beta, or when it's on the app store!"
                },
                {
                    "author": "coltx654",
                    "text": "Lemme know if you\u2019re still looking for feedback/testers!"
                },
                {
                    "author": "thepathlesstraveled6",
                    "text": "Damn that's thinking outside the box"
                },
                {
                    "author": "Impressive_Equal3452",
                    "text": "sign me up!"
                },
                {
                    "author": "Sudden_Charity_9933",
                    "text": "I would love to take this for a test flight!"
                },
                {
                    "author": "Practical_Mongoose69",
                    "text": "Hey! can i test?"
                },
                {
                    "author": "vnnkl",
                    "text": "sign me up"
                },
                {
                    "author": "Deleted",
                    "text": "That looks pretty awesome"
                },
                {
                    "author": "Daveboi7",
                    "text": "Please sign me up! :)"
                },
                {
                    "author": "efernan5",
                    "text": "Would love to test it too!"
                },
                {
                    "author": "Lancaster61",
                    "text": "You should create a \u201cstore\u201d where people can share their panoramas too"
                },
                {
                    "author": "ampsonic",
                    "text": "Great idea, happy to test."
                },
                {
                    "author": "SmokinMagic",
                    "text": "Sign me up!"
                },
                {
                    "author": "JoeyKX",
                    "text": "Would love to help as well if you still need people"
                },
                {
                    "author": "Kinglis",
                    "text": "I work in a facility with no external windows, so this is a fantastic idea. Would be glad to test for/with you"
                },
                {
                    "author": "eineken83",
                    "text": "Brilliant! I\u2019d love to have something like this! Got TestFlight and would love to help."
                },
                {
                    "author": "corkycorkyhey",
                    "text": "There are like 3 apps that already do exactly this.  One of them literally has a window frame overlay"
                },
                {
                    "author": "cavafycp",
                    "text": "Im down to test this too!"
                },
                {
                    "author": "Ecnarps",
                    "text": "Happy to TestFlight!"
                },
                {
                    "author": "King_0zymandias",
                    "text": "Hey that'd be great, I'd be game to try"
                },
                {
                    "author": "wepiii",
                    "text": "Would love to Test! This is awesome"
                },
                {
                    "author": "quintsreddit",
                    "text": "I\u2019d love to test this, it looks super neat :)"
                },
                {
                    "author": "Gundislav",
                    "text": "If you still need testers, I\u2019m down. I took a few panoramas last year on my trip to Iceland."
                },
                {
                    "author": "atticus04",
                    "text": "Interested!"
                },
                {
                    "author": "mr_baby_pigeon",
                    "text": "I\u2019d be happy to test it out."
                },
                {
                    "author": "MuncleUscles",
                    "text": "Love it, would be happy to try it out"
                },
                {
                    "author": "rrrand0mmm",
                    "text": "This is sick!"
                },
                {
                    "author": "iamfromtwitter",
                    "text": "i dont have a vision pro but i was thinking maybe you could add some kind of parallax mapping to the panorama texture."
                },
                {
                    "author": "uzapy",
                    "text": "all in, please sign me up as well."
                },
                {
                    "author": "Few-Expression-1014",
                    "text": "Looks great!  Love to test!"
                },
                {
                    "author": "Manson2k",
                    "text": "God, love this idea! Testflight member here, would love to try as well."
                },
                {
                    "author": "joeo24",
                    "text": "Would love to test this! Been dreaming of this idea since seeing Treasure Planet as a kid!"
                },
                {
                    "author": "808TRK",
                    "text": "I'm interested in trying it if you still have room for testers."
                },
                {
                    "author": "Deleted",
                    "text": "So cool, i would love it to be pushed further. Like what if we can see kyoto during the edo periord or 1920s paris?"
                },
                {
                    "author": "MaterialTemporary763",
                    "text": "Great idea, would love to try"
                },
                {
                    "author": "monkeyonreefer",
                    "text": "Would love to test"
                },
                {
                    "author": "Former_Bill_1126",
                    "text": "I\u2019d test it out!"
                },
                {
                    "author": "mattdelliott",
                    "text": "Looks awesome! I'll give it a go also."
                },
                {
                    "author": "RyanLM80",
                    "text": "That\u2019s really cool! Quick question for the actual color of the inside wall of the window do you automatically detect that?"
                },
                {
                    "author": "YellowBlush",
                    "text": "That looks amazing! I\u2019d absolutely test that! I\ufe0f am testing several apps in TestFlight already."
                },
                {
                    "author": "Swankyview",
                    "text": "Amazing idea!"
                },
                {
                    "author": "texasproof",
                    "text": "This is so cool. Would love to test it out."
                },
                {
                    "author": "InItsTeeth",
                    "text": "Oh yes please!!"
                },
                {
                    "author": "sbonnot1",
                    "text": "Interested!"
                },
                {
                    "author": "NomadicHumanoid",
                    "text": "This is amazing!"
                },
                {
                    "author": "raines",
                    "text": "I\u2019ve spent the past decade shooting panoramas of intentional communities, looking forward to tools like this to help people explore them immersively.\n\nhttps://preview.redd.it/do4t30zfdclc1.jpeg?width=14802&format=pjpg&auto=webp&s=278ae8b2ae5b0bc6df88d2220c7d4fe823e36f47"
                },
                {
                    "author": "yepher",
                    "text": "I'm on test flight. Would love to help test it out"
                },
                {
                    "author": "CaprionRS",
                    "text": "Love this. Can put a \u201cwindow\u201d of an epic scene. \n\nWould love to try!"
                },
                {
                    "author": "midnightcaptain",
                    "text": "This is great. I would love to be able to just set this to always replace a particular real window or blank wall and have it rotate through different panoramas in my library, choosing one based on the time of day it was taken."
                },
                {
                    "author": "jmar31",
                    "text": "Would love to try this"
                },
                {
                    "author": "vinced45",
                    "text": "Awesome! Sign me up as well!"
                },
                {
                    "author": "Bright_Ability2025",
                    "text": "I'd gladly test it and give feedback"
                },
                {
                    "author": "szzzn",
                    "text": "Looks awesome I want to try it out"
                },
                {
                    "author": "bambiS2",
                    "text": "Sign me please"
                },
                {
                    "author": "RHc137",
                    "text": "Yes please!"
                },
                {
                    "author": "hirolux22",
                    "text": "Nice! Would love to test and provide feedback!"
                },
                {
                    "author": "reallydisleksic",
                    "text": "Happy to test if you\u2019re still looking for people!"
                },
                {
                    "author": "beansaretasty",
                    "text": "on TestFlight and would love to test this!"
                },
                {
                    "author": "lll61and49lll",
                    "text": "I\u2019d let a friend use my AVP to let them see what it\u2019s all about and set up Goatse in a window\ud83d\ude2d"
                },
                {
                    "author": "matrixagent69420",
                    "text": "A Star Wars window like you\u2019re on a spaceship would be cool"
                },
                {
                    "author": "Avid1",
                    "text": "Looks interesting! I\u2019m down to test"
                },
                {
                    "author": "Solkre",
                    "text": "I've got quest3 money, not visionpro money but I love the idea.  good job."
                },
                {
                    "author": "Musicmonkey34",
                    "text": "I love it! It would be really cool if you could select different styles of windows, like arches, or wrought iron like at this ice cream shop in Brooklyn: [https://www.google.com/maps/place/Van+Leeuwen+Ice+Cream/@40.686723,-73.990156,3a,75y,90t/data=!3m8!1e2!3m6!1sAF1QipMAbpTFrKTYC6OPQfzpoC3QRskb67klhz-P6W-V!2e10!3e12!6shttps:%2F%2Flh5.googleusercontent.com%2Fp%2FAF1QipMAbpTFrKTYC6OPQfzpoC3QRskb67klhz-P6W-V%3Dw203-h270-k-no!7i2775!8i3700!4m11!1m2!2m1!1svan+leeuwen+ice+cream!3m7!1s0x89c259444d5b4ee9:0xfb245f80528eb5a7!8m2!3d40.686723!4d-73.990156!10e5!15sChV2YW4gbGVldXdlbiBpY2UgY3JlYW0iA4gBAVoXIhV2YW4gbGVldXdlbiBpY2UgY3JlYW2SAQ5pY2VfY3JlYW1fc2hvcOABAA!16s%2Fg%2F1tscpy9l?entry=ttu](https://www.google.com/maps/place/Van+Leeuwen+Ice+Cream/@40.686723,-73.990156,3a,75y,90t/data=!3m8!1e2!3m6!1sAF1QipMAbpTFrKTYC6OPQfzpoC3QRskb67klhz-P6W-V!2e10!3e12!6shttps:%2F%2Flh5.googleusercontent.com%2Fp%2FAF1QipMAbpTFrKTYC6OPQfzpoC3QRskb67klhz-P6W-V%3Dw203-h270-k-no!7i2775!8i3700!4m11!1m2!2m1!1svan+leeuwen+ice+cream!3m7!1s0x89c259444d5b4ee9:0xfb245f80528eb5a7!8m2!3d40.686723!4d-73.990156!10e5!15sChV2YW4gbGVldXdlbiBpY2UgY3JlYW0iA4gBAVoXIhV2YW4gbGVldXdlbiBpY2UgY3JlYW2SAQ5pY2VfY3JlYW1fc2hvcOABAA!16s%2Fg%2F1tscpy9l?entry=ttu)"
                },
                {
                    "author": "tgibeau",
                    "text": "Sign me up as well!"
                },
                {
                    "author": "cheesepuff18",
                    "text": "Would love to test it"
                },
                {
                    "author": "Top_Tour6196",
                    "text": "I\u2019d be happy to help test!"
                },
                {
                    "author": "DimitriElephant",
                    "text": "I\u2019m on test flight, hit me up, looks super cool"
                },
                {
                    "author": "DonnayWinterford",
                    "text": "I\u2019m happy to test could you share a link?"
                },
                {
                    "author": "pbbpwns",
                    "text": "This is amazing."
                },
                {
                    "author": "oneyoucantrust",
                    "text": "Would love to test this, thank you!"
                },
                {
                    "author": "twokiloballs",
                    "text": "looks very cool. send me testflight!"
                },
                {
                    "author": "gokhanbas",
                    "text": "The app looks very cool, this is a very good idea. Sign me up please!"
                },
                {
                    "author": "iamgarffi",
                    "text": "Any TestFlight available OP? Looks fantastic. \n\nConsider supporting different window frames too :-)"
                },
                {
                    "author": "Klexme",
                    "text": "I\u2019d also love to test it out"
                },
                {
                    "author": "rlay001",
                    "text": "I\u2019d love to test it.  Also would love advice on how to take high resolution panoramas that isn\u2019t the Apple camera method."
                },
                {
                    "author": "DivinityDeluxe",
                    "text": "Awesome idea! I\u2019d love to test it out and give some feedback."
                },
                {
                    "author": "Big-Veterinarian740",
                    "text": "Wow. This is beautiful. I\u2019d love to test this as well."
                },
                {
                    "author": "cowbomber",
                    "text": "May I test this? This looks awesome!"
                },
                {
                    "author": "Org4nik",
                    "text": "Me me me! Looks very cool!"
                },
                {
                    "author": "aceestes",
                    "text": "Oohh I want to test it. I want to see how long it takes before I inevitably put my head through the wall lol. This looks pretty awesome."
                },
                {
                    "author": "thesquadphil",
                    "text": "Would love to test this. Looks great!"
                },
                {
                    "author": "Drawerpull",
                    "text": "Please let me test!"
                },
                {
                    "author": "Deleted",
                    "text": "Add in different styles of windows like floor to ceiling"
                },
                {
                    "author": "chintis123",
                    "text": "Looks insane! Sign me up"
                },
                {
                    "author": "zeekxx1",
                    "text": "I get mine Friday, happy to test after that."
                },
                {
                    "author": "chintis123",
                    "text": "Looks beautiful ! Sign me up"
                },
                {
                    "author": "WesleyWex",
                    "text": "Sign me up :D"
                },
                {
                    "author": "DoNoDuplicate",
                    "text": "Love this idea, well done!"
                },
                {
                    "author": "Rare_Stay_3501",
                    "text": "I ll try it"
                },
                {
                    "author": "Rare_Stay_3501",
                    "text": "I ll try it"
                },
                {
                    "author": "idreamer23",
                    "text": "Another volunteer here!"
                },
                {
                    "author": "ninmario890",
                    "text": "I can see myself sticking my head out the window  and  either breaking the AVP or the wall. Great idea though!"
                },
                {
                    "author": "ninmario890",
                    "text": "I can see myself sticking my head out \nthe window  and  either breaking the AVP or the wall. Great idea though!"
                },
                {
                    "author": "fakemickjagger",
                    "text": "Sign me up!"
                },
                {
                    "author": "Main-Reporter-1966",
                    "text": "Would be honored to test!"
                },
                {
                    "author": "JesseWebDotCom",
                    "text": "Awesome, I\u2019m in!"
                },
                {
                    "author": "natiahs",
                    "text": "Hey, very interested in testing if you're not already full."
                },
                {
                    "author": "rwl4z",
                    "text": "Looks great! I\u2019d love to try it!"
                },
                {
                    "author": "Deleted",
                    "text": "This is why the Apple Vision is rad. Apple sold this device with not much on it sure, but it\u2019s already leading to some really innovative and cool stuff"
                },
                {
                    "author": "clearbrian",
                    "text": "reminds me of this website that kept people sane during lockdown  \n[https://www.window-swap.com/](https://www.window-swap.com/)"
                },
                {
                    "author": "Apprehensive_Artist9",
                    "text": "Sign me up. Great idea"
                },
                {
                    "author": "sharpleft",
                    "text": "Very, very cool! I love how the window looks like it's really part of the wall. Is this built on realitykit?"
                },
                {
                    "author": "PuddyTheGreaseMonkey",
                    "text": "I\u2019d love to test! Looks awesome"
                },
                {
                    "author": "PuddyTheGreaseMonkey",
                    "text": "I\u2019d love to test! Looks awesome"
                },
                {
                    "author": "DigitalNomad1010",
                    "text": "I\u2019m available !"
                },
                {
                    "author": "zeazzz",
                    "text": "I\u2019m on TestFlight as well and would love to help test."
                },
                {
                    "author": "calvincrack",
                    "text": "Brilliant"
                },
                {
                    "author": "Stock-Initiative7081",
                    "text": "I\u2019m here, from italy, how can i try?"
                },
                {
                    "author": "thehighkinghimself",
                    "text": "Looks cool I\u2019d try it out."
                },
                {
                    "author": "kodezero911",
                    "text": "Ready to test if codes still available"
                },
                {
                    "author": "SeniorCaptain",
                    "text": "Awesome idea! I\u2019d love to try it."
                },
                {
                    "author": "La7ish",
                    "text": "I'm interested. I take a ton of Panoramas with my drone so I would love to test"
                },
                {
                    "author": "Pifman",
                    "text": "I'm curious why you are raising your hand all the way up and \\*pinching\\* the thumbnails themselves, opposed to just looking at it and pinching your fingers are a more comfortable position?"
                },
                {
                    "author": "wstoneman",
                    "text": "This looks awesome. I think it would make my workspace not feel so isolated. Sign me up please!"
                },
                {
                    "author": "SaintRavenz",
                    "text": "Me! I'll be your QA"
                },
                {
                    "author": "joedevivo",
                    "text": "this looks great. I\u2019d love to test it out."
                },
                {
                    "author": "surfer808",
                    "text": "Yes please sign me up"
                },
                {
                    "author": "jnorris441",
                    "text": "Alternate names are welcome"
                },
                {
                    "author": "halfteatree",
                    "text": "Would love to test!"
                },
                {
                    "author": "Due_Leadership5858",
                    "text": "I would like to assist as well."
                },
                {
                    "author": "DreamDriver",
                    "text": "I\u2019d love to help!"
                },
                {
                    "author": "SpeechAgreeable3442",
                    "text": "\ud83d\udc4b\ud83c\udffb Happy to test! App/experience designer from London"
                },
                {
                    "author": "sonofdeepvalue",
                    "text": "This is cool. Would love to test"
                },
                {
                    "author": "Jdunrrp",
                    "text": "Would love to test this out \u26a1\ufe0f"
                },
                {
                    "author": "FriendOfanArtist",
                    "text": "Id love to sign up"
                },
                {
                    "author": "SamQuattrociocchi",
                    "text": "I\u2019d love to test it!"
                },
                {
                    "author": "revgizmo",
                    "text": "That\u2019s fucking amazing"
                },
                {
                    "author": "phinity_",
                    "text": "Windorama missed opportunity."
                },
                {
                    "author": "Old-n-busy",
                    "text": "I would love to test this!  What a beautiful way to really enjoy spaces !"
                },
                {
                    "author": "fried_penguin_wings",
                    "text": "Interested in testing if you still need more."
                },
                {
                    "author": "Boo_Dev",
                    "text": "would love to test!"
                },
                {
                    "author": "iseetreesofgreen_",
                    "text": "I'd love to test it!"
                },
                {
                    "author": "phillecheesesteak",
                    "text": "Call it ReViewed"
                },
                {
                    "author": "yaelm631",
                    "text": "Without 3D panoramas/parallax, doesn't it look a bit too flat? Is there 360\u00b0 photo app to stereoscopic 360\u00b0?"
                },
                {
                    "author": "flyblackbox",
                    "text": "This is very very good!"
                },
                {
                    "author": "Supradeac",
                    "text": "I\u2019m on TestFlight if you need another to test. Looks cool!"
                },
                {
                    "author": "helloblackhole",
                    "text": "Me! Please."
                },
                {
                    "author": "himey72",
                    "text": "That is a very good idea.  Feel free to PM me if you still need testing help."
                },
                {
                    "author": "jaredcwood",
                    "text": "I\u2019m a photographer who\u2019s been looking for others to bounce ideas off of.  I\u2019d love to support you as a tester or i can even provide medium format caliber panos if you want to test some 400MP+ images.  Excellent idea!!"
                },
                {
                    "author": "MagreviZoldnar",
                    "text": "Sign me up!"
                },
                {
                    "author": "backstreetatnight",
                    "text": "Windora is an awesome name and this is an awesome idea"
                },
                {
                    "author": "warrior178",
                    "text": "very good idea!"
                },
                {
                    "author": "StungTwice",
                    "text": "Can you work with 2D panoramas? I have lots of those. I haven't had a reason to invest in the VR cameras until now."
                },
                {
                    "author": "likeCircle",
                    "text": "I've though about this before.  I can imagine it being popular with people who live in apartments with uninspiring views.  Are they static images or do you have video's that sync with local time?"
                },
                {
                    "author": "bozidarsevo",
                    "text": "I can test if needed \ud83d\udc4d"
                },
                {
                    "author": "Low-Presentation7206",
                    "text": "Sign me up I\u2019m on test flight and beta vision os"
                },
                {
                    "author": "Step991",
                    "text": "Great idea! sign me up please!"
                },
                {
                    "author": "CGREDDIT1",
                    "text": "Send a link if you are looking for additional testers. Experienced TestFlight user and beta tester."
                },
                {
                    "author": "chrysky",
                    "text": "Would love to test this"
                },
                {
                    "author": "Nonomomomo2",
                    "text": "Love to test it too, thanks!"
                },
                {
                    "author": "Nonomomomo2",
                    "text": "Love to test it too, thanks!"
                },
                {
                    "author": "ZestycloseShare2413",
                    "text": "Love to test!"
                },
                {
                    "author": "Step991",
                    "text": "Great idea! I'm on TestFlight and would love to help you test it."
                },
                {
                    "author": "vidgameplaya",
                    "text": "I'd like to test please!"
                },
                {
                    "author": "-The-DrGenome",
                    "text": "Excellent idea! Great work!"
                },
                {
                    "author": "jayb0og",
                    "text": "Brilliant idea, sign me up"
                },
                {
                    "author": "jayb0og",
                    "text": "Brilliant idea, sign me up"
                },
                {
                    "author": "jayb0og",
                    "text": "Brilliant idea, sign me up!"
                },
                {
                    "author": "coffeemoney7",
                    "text": "I\u2019m game"
                },
                {
                    "author": "Less_Influence9009",
                    "text": "I would love to test!"
                },
                {
                    "author": "angelvocifer",
                    "text": " me plz"
                },
                {
                    "author": "angelvocifer",
                    "text": "Windora me plz"
                },
                {
                    "author": "meester_pink",
                    "text": "great idea, you should throw in some different window frames to choose from so we can match our existing windows!"
                },
                {
                    "author": "gnoresbs",
                    "text": "Isn't this ability already in by default?"
                },
                {
                    "author": "Christoph323",
                    "text": "Would love to test it!"
                },
                {
                    "author": "hotwire32",
                    "text": "Yes, so much yes!  Would love to test, this is exactly what I want for my virtual office next!"
                },
                {
                    "author": "No-Independence828",
                    "text": "Looks amazing, but the window itself looks super fake"
                },
                {
                    "author": "NoLoveForDrJones",
                    "text": "it\u2019ll be great if this or another app included motion. i\u2019d want to look out the window of a moving train riding ala going to Westworld and get murdered."
                },
                {
                    "author": "NoLoveForDrJones",
                    "text": "it\u2019ll be great if this or another app included video. i\u2019d want to look out the window of a moving train riding ala going to Westworld and get murdered."
                },
                {
                    "author": "4241342413",
                    "text": "id love to try it too"
                },
                {
                    "author": "Calm-Elevator5125",
                    "text": "THAT IS SO COOL!!! It\u2019s like something right out of a movie"
                },
                {
                    "author": "Basekomp",
                    "text": "looks like im late to the party - can I get an invite pls?"
                },
                {
                    "author": "askep3",
                    "text": "I\u2019d love to test as well"
                },
                {
                    "author": "c_nan",
                    "text": "Would love to test and give feedback! Been running betas and submitting feedback for iOS since 2017."
                },
                {
                    "author": "ponyo240",
                    "text": "This kinda depresses me idk why"
                },
                {
                    "author": "Deleted",
                    "text": "[deleted]"
                },
                {
                    "author": "Loon_Cheese",
                    "text": "I\u2019m interested!"
                },
                {
                    "author": "Reasonable-Choice-59",
                    "text": "I\u2019m down"
                },
                {
                    "author": "brett_ATL",
                    "text": "I would love to test"
                },
                {
                    "author": "gurutek71",
                    "text": "Great idea!"
                },
                {
                    "author": "mkm6_",
                    "text": "Great idea and the resolution of those panoramas looks stunning. I'd love to test the app."
                },
                {
                    "author": "frrrni",
                    "text": "Are the panoramas 3D?"
                },
                {
                    "author": "juriswilliams",
                    "text": "I\u2019d love to test it out for you!"
                },
                {
                    "author": "cr8tvt",
                    "text": "I\u2019d love to test this as well."
                },
                {
                    "author": "C0DESTR0NG",
                    "text": "u/jnorris441 I have my own unique beta app (secret idea, not panorama) that I'd love to share with you too, if you still have room I can test your app!"
                },
                {
                    "author": "roz303",
                    "text": "This is AWESOME!!!"
                },
                {
                    "author": "A_Sitting_Wall",
                    "text": "Awesome idea! I\u2019d love to try :)"
                },
                {
                    "author": "answerdvd",
                    "text": "Down. Send me a demo"
                },
                {
                    "author": "ankn7",
                    "text": "Looks amazing! Would love to test it!"
                },
                {
                    "author": "burghcoder",
                    "text": "Love this idea"
                },
                {
                    "author": "FrenchFrozenFrog",
                    "text": "as a matte painter for film, I long for these panoramas to be mapped on a geo to give it a bit of parallaxes."
                },
                {
                    "author": "CalzonePillow",
                    "text": "I know it\u2019s a bit gimmicky to an extent but god damn I want to get an AVP"
                },
                {
                    "author": "Palitrab",
                    "text": "Niice"
                },
                {
                    "author": "Deleted",
                    "text": "[removed]"
                },
                {
                    "author": "Street-Tree-8126",
                    "text": "How does this look so good. Is there already anything alike out there which you\u2019re building on ? Or it\u2019s a first with AR/VR ?"
                },
                {
                    "author": "qpid360",
                    "text": "Sign me up!"
                },
                {
                    "author": "TheRoe102",
                    "text": "It could be huge!"
                },
                {
                    "author": "MercurialMadnessMan",
                    "text": "Incredible idea.\n\nI work in a basement and it\u2019s quite isolating and dreary.\n\nAre you able to have multiple windows? Like one on each wall?\n\nI also had this idea of making interior walls in my house invisible by putting a wide angle HomeKit camera in the center of each wall, and casting those as windows into AVP. This parallax effect might be useful for that"
                },
                {
                    "author": "Hssirhc",
                    "text": "Would love to test it"
                },
                {
                    "author": "itsalatte",
                    "text": "I\u2019ll test it!! Looks neat"
                },
                {
                    "author": "eclipseforever",
                    "text": "Sign me up"
                },
                {
                    "author": "2001skydog10",
                    "text": "majestic"
                },
                {
                    "author": "TheVloginator",
                    "text": "I\u2019d love to try this out! Lots of cool panoramas I\u2019ve been wanting to check out :)"
                },
                {
                    "author": "Status_Mongoose2307",
                    "text": "Awesome!"
                },
                {
                    "author": "neoburnett",
                    "text": "I would like to test it"
                },
                {
                    "author": "Kampy_",
                    "text": "Coool. I have Beta 4 and Testflight... would love to try this"
                },
                {
                    "author": "BlooooContra",
                    "text": "This looks fantastic! Would love to test."
                },
                {
                    "author": "markworsnop",
                    "text": "Very cool. Happy to test. I'm usually in AVP at least 4 hours a day."
                },
                {
                    "author": "brokenarrow326",
                    "text": "Great idea"
                },
                {
                    "author": "wildberry815",
                    "text": "Hella black mirror vibes"
                },
                {
                    "author": "oceanthrsty",
                    "text": "would love to help. Love the idea. I\u2019m experienced with Test Flight. Let me know."
                },
                {
                    "author": "folkpoet369",
                    "text": "Sign me up!"
                },
                {
                    "author": "LionaltheGreat",
                    "text": "I\u2019d be happy to test my friend! DM me for contact details for TestFlight"
                },
                {
                    "author": "nusodumi",
                    "text": "Very good idea  \n\n\nPanoramic movies, or interactive things, and boom it's harry potter portraits you can interact with"
                },
                {
                    "author": "Early_Ad8773",
                    "text": "Sign me up please!"
                },
                {
                    "author": "TheFirstDogSix",
                    "text": "That is fantastic!  Will definitely buy when it's official!"
                },
                {
                    "author": "glacialOwl",
                    "text": "I can also test"
                },
                {
                    "author": "polyglot_865",
                    "text": "Very cool concept. Probably many ways to spin off this."
                },
                {
                    "author": "Genome_Doc_76",
                    "text": "I love this!"
                },
                {
                    "author": "iareamisme",
                    "text": "i like it! already have many panos saved to try it"
                },
                {
                    "author": "Motor_Technology4486",
                    "text": "Sign me up"
                },
                {
                    "author": "rhino8910",
                    "text": "I'm a test flight-er I'd love to test \ud83d\ude4b\ud83c\udffb\u200d\u2642\ufe0f"
                },
                {
                    "author": "DonnayWinterford",
                    "text": "Please resend the link so that I may test it. Thank you."
                },
                {
                    "author": "Minjaben",
                    "text": "Would love to try it! Happy to test!"
                },
                {
                    "author": "fPmrU5XxJN",
                    "text": "Would love to try this!"
                },
                {
                    "author": "No-Entrance-8351",
                    "text": "How can I be added to the list for testing?"
                },
                {
                    "author": "JobsCovenant",
                    "text": "Sign me up please"
                },
                {
                    "author": "pogdaddle",
                    "text": "Very Cool! Can I test?"
                },
                {
                    "author": "Deleted",
                    "text": "Brilliant idea. Let me know if you need a tester"
                },
                {
                    "author": "nicB72",
                    "text": "great idea.  sign me up for testing"
                },
                {
                    "author": "Biomexr",
                    "text": "this is great"
                },
                {
                    "author": "bdougherty",
                    "text": "Looks like you've got plenty of testers, but happy to add myself to the list if you need any more."
                },
                {
                    "author": "gsx302",
                    "text": "I would love to test it"
                },
                {
                    "author": "Character-Bill-5710",
                    "text": "Count me in!"
                },
                {
                    "author": "jsauger",
                    "text": "This sounds cool. I\u2019d love to test it!"
                },
                {
                    "author": "After_Skirt_6777",
                    "text": "Available for Quest?"
                },
                {
                    "author": "Sordidloam",
                    "text": "Would love to test!"
                },
                {
                    "author": "andreelijah",
                    "text": "I\u2019d love to!"
                },
                {
                    "author": "Plus-Clerk-1750",
                    "text": "Love to test it"
                },
                {
                    "author": "Few_Dragonfruit_3700",
                    "text": "How on earth did you manage to display spatial content spatially? I\u2019ve tried so many different implementations and spatial video for me continues to display in 2D and/or with no parallax effect."
                },
                {
                    "author": "Ok-Handle1",
                    "text": "I would love to try it!"
                },
                {
                    "author": "Alekssu-Pandian",
                    "text": "I\u2019d love to see this when it\u2019s daylight in your room. It would look more realistic to match the lighting."
                },
                {
                    "author": "TheJohnnyFuzz",
                    "text": "Looks great - if you still need people to test let me know!"
                },
                {
                    "author": "mitchrogoff",
                    "text": "I would like to test it"
                },
                {
                    "author": "jwreda",
                    "text": "I\u2019d try it!"
                },
                {
                    "author": "expertjdm",
                    "text": "Would love to test! Such a good idea"
                },
                {
                    "author": "Gtaz19",
                    "text": "Need to have some different window options, bay window, French ect. Also some short videos in a loop so we can see leaves on trees blow or waves crash on a beach."
                },
                {
                    "author": "HotThotty69",
                    "text": "I woukd love to try. I work inside of a coat closet."
                },
                {
                    "author": "onelilfizzle",
                    "text": "I\u2019ll gladly give it a try!"
                },
                {
                    "author": "Fatieh_",
                    "text": "yep you should try leaning out the window and looking around :D"
                },
                {
                    "author": "MarticZtn",
                    "text": "Any spot left? I\u2019m a developer as well and I wanna try it out!"
                },
                {
                    "author": "Professor_Mando",
                    "text": "I would love to be one of your testers!"
                },
                {
                    "author": "Developer-Santi",
                    "text": "I\u2019d love to test!"
                },
                {
                    "author": "Altruistic-Series-84",
                    "text": "send me a link :)"
                },
                {
                    "author": "hellobritishcolumbia",
                    "text": "Excellent idea! Here are some unsolicited alternative names in case you like any of em \u263a\ufe0f\n\nNo results on the App Store:\n- SceneScape\n- OpenWindow\n\nHandful of unrelated results:\n- WorldView\n- MindScape"
                },
                {
                    "author": "jekcheognuod",
                    "text": "I\u2019m pretty sure I\u2019ll smack my face into the wall trying to take a look outside \u2026"
                },
                {
                    "author": "ekurutepe",
                    "text": "Looks amazing. I\u2019d love to test as well"
                },
                {
                    "author": "balancetotheforce99",
                    "text": "Ah but you stole that idea from my excel of ideas"
                },
                {
                    "author": "zr0sum",
                    "text": "I\u2019d really love the opportunity to test this!"
                },
                {
                    "author": "idreamer23",
                    "text": "Can I get invited to the testing this app?"
                },
                {
                    "author": "FLASHsynced",
                    "text": "If you\u2019re still looking for testers, I\u2019m on TestFlight already"
                },
                {
                    "author": "NipplessCage7891",
                    "text": "I'd love to test this out, as a remote worker I think this would be amazing"
                },
                {
                    "author": "tachijuan",
                    "text": "Happy to test for you. Sign me up!"
                },
                {
                    "author": "Life_Acanthisitta322",
                    "text": "Please send me !!!\n\n\nThank you \ud83e\udd70"
                },
                {
                    "author": "Donstil",
                    "text": "super cool idea, if you still has spots, let me know!"
                },
                {
                    "author": "Radiant_Dealer9183",
                    "text": "TestFlight, please"
                },
                {
                    "author": "Disastrous_Analyst_1",
                    "text": "I know it's been said already, but just to throw my voice into the ring, this is a superb idea.  I'd pay for this app.  It would be even better if the scene changed over time, even if that was a slow transition."
                },
                {
                    "author": "hcatch",
                    "text": "I\u2019d love to test it pls"
                },
                {
                    "author": "Justgus63",
                    "text": "I\u2019m up for testing. It would be interesting if you could find a way to stitch together video or spatial photos as a panorama too."
                },
                {
                    "author": "clintceasewood",
                    "text": "What kind of signals do you get when the app is not in the viewport? As an app owner, do you get to know if apple has stopped rendering the video when it's not in the viewport?"
                },
                {
                    "author": "fbloise",
                    "text": "This is lovely !"
                },
                {
                    "author": "Equal-Selection7742",
                    "text": "That is awesome and gives me these vibes\u2026.\n\nhttps://preview.redd.it/abljr6osljlc1.jpeg?width=1588&format=pjpg&auto=webp&s=a7bfbe34866385715f88c0c0fb5f2d16f1f1f142\n\nDown to test as well!"
                },
                {
                    "author": "megadabs",
                    "text": "just got avp. i\u2019d love to try this please"
                },
                {
                    "author": "Ordinary_Lifeform",
                    "text": "Very cool idea!"
                },
                {
                    "author": "No_Key6434",
                    "text": "That\u2019s one of my favorite things about the Vision Pro. I feel like the opportunities for developers are absolutely endless and are so exciting. Concerts, sporting events, even work out classes with friends people around you! Imagine being on stage with your favorite act or being in the front row for something you\u2019ll never be able to be at. People would PAY. It\u2019s pretty sweet. Honestly not as cool as the real thing, but definitely cooler than watching on TV."
                },
                {
                    "author": "Certain_Customer4983",
                    "text": "I\u2019d like to test it get back to me"
                },
                {
                    "author": "Cappa86",
                    "text": "Sign me up"
                },
                {
                    "author": "happyfugu",
                    "text": "This is genius. Can you add me?"
                },
                {
                    "author": "AttackingHobo",
                    "text": "Good job! I've created this kind of thing before in AR with Unity.  \n\n\nSurprised that it took this long!\n\nCan I get a code to try? I can give you some developer focused feedback."
                },
                {
                    "author": "Anderson2218",
                    "text": "Sent a dm id love to try"
                },
                {
                    "author": "Khizer23",
                    "text": "Can test"
                },
                {
                    "author": "Eggy-Toast",
                    "text": "I\u2019m in for sure!"
                },
                {
                    "author": "sexysausage",
                    "text": "[https://www.youtube.com/watch?v=TxDbx2bOFRU](https://www.youtube.com/watch?v=TxDbx2bOFRU) ... this is so 2015 ;) according to Back to the Future part 2"
                },
                {
                    "author": "sexysausage",
                    "text": "are you going to project the panorama into some medium resolution mesh to create a bit of 2.5 D effect and parallax ?"
                },
                {
                    "author": "Djnoelb",
                    "text": "Man I\u2019ve been learning development bc I wanted to make this exact app. This is awesome !"
                },
                {
                    "author": "Snoo-90095",
                    "text": "Good idea count me in"
                },
                {
                    "author": "kinabalu",
                    "text": "would love to test it, looks fun"
                },
                {
                    "author": "Agile_Detail_1570",
                    "text": "Wow! I am looking for one like this! Please!"
                },
                {
                    "author": "Ouralien",
                    "text": "I would be happy to test :)"
                },
                {
                    "author": "jewettg",
                    "text": "Count me in for testing.  Please send me a Testflight link! :)"
                },
                {
                    "author": "chicagojacks",
                    "text": "Awesome idea man!"
                },
                {
                    "author": "Visionchoze",
                    "text": "Sign me up! Down to test!"
                },
                {
                    "author": "smarshyboy",
                    "text": "I'd like to test it!"
                },
                {
                    "author": "Kostner_Emmerich",
                    "text": "An app for sharing panoramas would be cool! There is already an app for sharing spacial videos. It\u2019s mildly buggy but it\u2019s free and fun."
                },
                {
                    "author": "CBanga",
                    "text": "Definitely interested in testing. I\u2019ve been making apps for 15 years, so happy to offer any feedback I can."
                },
                {
                    "author": "kkwok",
                    "text": "I\u2019d love to test this"
                },
                {
                    "author": "gjamesb0",
                    "text": "Cup O\u2019 Soup? or Stasis Cube?\n\nBecause it reminds me of the 3D painting.\n\nhttps://tardis.fandom.com/wiki/Gallifrey_Falls_No_More"
                },
                {
                    "author": "dfbillsPRO",
                    "text": "Would love to check this out!"
                },
                {
                    "author": "DesperateStorage",
                    "text": "I\u2019d like to donate some landscapes, how can I help?"
                },
                {
                    "author": "puterdude92",
                    "text": "I\u2019d be down to test this, cool idea!"
                },
                {
                    "author": "BeeEnvironmental4483",
                    "text": "Great idea I would like to be a tester"
                },
                {
                    "author": "bskim214",
                    "text": "I\u2019ll try it out"
                },
                {
                    "author": "Sea_Paramedic2434",
                    "text": "I won't lie. That's awesome! \ud83d\ude32"
                },
                {
                    "author": "DeveloperLuke",
                    "text": "Would love to try!"
                },
                {
                    "author": "MnJoe78",
                    "text": "I\u2019d be delighted to try it!"
                },
                {
                    "author": "macnow",
                    "text": "Wow, great idea. I want to try it too."
                },
                {
                    "author": "zmrogj",
                    "text": "My partner would be down to test it! He\u2019s doesn\u2019t hang out here but I send him posts constantly. \ud83d\ude05"
                },
                {
                    "author": "Saroo7866",
                    "text": "Happy to test :)"
                },
                {
                    "author": "Nobiting",
                    "text": "I had a very similar idea but I had no idea how to make it reality haha. I'd love to test if you need any feedback."
                },
                {
                    "author": "Deleted",
                    "text": "Is it too late to become a tester?? Thanks!"
                }
            ]
        },
        {
            "link": "https://www.reddit.com/r/VisionPro/comments/1ahhdnj/vision_pros_spatial_understanding_is_insane/",
            "title": "Vision Pro's spatial understanding is INSANE",
            "selftext": "",
            "comments": [
                {
                    "author": "That-SoCal-Guy",
                    "text": "Apple Car - here we come! \u00a0"
                },
                {
                    "author": "ThatRainbowGuy",
                    "text": "What is this from?"
                },
                {
                    "author": "MS2Entertainment",
                    "text": "This is like what Neo saw when he finally saw the Matrix."
                },
                {
                    "author": "ishtechte",
                    "text": "Oh wow. Do you have to mark your furniture or does it do everything for you?"
                },
                {
                    "author": "Maralitabambolo",
                    "text": "You\u2019re going a bit fast, but is it me or it\u2019s recognizing at least some objects as well? I can only imagine how this can be supercharged with a multimodal LLM"
                },
                {
                    "author": "redditrasberry",
                    "text": "this is what I'm really most interested in from Vision Pro - how much has Apple moved the state of the art forward in terms of *actually* having real time understanding of the world? Everything else is sort of a qualitative / marginal improvement over previous things that existed. But this idea of genuine depth perception with true real time scene modeling is tantalising for what it can mean. It feels like Apple has chosen fairly superficial things to highlight for marketing purposes because they appeal to mass market easily (yay we can watch movies ... like we have in VR for 10+ years now ...). But the real exciting capabilities here are yet to be revealed / highlighted because they take much more time and nuance for people to understand them."
                },
                {
                    "author": "mailslot",
                    "text": "There\u2019s a simple bouncy ball app, and it was bouncing a ball off of furniture, junk I have on the floor, my walls, hallway, even the box the Vision Pro came in. Its mapping is impressive."
                },
                {
                    "author": "tiringandretiring",
                    "text": "That is so cool looking!"
                },
                {
                    "author": "94746382926",
                    "text": "Wow looking at this I suddenly became aware of the fact that I expect a certain amount of \"sliding\" when it comes to object detection algorithms. This shit is completely anchored and almost flawless. Super impressive stuff."
                },
                {
                    "author": "Aranfiy",
                    "text": "Now I kinda get why the battery life is 2 hours"
                },
                {
                    "author": "Wise_Royal9545",
                    "text": "Nice place :)"
                },
                {
                    "author": "beryka",
                    "text": "Looks better than Tesla \"full self driving\""
                },
                {
                    "author": "jabblack",
                    "text": "Does it work well outside? Or do you get lots of glare?"
                },
                {
                    "author": "SerialKillerVibes",
                    "text": "You could do this with the iPhone 14's LIDAR sensor, pretty detailed as well. Love to see this technology advancing."
                },
                {
                    "author": "adeze",
                    "text": "This must be being accelerated by the R1?"
                },
                {
                    "author": "youngsobe",
                    "text": "Does it do this when the lights are off and it\u2019s dark or is it relying on beyond LiDAR to provide such data?"
                },
                {
                    "author": "Reelevant",
                    "text": "R1"
                },
                {
                    "author": "brycedriesenga",
                    "text": "How far can you push this, in terms of leaving windows in different spots? Can you like, walk down the street a bit and leave a browser and then come back to it in a while?"
                },
                {
                    "author": "tractorrobot",
                    "text": "Would you share this Xcode project with me? Or if not, could you point me to what APIs are used here to display the geometry? It looks similar to what can be done with RoomPlan on iOS, but RoomPlan does not appear to be in visionOS."
                },
                {
                    "author": "HeadlineINeed",
                    "text": "These videos piss me off. Why are people moving their heads around so fast when they are trying to show stuff."
                },
                {
                    "author": "Rabus",
                    "text": "Can you compare with quest 3?"
                },
                {
                    "author": "notnellaf",
                    "text": "is this an app?"
                },
                {
                    "author": "VictoriaSobocki",
                    "text": "Awesome"
                },
                {
                    "author": "Joesardone",
                    "text": "can we use this mesh data?"
                },
                {
                    "author": "d34dw3b",
                    "text": "Any apps that exploit this?"
                },
                {
                    "author": "Fabulous_Ad_9011",
                    "text": "And this is why they call it \u201cspatial computer\u201d instead of Vr headset \ud83d\ude09"
                },
                {
                    "author": "13e1ieve",
                    "text": "Any iPhone pro since iPhone 12 will do the exact same thing with the lidar sensor."
                },
                {
                    "author": "Arrakis_Surfer",
                    "text": "So now Apple has makes the entirety of your home interior."
                },
                {
                    "author": "Maleficent-Cat6074",
                    "text": "And now Apple can see inside your house \ud83e\udd29"
                },
                {
                    "author": "Deleted",
                    "text": "basically mapping your house and storing it in their servers. When ever something is missing or broken, you will get an ad for a new one."
                },
                {
                    "author": "JamesR624",
                    "text": "Oookay? I. mean it can scan shapes just like the iPad could do for years....\n\nTry and hold your hands in front of it. Try and hold your arms in front. Try and place windows behnd furniture.\n\nThis isn't a demo of Vision Pro's spatial awareness. This is a demo of LiDar and that's it."
                },
                {
                    "author": "Bubbahard",
                    "text": "I like how you swing around and expect anyone to grasp what you're trying to show."
                },
                {
                    "author": "Cooe14",
                    "text": "... Except that Quest 3's 3D spatial mesh maps are just as good despite the headset costing a SEVENTH as much. Try again. \ud83e\udd37\n\nLIDAR does let you not have to get as close to objects for an accurate mesh scan, but that's literally about Vision Pro's only real advantage on this front.\n\nDynamic identification of objects like tables & couches is an advantage, but a temporary one. That's confirmed coming to Quest 3 within the year."
                },
                {
                    "author": "ChessGibson",
                    "text": "Gives us the glimpse at the whole potential of this with third party apps and upcoming OS upgrades"
                },
                {
                    "author": "antdude",
                    "text": "Now, Apple and we know what's your home looks like. :P"
                },
                {
                    "author": "Capitaclism",
                    "text": "Too bad it doesn't currently play well with windows"
                },
                {
                    "author": "PimpTrickGangstaClik",
                    "text": "Except for the labeling, my Roborock robot vacuum app does this exactly with my iPhone 15"
                },
                {
                    "author": "Priivate7785",
                    "text": "Wow! This is amazing."
                },
                {
                    "author": "theKnightWatchman44",
                    "text": "This should help SUV drivers when it comes to lanes and parking spaces"
                },
                {
                    "author": "Sad_Ad4916",
                    "text": "You are new to VR right ?"
                },
                {
                    "author": "packsendingveteran",
                    "text": "This is it, this is the end"
                },
                {
                    "author": "Low_Wishbone_8200",
                    "text": "This is what being on shrooms look like"
                },
                {
                    "author": "TYLabOfLifeMaster",
                    "text": "This looks like Watch dog hack mode.\ud83d\ude02"
                },
                {
                    "author": "WeaponizedFOMO",
                    "text": "Anyone know of an app that will give me the measurements/dimensions of a room? Would be cool if it could tell me window sizes and such as well. Could be used to figure out how much carpet you need and such."
                },
                {
                    "author": "bobtruck2020",
                    "text": "Toyota about to release solid state batteries in 2026 on their models. 945 miles range and charge in under 10 minutes. If Apple releases their car and puts that battery in it, it would destroy Tesla."
                },
                {
                    "author": "catwithlonghair",
                    "text": "Bro best 3D scanner for 3D models."
                },
                {
                    "author": "Jbaker318",
                    "text": "Can someone do this hella slower, looking at AVPs labeling and boundary detection? Some lines looked unnecessarily wavy, and there were red spots not sure what it is thinking those are.\n\nIf any AR app designers are out there, can ya comment if the data apple is providing enough for your app?"
                },
                {
                    "author": "while_youre_up",
                    "text": "I expected it to be more impressive; like it should know the shapes of the frames in the wall, not just that there is a wall."
                }
            ]
        }
    ],
    "youtube_video_subtitles": {
        "Apple Vision Pro Review - 6 Months Later.srt": [
            {
                "start": "00:00:00,240",
                "end": "00:00:04,640",
                "text": "what happened to Apple Vision Pro in the"
            },
            {
                "start": "00:00:02,679",
                "end": "00:00:06,120",
                "text": "six months since I bought mine The"
            },
            {
                "start": "00:00:04,640",
                "end": "00:00:08,440",
                "text": "Narrative around this product has"
            },
            {
                "start": "00:00:06,120",
                "end": "00:00:10,639",
                "text": "changed drastically from Apple's"
            },
            {
                "start": "00:00:08,440",
                "end": "00:00:13,519",
                "text": "Visionary new product is the most"
            },
            {
                "start": "00:00:10,639",
                "end": "00:00:15,639",
                "text": "technologically advanced ever to the"
            },
            {
                "start": "00:00:13,519",
                "end": "00:00:18,760",
                "text": "Apple Vision Pro is a dud flop and a"
            },
            {
                "start": "00:00:15,639",
                "end": "00:00:21,240",
                "text": "miss but why what the hell happened in"
            },
            {
                "start": "00:00:18,760",
                "end": "00:00:24,439",
                "text": "the course of 6 months to justify that"
            },
            {
                "start": "00:00:21,240",
                "end": "00:00:28,199",
                "text": "change is the Vision Pro actually a flop"
            },
            {
                "start": "00:00:24,439",
                "end": "00:00:29,519",
                "text": "and would I recommend buying one first"
            },
            {
                "start": "00:00:28,199",
                "end": "00:00:31,880",
                "text": "let me take you through what I've"
            },
            {
                "start": "00:00:29,519",
                "end": "00:00:33,840",
                "text": "actually been using mine for the first"
            },
            {
                "start": "00:00:31,880",
                "end": "00:00:36,600",
                "text": "big thing I've been using the Vision Pro"
            },
            {
                "start": "00:00:33,840",
                "end": "00:00:38,840",
                "text": "for is for novelty experiences the"
            },
            {
                "start": "00:00:36,600",
                "end": "00:00:42,360",
                "text": "dinosaur encounter is the best example"
            },
            {
                "start": "00:00:38,840",
                "end": "00:00:43,840",
                "text": "of this oh it's looking right at me holy"
            },
            {
                "start": "00:00:42,360",
                "end": "00:00:46,399",
                "text": "sh"
            },
            {
                "start": "00:00:43,840",
                "end": "00:00:49,000",
                "text": "holy I knew it was going to do this that"
            },
            {
                "start": "00:00:46,399",
                "end": "00:00:52,719",
                "text": "your walls open up into the Jurassic age"
            },
            {
                "start": "00:00:49,000",
                "end": "00:00:55,039",
                "text": "and a giant dinosaur looks right at you"
            },
            {
                "start": "00:00:52,719",
                "end": "00:00:56,800",
                "text": "as it steps through your living room"
            },
            {
                "start": "00:00:55,039",
                "end": "00:00:59,280",
                "text": "other apps like Kung Fu Panda's"
            },
            {
                "start": "00:00:56,800",
                "end": "00:01:02,399",
                "text": "meditation lessons and Disney Marvel's"
            },
            {
                "start": "00:00:59,280",
                "end": "00:01:05,280",
                "text": "what if offers similar experiences what"
            },
            {
                "start": "00:01:02,399",
                "end": "00:01:08,040",
                "text": "makes these experiences so novel and"
            },
            {
                "start": "00:01:05,280",
                "end": "00:01:09,920",
                "text": "compelling is how the Vision Pro can"
            },
            {
                "start": "00:01:08,040",
                "end": "00:01:13,280",
                "text": "make you feel like the characters and"
            },
            {
                "start": "00:01:09,920",
                "end": "00:01:15,560",
                "text": "creatures you're seeing can also see you"
            },
            {
                "start": "00:01:13,280",
                "end": "00:01:18,479",
                "text": "well yes other headsets like the quest 3"
            },
            {
                "start": "00:01:15,560",
                "end": "00:01:21,479",
                "text": "offer similar experiences The Vision Pro"
            },
            {
                "start": "00:01:18,479",
                "end": "00:01:24,400",
                "text": "sells this illusion of presence way more"
            },
            {
                "start": "00:01:21,479",
                "end": "00:01:26,520",
                "text": "thanks to its better displays graphics"
            },
            {
                "start": "00:01:24,400",
                "end": "00:01:28,720",
                "text": "and performance another immersive"
            },
            {
                "start": "00:01:26,520",
                "end": "00:01:31,000",
                "text": "experience can transport you to Mount"
            },
            {
                "start": "00:01:28,720",
                "end": "00:01:33,680",
                "text": "Hood or the surface surf of the Moon in"
            },
            {
                "start": "00:01:31,000",
                "end": "00:01:35,600",
                "text": "what Apple calls environments these are"
            },
            {
                "start": "00:01:33,680",
                "end": "00:01:37,600",
                "text": "mainly places in the real world that"
            },
            {
                "start": "00:01:35,600",
                "end": "00:01:40,040",
                "text": "have been recreated to make it feel like"
            },
            {
                "start": "00:01:37,600",
                "end": "00:01:42,600",
                "text": "you're right there though some apps like"
            },
            {
                "start": "00:01:40,040",
                "end": "00:01:44,920",
                "text": "Disney plus and Max have created their"
            },
            {
                "start": "00:01:42,600",
                "end": "00:01:46,759",
                "text": "own like the throne room from Game of"
            },
            {
                "start": "00:01:44,920",
                "end": "00:01:48,600",
                "text": "Thrones the purpose of these"
            },
            {
                "start": "00:01:46,759",
                "end": "00:01:50,680",
                "text": "environments is to help block out"
            },
            {
                "start": "00:01:48,600",
                "end": "00:01:53,560",
                "text": "everything around you so you can focus"
            },
            {
                "start": "00:01:50,680",
                "end": "00:01:55,399",
                "text": "on completing a certain task or you just"
            },
            {
                "start": "00:01:53,560",
                "end": "00:01:57,960",
                "text": "want to have a space to have a giant"
            },
            {
                "start": "00:01:55,399",
                "end": "00:02:00,600",
                "text": "screen to watch something on meditating"
            },
            {
                "start": "00:01:57,960",
                "end": "00:02:02,520",
                "text": "in these environments can also be fun"
            },
            {
                "start": "00:02:00,600",
                "end": "00:02:05,159",
                "text": "Apple's updated meditation app for The"
            },
            {
                "start": "00:02:02,520",
                "end": "00:02:07,240",
                "text": "Vision Pro has this very soothing 3D"
            },
            {
                "start": "00:02:05,159",
                "end": "00:02:09,440",
                "text": "breathing guide now one of the best"
            },
            {
                "start": "00:02:07,240",
                "end": "00:02:12,280",
                "text": "parts of Oni A Vision Pro is watching"
            },
            {
                "start": "00:02:09,440",
                "end": "00:02:14,360",
                "text": "other people try it on Via guest mode"
            },
            {
                "start": "00:02:12,280",
                "end": "00:02:16,920",
                "text": "it's hilarious seeing other people react"
            },
            {
                "start": "00:02:14,360",
                "end": "00:02:19,160",
                "text": "to the dinosaur coming right at them but"
            },
            {
                "start": "00:02:16,920",
                "end": "00:02:21,040",
                "text": "again that's novelty it's the thing that"
            },
            {
                "start": "00:02:19,160",
                "end": "00:02:24,160",
                "text": "gets you excited about a product and"
            },
            {
                "start": "00:02:21,040",
                "end": "00:02:26,120",
                "text": "then perhaps buy it but it's rarely the"
            },
            {
                "start": "00:02:24,160",
                "end": "00:02:28,080",
                "text": "thing that actually keeps you using it"
            },
            {
                "start": "00:02:26,120",
                "end": "00:02:30,319",
                "text": "over the long term and that leads me to"
            },
            {
                "start": "00:02:28,080",
                "end": "00:02:33,120",
                "text": "the vision Pro's next big feature which"
            },
            {
                "start": "00:02:30,319",
                "end": "00:02:35,120",
                "text": "is Apple immersive video Apple immersive"
            },
            {
                "start": "00:02:33,120",
                "end": "00:02:37,040",
                "text": "video is a new format that makes you"
            },
            {
                "start": "00:02:35,120",
                "end": "00:02:41,280",
                "text": "feel like you've been put right in the"
            },
            {
                "start": "00:02:37,040",
                "end": "00:02:44,360",
                "text": "middle of a 180\u00b0 IMAX movie the people"
            },
            {
                "start": "00:02:41,280",
                "end": "00:02:46,360",
                "text": "and animals you see feel real I just"
            },
            {
                "start": "00:02:44,360",
                "end": "00:02:48,480",
                "text": "couldn't stop smiling watching this mini"
            },
            {
                "start": "00:02:46,360",
                "end": "00:02:50,080",
                "text": "do about a rhino Sanctuary especially in"
            },
            {
                "start": "00:02:48,480",
                "end": "00:02:51,959",
                "text": "the shot where it just looks like the"
            },
            {
                "start": "00:02:50,080",
                "end": "00:02:54,120",
                "text": "rhinos are right in front of you and you"
            },
            {
                "start": "00:02:51,959",
                "end": "00:02:56,920",
                "text": "could just Reach Out And Touch them it"
            },
            {
                "start": "00:02:54,120",
                "end": "00:02:59,000",
                "text": "sells the illusion that well and through"
            },
            {
                "start": "00:02:56,920",
                "end": "00:03:01,159",
                "text": "an apple immersive video trailer apple"
            },
            {
                "start": "00:02:59,000",
                "end": "00:03:03,280",
                "text": "is actually shown off what live sports"
            },
            {
                "start": "00:03:01,159",
                "end": "00:03:06,280",
                "text": "footage can look like in this format and"
            },
            {
                "start": "00:03:03,280",
                "end": "00:03:08,400",
                "text": "it is also just insane like it makes you"
            },
            {
                "start": "00:03:06,280",
                "end": "00:03:10,599",
                "text": "feel like you're sitting courtside at a"
            },
            {
                "start": "00:03:08,400",
                "end": "00:03:13,200",
                "text": "Lakers game or you're on the sidelines"
            },
            {
                "start": "00:03:10,599",
                "end": "00:03:15,280",
                "text": "during the Super Bowl it is by far the"
            },
            {
                "start": "00:03:13,200",
                "end": "00:03:17,920",
                "text": "most compelling Sports viewing"
            },
            {
                "start": "00:03:15,280",
                "end": "00:03:21,120",
                "text": "experience I've ever experienced outside"
            },
            {
                "start": "00:03:17,920",
                "end": "00:03:22,879",
                "text": "of actually being at the game to me it's"
            },
            {
                "start": "00:03:21,120",
                "end": "00:03:25,000",
                "text": "one of the most compelling things about"
            },
            {
                "start": "00:03:22,879",
                "end": "00:03:26,720",
                "text": "Vision Pro and there's more content"
            },
            {
                "start": "00:03:25,000",
                "end": "00:03:29,080",
                "text": "coming to The Vision Pro including the"
            },
            {
                "start": "00:03:26,720",
                "end": "00:03:31,000",
                "text": "first ever scripted show in this format"
            },
            {
                "start": "00:03:29,080",
                "end": "00:03:33,720",
                "text": "from Oscar winning director Edward"
            },
            {
                "start": "00:03:31,000",
                "end": "00:03:35,360",
                "text": "burger and speaking of content the last"
            },
            {
                "start": "00:03:33,720",
                "end": "00:03:38,280",
                "text": "main thing I've been using the Vision"
            },
            {
                "start": "00:03:35,360",
                "end": "00:03:40,959",
                "text": "Pro for is watching 2D movies and TV"
            },
            {
                "start": "00:03:38,280",
                "end": "00:03:43,120",
                "text": "shows unless you have a giant theater in"
            },
            {
                "start": "00:03:40,959",
                "end": "00:03:45,280",
                "text": "your home nothing else will come close"
            },
            {
                "start": "00:03:43,120",
                "end": "00:03:48,280",
                "text": "to the experience of watching content on"
            },
            {
                "start": "00:03:45,280",
                "end": "00:03:50,439",
                "text": "Vision Pro this headset is the same to"
            },
            {
                "start": "00:03:48,280",
                "end": "00:03:53,280",
                "text": "TVs and movie theaters as what the"
            },
            {
                "start": "00:03:50,439",
                "end": "00:03:56,760",
                "text": "airpods are to stereo systems and"
            },
            {
                "start": "00:03:53,280",
                "end": "00:03:59,120",
                "text": "speakers and yes you can watch 3D movies"
            },
            {
                "start": "00:03:56,760",
                "end": "00:04:01,959",
                "text": "as well though I've mainly stuck to 2D"
            },
            {
                "start": "00:03:59,120",
                "end": "00:04:03,720",
                "text": "movies as some 3D movies with a screen"
            },
            {
                "start": "00:04:01,959",
                "end": "00:04:05,840",
                "text": "as large as what you get in the Vision"
            },
            {
                "start": "00:04:03,720",
                "end": "00:04:07,959",
                "text": "Pro I've noticed it can cause me to get"
            },
            {
                "start": "00:04:05,840",
                "end": "00:04:10,560",
                "text": "a bit motion sick now while I don't use"
            },
            {
                "start": "00:04:07,959",
                "end": "00:04:13,599",
                "text": "the Vision Pro as much as my TV there"
            },
            {
                "start": "00:04:10,560",
                "end": "00:04:16,280",
                "text": "are two main use cases where I found I"
            },
            {
                "start": "00:04:13,599",
                "end": "00:04:18,160",
                "text": "prefer it to watch content on one is"
            },
            {
                "start": "00:04:16,280",
                "end": "00:04:20,400",
                "text": "when I'm traveling and I don't have a"
            },
            {
                "start": "00:04:18,160",
                "end": "00:04:22,360",
                "text": "great TV setup like when I was at the"
            },
            {
                "start": "00:04:20,400",
                "end": "00:04:24,840",
                "text": "beach and I wanted to watch the latest"
            },
            {
                "start": "00:04:22,360",
                "end": "00:04:26,680",
                "text": "episode of House of dragon I've also"
            },
            {
                "start": "00:04:24,840",
                "end": "00:04:29,520",
                "text": "found it useful for when I want to watch"
            },
            {
                "start": "00:04:26,680",
                "end": "00:04:31,680",
                "text": "TV during the day where unlike my TV"
            },
            {
                "start": "00:04:29,520",
                "end": "00:04:34,000",
                "text": "there there's no glare from surrounding"
            },
            {
                "start": "00:04:31,680",
                "end": "00:04:36,880",
                "text": "Windows the sound quality of the vision"
            },
            {
                "start": "00:04:34,000",
                "end": "00:04:39,240",
                "text": "Pro's dual driver audio pods is actually"
            },
            {
                "start": "00:04:36,880",
                "end": "00:04:41,800",
                "text": "pretty good I didn't immediately feel"
            },
            {
                "start": "00:04:39,240",
                "end": "00:04:44,400",
                "text": "the need to reach for my earbuds when I"
            },
            {
                "start": "00:04:41,800",
                "end": "00:04:46,720",
                "text": "was watching something however using a"
            },
            {
                "start": "00:04:44,400",
                "end": "00:04:49,800",
                "text": "set of Apple's newest version of airpods"
            },
            {
                "start": "00:04:46,720",
                "end": "00:04:51,520",
                "text": "Pro with the USBC case those do"
            },
            {
                "start": "00:04:49,800",
                "end": "00:04:53,759",
                "text": "significantly improve the audio"
            },
            {
                "start": "00:04:51,520",
                "end": "00:04:56,199",
                "text": "experience of the Vision Pro by blocking"
            },
            {
                "start": "00:04:53,759",
                "end": "00:04:59,759",
                "text": "out background noise and providing way"
            },
            {
                "start": "00:04:56,199",
                "end": "00:05:03,039",
                "text": "better bass so what have I not used the"
            },
            {
                "start": "00:04:59,759",
                "end": "00:05:05,000",
                "text": "Vision Pro 4 first is using it for work"
            },
            {
                "start": "00:05:03,039",
                "end": "00:05:07,800",
                "text": "you can use it with a Mac to create a"
            },
            {
                "start": "00:05:05,000",
                "end": "00:05:09,639",
                "text": "giant virtual Mac window which is great"
            },
            {
                "start": "00:05:07,800",
                "end": "00:05:12,080",
                "text": "for when you're working off a Macbook or"
            },
            {
                "start": "00:05:09,639",
                "end": "00:05:15,280",
                "text": "MacBook Air and want to view content on"
            },
            {
                "start": "00:05:12,080",
                "end": "00:05:17,360",
                "text": "a larger screen the second work use case"
            },
            {
                "start": "00:05:15,280",
                "end": "00:05:19,720",
                "text": "is having a bunch of apps in multiple"
            },
            {
                "start": "00:05:17,360",
                "end": "00:05:21,880",
                "text": "virtual Windows around you but I find"
            },
            {
                "start": "00:05:19,720",
                "end": "00:05:23,960",
                "text": "that use case less compelling it looks"
            },
            {
                "start": "00:05:21,880",
                "end": "00:05:26,120",
                "text": "cool and it does allow you to Conta"
            },
            {
                "start": "00:05:23,960",
                "end": "00:05:27,840",
                "text": "switched faster meaning you can move"
            },
            {
                "start": "00:05:26,120",
                "end": "00:05:30,199",
                "text": "from one task to another and then back"
            },
            {
                "start": "00:05:27,840",
                "end": "00:05:33,280",
                "text": "to the other task but that context"
            },
            {
                "start": "00:05:30,199",
                "end": "00:05:34,960",
                "text": "switching is more mentally taxing I do"
            },
            {
                "start": "00:05:33,280",
                "end": "00:05:37,199",
                "text": "like that I can just move a window"
            },
            {
                "start": "00:05:34,960",
                "end": "00:05:39,520",
                "text": "completely out of view to focus on"
            },
            {
                "start": "00:05:37,199",
                "end": "00:05:42,639",
                "text": "another window though now would I use"
            },
            {
                "start": "00:05:39,520",
                "end": "00:05:45,280",
                "text": "Vision Pro to replace my studio display"
            },
            {
                "start": "00:05:42,639",
                "end": "00:05:48,039",
                "text": "no using the studio display as my"
            },
            {
                "start": "00:05:45,280",
                "end": "00:05:49,720",
                "text": "monitor is just more comfortable"
            },
            {
                "start": "00:05:48,039",
                "end": "00:05:52,120",
                "text": "depending on the person and the"
            },
            {
                "start": "00:05:49,720",
                "end": "00:05:54,160",
                "text": "situation I can see a use case for when"
            },
            {
                "start": "00:05:52,120",
                "end": "00:05:56,240",
                "text": "you're traveling without a monitor and"
            },
            {
                "start": "00:05:54,160",
                "end": "00:05:58,639",
                "text": "using the Vision Pro with your MacBook"
            },
            {
                "start": "00:05:56,240",
                "end": "00:06:01,039",
                "text": "for quick spurts when you want a larger"
            },
            {
                "start": "00:05:58,639",
                "end": "00:06:03,360",
                "text": "display the environments can be nice to"
            },
            {
                "start": "00:06:01,039",
                "end": "00:06:05,720",
                "text": "work in because they help block out all"
            },
            {
                "start": "00:06:03,360",
                "end": "00:06:07,800",
                "text": "the distractions around you it's like"
            },
            {
                "start": "00:06:05,720",
                "end": "00:06:09,880",
                "text": "noise cancellation for your vision"
            },
            {
                "start": "00:06:07,800",
                "end": "00:06:12,280",
                "text": "though I'm not sure I'd have the courage"
            },
            {
                "start": "00:06:09,880",
                "end": "00:06:14,199",
                "text": "to wear it in a coffee shop just yet"
            },
            {
                "start": "00:06:12,280",
                "end": "00:06:16,919",
                "text": "gaming is another thing I haven't found"
            },
            {
                "start": "00:06:14,199",
                "end": "00:06:19,000",
                "text": "myself using the Vision Pro 4 I've tried"
            },
            {
                "start": "00:06:16,919",
                "end": "00:06:20,840",
                "text": "a few and looked at plenty of games out"
            },
            {
                "start": "00:06:19,000",
                "end": "00:06:22,720",
                "text": "there for it but they're either too"
            },
            {
                "start": "00:06:20,840",
                "end": "00:06:24,360",
                "text": "expensive for me to want to really try"
            },
            {
                "start": "00:06:22,720",
                "end": "00:06:26,080",
                "text": "them out or they just haven't really"
            },
            {
                "start": "00:06:24,360",
                "end": "00:06:28,160",
                "text": "appealed to me though I'm the type of"
            },
            {
                "start": "00:06:26,080",
                "end": "00:06:30,319",
                "text": "gamer that plays very few games but of"
            },
            {
                "start": "00:06:28,160",
                "end": "00:06:32,880",
                "text": "the games I do play i s a lot of hours"
            },
            {
                "start": "00:06:30,319",
                "end": "00:06:35,120",
                "text": "into them so this might just be a me"
            },
            {
                "start": "00:06:32,880",
                "end": "00:06:37,680",
                "text": "thing FaceTime is another feature I"
            },
            {
                "start": "00:06:35,120",
                "end": "00:06:40,080",
                "text": "haven't used I've used it once to scare"
            },
            {
                "start": "00:06:37,680",
                "end": "00:06:42,039",
                "text": "my family members with my Persona which"
            },
            {
                "start": "00:06:40,080",
                "end": "00:06:44,720",
                "text": "The Vision Pro creates when it scans"
            },
            {
                "start": "00:06:42,039",
                "end": "00:06:46,400",
                "text": "your face during initial setup the last"
            },
            {
                "start": "00:06:44,720",
                "end": "00:06:48,840",
                "text": "thing I haven't found myself using"
            },
            {
                "start": "00:06:46,400",
                "end": "00:06:51,479",
                "text": "Vision Pro for at all is specifically"
            },
            {
                "start": "00:06:48,840",
                "end": "00:06:53,440",
                "text": "for airline travel mainly because of its"
            },
            {
                "start": "00:06:51,479",
                "end": "00:06:56,039",
                "text": "size if you're already bringing a"
            },
            {
                "start": "00:06:53,440",
                "end": "00:06:58,599",
                "text": "carryon bag and a personal item onto a"
            },
            {
                "start": "00:06:56,039",
                "end": "00:07:00,919",
                "text": "plane The Vision Pro in its case is"
            },
            {
                "start": "00:06:58,599",
                "end": "00:07:03,240",
                "text": "going to take up a lot of space in one"
            },
            {
                "start": "00:07:00,919",
                "end": "00:07:05,680",
                "text": "of those bags though yes you could just"
            },
            {
                "start": "00:07:03,240",
                "end": "00:07:08,039",
                "text": "take the Vision Pro like this and put it"
            },
            {
                "start": "00:07:05,680",
                "end": "00:07:10,720",
                "text": "directly into one of your bags though"
            },
            {
                "start": "00:07:08,039",
                "end": "00:07:13,319",
                "text": "given how much this device costs and how"
            },
            {
                "start": "00:07:10,720",
                "end": "00:07:16,240",
                "text": "fragile some of its components are I'm"
            },
            {
                "start": "00:07:13,319",
                "end": "00:07:17,879",
                "text": "not sure I'd recommend doing that so if"
            },
            {
                "start": "00:07:16,240",
                "end": "00:07:20,599",
                "text": "the Vision Pro can do some pretty"
            },
            {
                "start": "00:07:17,879",
                "end": "00:07:22,960",
                "text": "incredible things why did it fade so"
            },
            {
                "start": "00:07:20,599",
                "end": "00:07:26,599",
                "text": "quickly and why do people consider it a"
            },
            {
                "start": "00:07:22,960",
                "end": "00:07:28,759",
                "text": "flop do I consider it a flop no not"
            },
            {
                "start": "00:07:26,599",
                "end": "00:07:30,759",
                "text": "necessarily it depends on how you look"
            },
            {
                "start": "00:07:28,759",
                "end": "00:07:33,400",
                "text": "at the Vision Pro Pro its underlying"
            },
            {
                "start": "00:07:30,759",
                "end": "00:07:36,120",
                "text": "technology platform and the product"
            },
            {
                "start": "00:07:33,400",
                "end": "00:07:38,800",
                "text": "itself when looking at the underlying"
            },
            {
                "start": "00:07:36,120",
                "end": "00:07:41,319",
                "text": "technology platform I think Apple"
            },
            {
                "start": "00:07:38,800",
                "end": "00:07:44,159",
                "text": "actually did what they set out to do the"
            },
            {
                "start": "00:07:41,319",
                "end": "00:07:46,680",
                "text": "highresolution micro OLED panels that's"
            },
            {
                "start": "00:07:44,159",
                "end": "00:07:48,800",
                "text": "the tech responsible for creating such a"
            },
            {
                "start": "00:07:46,680",
                "end": "00:07:51,840",
                "text": "crisp image with outstanding color"
            },
            {
                "start": "00:07:48,800",
                "end": "00:07:53,479",
                "text": "reproduction and contrast they also move"
            },
            {
                "start": "00:07:51,840",
                "end": "00:07:55,960",
                "text": "the Vision Pro will actually scan the"
            },
            {
                "start": "00:07:53,479",
                "end": "00:07:59,000",
                "text": "distance between your eyes to align the"
            },
            {
                "start": "00:07:55,960",
                "end": "00:08:01,000",
                "text": "displays perfectly for that 3D depth"
            },
            {
                "start": "00:07:59,000",
                "end": "00:08:02,759",
                "text": "effect which is key to viewing"
            },
            {
                "start": "00:08:01,000",
                "end": "00:08:05,039",
                "text": "everything in the Vision Pro like"
            },
            {
                "start": "00:08:02,759",
                "end": "00:08:07,199",
                "text": "spatial photos and videos while the"
            },
            {
                "start": "00:08:05,039",
                "end": "00:08:10,000",
                "text": "spatial photos and videos captured on my"
            },
            {
                "start": "00:08:07,199",
                "end": "00:08:11,800",
                "text": "iPhone 15 Pro Max aren't nearly as"
            },
            {
                "start": "00:08:10,000",
                "end": "00:08:14,240",
                "text": "impressive as the ones captured on the"
            },
            {
                "start": "00:08:11,800",
                "end": "00:08:17,440",
                "text": "Vision Pro itself thanks to the better"
            },
            {
                "start": "00:08:14,240",
                "end": "00:08:19,840",
                "text": "depth effect it creates even today I"
            },
            {
                "start": "00:08:17,440",
                "end": "00:08:22,080",
                "text": "think spatial photos and videos are"
            },
            {
                "start": "00:08:19,840",
                "end": "00:08:24,560",
                "text": "compelling though somewhat limiting"
            },
            {
                "start": "00:08:22,080",
                "end": "00:08:26,720",
                "text": "since better videos can only be taken"
            },
            {
                "start": "00:08:24,560",
                "end": "00:08:29,039",
                "text": "with Vision Pro and overall their"
            },
            {
                "start": "00:08:26,720",
                "end": "00:08:31,599",
                "text": "resolution and Clarity isn't as crystal"
            },
            {
                "start": "00:08:29,039",
                "end": "00:08:34,240",
                "text": "clear as you want it to be hopefully"
            },
            {
                "start": "00:08:31,599",
                "end": "00:08:36,800",
                "text": "that'll improve over time oddly enough"
            },
            {
                "start": "00:08:34,240",
                "end": "00:08:39,440",
                "text": "for me today panoramas are the most"
            },
            {
                "start": "00:08:36,800",
                "end": "00:08:41,800",
                "text": "impressive photo video feature on Vision"
            },
            {
                "start": "00:08:39,440",
                "end": "00:08:43,599",
                "text": "Pro because it can recreate the"
            },
            {
                "start": "00:08:41,800",
                "end": "00:08:46,600",
                "text": "perspective you had when you took the"
            },
            {
                "start": "00:08:43,599",
                "end": "00:08:48,959",
                "text": "Panorama and its high res so it looks"
            },
            {
                "start": "00:08:46,600",
                "end": "00:08:51,279",
                "text": "really impressive the lidar and Camera"
            },
            {
                "start": "00:08:48,959",
                "end": "00:08:53,880",
                "text": "Suite is another incredible technology"
            },
            {
                "start": "00:08:51,279",
                "end": "00:08:56,279",
                "text": "packed into Vision Pro it's the reason"
            },
            {
                "start": "00:08:53,880",
                "end": "00:08:58,560",
                "text": "the tracking and placement of virtual"
            },
            {
                "start": "00:08:56,279",
                "end": "00:09:01,120",
                "text": "objects in your environment feels so"
            },
            {
                "start": "00:08:58,560",
                "end": "00:09:03,440",
                "text": "damn real the camera Suite also helps"
            },
            {
                "start": "00:09:01,120",
                "end": "00:09:05,920",
                "text": "power Apple's hand and eye tracking"
            },
            {
                "start": "00:09:03,440",
                "end": "00:09:07,720",
                "text": "which is actually quite good it allows"
            },
            {
                "start": "00:09:05,920",
                "end": "00:09:09,480",
                "text": "you to look at something with your eyes"
            },
            {
                "start": "00:09:07,720",
                "end": "00:09:11,880",
                "text": "and pinch your fingers together to"
            },
            {
                "start": "00:09:09,480",
                "end": "00:09:14,040",
                "text": "select it though parts of the experience"
            },
            {
                "start": "00:09:11,880",
                "end": "00:09:16,200",
                "text": "over the past 6 months have still felt a"
            },
            {
                "start": "00:09:14,040",
                "end": "00:09:18,720",
                "text": "bit clunky like when watching Apple"
            },
            {
                "start": "00:09:16,200",
                "end": "00:09:20,839",
                "text": "immersive videos often when you glance"
            },
            {
                "start": "00:09:18,720",
                "end": "00:09:22,640",
                "text": "up the little dot for the control center"
            },
            {
                "start": "00:09:20,839",
                "end": "00:09:24,959",
                "text": "constantly appears with its default"
            },
            {
                "start": "00:09:22,640",
                "end": "00:09:28,120",
                "text": "setting though Apple has addressed this"
            },
            {
                "start": "00:09:24,959",
                "end": "00:09:30,240",
                "text": "with a new hand gesture in Vision OS 2"
            },
            {
                "start": "00:09:28,120",
                "end": "00:09:31,680",
                "text": "which comes out later this year here and"
            },
            {
                "start": "00:09:30,240",
                "end": "00:09:34,240",
                "text": "sometimes I find the eye tracking to be"
            },
            {
                "start": "00:09:31,680",
                "end": "00:09:35,519",
                "text": "a bit fatiguing honestly when you're"
            },
            {
                "start": "00:09:34,240",
                "end": "00:09:37,040",
                "text": "always having to look at the thing"
            },
            {
                "start": "00:09:35,519",
                "end": "00:09:38,360",
                "text": "you're trying to select and then"
            },
            {
                "start": "00:09:37,040",
                "end": "00:09:40,880",
                "text": "sometimes you like look at the wrong"
            },
            {
                "start": "00:09:38,360",
                "end": "00:09:43,279",
                "text": "thing you select the wrong thing and"
            },
            {
                "start": "00:09:40,880",
                "end": "00:09:46,120",
                "text": "yeah now the last major Hardware"
            },
            {
                "start": "00:09:43,279",
                "end": "00:09:48,720",
                "text": "breakthrough with Vision Pro is the R1"
            },
            {
                "start": "00:09:46,120",
                "end": "00:09:50,920",
                "text": "chip to make the eye and hand tracking"
            },
            {
                "start": "00:09:48,720",
                "end": "00:09:53,600",
                "text": "as well as object placement work so"
            },
            {
                "start": "00:09:50,920",
                "end": "00:09:55,800",
                "text": "quickly that you can't perceive any lag"
            },
            {
                "start": "00:09:53,600",
                "end": "00:09:58,399",
                "text": "Apple had to design a chip separate from"
            },
            {
                "start": "00:09:55,800",
                "end": "00:10:01,079",
                "text": "the normal processor to run all of those"
            },
            {
                "start": "00:09:58,399",
                "end": "00:10:02,959",
                "text": "tasks now now does the R1 chip mean you"
            },
            {
                "start": "00:10:01,079",
                "end": "00:10:06,360",
                "text": "can't get any motion sickness while"
            },
            {
                "start": "00:10:02,959",
                "end": "00:10:08,680",
                "text": "wearing Vision Pro no but it does"
            },
            {
                "start": "00:10:06,360",
                "end": "00:10:10,760",
                "text": "significantly reduce the chances of that"
            },
            {
                "start": "00:10:08,680",
                "end": "00:10:13,399",
                "text": "happening I've only noticed getting"
            },
            {
                "start": "00:10:10,760",
                "end": "00:10:15,399",
                "text": "motion sick when watching a 3D movie"
            },
            {
                "start": "00:10:13,399",
                "end": "00:10:17,880",
                "text": "occasionally when walking around with a"
            },
            {
                "start": "00:10:15,399",
                "end": "00:10:19,519",
                "text": "headset on and my eyes are dry or in a"
            },
            {
                "start": "00:10:17,880",
                "end": "00:10:21,760",
                "text": "situation where the tracking goes"
            },
            {
                "start": "00:10:19,519",
                "end": "00:10:24,440",
                "text": "berserk like when my Apple TV screen"
            },
            {
                "start": "00:10:21,760",
                "end": "00:10:26,440",
                "text": "saver turned on in a dimly lit room and"
            },
            {
                "start": "00:10:24,440",
                "end": "00:10:28,880",
                "text": "the headset decided to track against"
            },
            {
                "start": "00:10:26,440",
                "end": "00:10:32,760",
                "text": "that overall Vision Pro's underlying"
            },
            {
                "start": "00:10:28,880",
                "end": "00:10:34,959",
                "text": "technology ol is insanely impressive but"
            },
            {
                "start": "00:10:32,760",
                "end": "00:10:37,839",
                "text": "where the Vision Pro will likely feel"
            },
            {
                "start": "00:10:34,959",
                "end": "00:10:40,079",
                "text": "like a flop to some is all of the issues"
            },
            {
                "start": "00:10:37,839",
                "end": "00:10:43,040",
                "text": "with the product experience the weight"
            },
            {
                "start": "00:10:40,079",
                "end": "00:10:46,639",
                "text": "of the device is the most glaring issue"
            },
            {
                "start": "00:10:43,040",
                "end": "00:10:49,240",
                "text": "Apple Vision Pro can weigh 600 to 650 g"
            },
            {
                "start": "00:10:46,639",
                "end": "00:10:51,600",
                "text": "depending on the light seal and headband"
            },
            {
                "start": "00:10:49,240",
                "end": "00:10:54,399",
                "text": "configuration and that's just too damn"
            },
            {
                "start": "00:10:51,600",
                "end": "00:10:56,880",
                "text": "heavy for most people worse is Apple"
            },
            {
                "start": "00:10:54,399",
                "end": "00:10:58,720",
                "text": "shipped to pretty garbage headbands for"
            },
            {
                "start": "00:10:56,880",
                "end": "00:11:00,959",
                "text": "Distributing the weight of the Vision"
            },
            {
                "start": "00:10:58,720",
                "end": "00:11:03,440",
                "text": "Pro around around your head the first is"
            },
            {
                "start": "00:11:00,959",
                "end": "00:11:05,639",
                "text": "the solo nit band which has an awesome"
            },
            {
                "start": "00:11:03,440",
                "end": "00:11:08,279",
                "text": "adjustable dial and great fabric"
            },
            {
                "start": "00:11:05,639",
                "end": "00:11:10,320",
                "text": "material however Apple decided not to"
            },
            {
                "start": "00:11:08,279",
                "end": "00:11:13,279",
                "text": "ship it with the optional head strap"
            },
            {
                "start": "00:11:10,320",
                "end": "00:11:15,399",
                "text": "which they originally showed off at WWDC"
            },
            {
                "start": "00:11:13,279",
                "end": "00:11:17,920",
                "text": "they instead shipped the solo knit band"
            },
            {
                "start": "00:11:15,399",
                "end": "00:11:20,200",
                "text": "with the additional dual Loop band the"
            },
            {
                "start": "00:11:17,920",
                "end": "00:11:22,560",
                "text": "problem is the Dual Loop band is harder"
            },
            {
                "start": "00:11:20,200",
                "end": "00:11:24,760",
                "text": "to adjust and the bottom strap doesn't"
            },
            {
                "start": "00:11:22,560",
                "end": "00:11:27,360",
                "text": "cover as much of your head as the solo"
            },
            {
                "start": "00:11:24,760",
                "end": "00:11:28,959",
                "text": "knit band does for weight distribution"
            },
            {
                "start": "00:11:27,360",
                "end": "00:11:31,160",
                "text": "wearing the Vision Pro with the solo"
            },
            {
                "start": "00:11:28,959",
                "end": "00:11:33,720",
                "text": "knit band without any additional type of"
            },
            {
                "start": "00:11:31,160",
                "end": "00:11:35,480",
                "text": "head strap over top that's typically"
            },
            {
                "start": "00:11:33,720",
                "end": "00:11:37,839",
                "text": "going to cause the Vision Pro to dig"
            },
            {
                "start": "00:11:35,480",
                "end": "00:11:39,880",
                "text": "into your cheeks or your forehead as you"
            },
            {
                "start": "00:11:37,839",
                "end": "00:11:42,279",
                "text": "continue to wear it to remedy that"
            },
            {
                "start": "00:11:39,880",
                "end": "00:11:44,839",
                "text": "you'll either try to move it or further"
            },
            {
                "start": "00:11:42,279",
                "end": "00:11:46,440",
                "text": "tighten it and it's easy to overtighten"
            },
            {
                "start": "00:11:44,839",
                "end": "00:11:49,160",
                "text": "it to the point where it can cause"
            },
            {
                "start": "00:11:46,440",
                "end": "00:11:51,120",
                "text": "headaches migraines and general Facial"
            },
            {
                "start": "00:11:49,160",
                "end": "00:11:53,440",
                "text": "Pain wearing Vision Pro gave me the"
            },
            {
                "start": "00:11:51,120",
                "end": "00:11:56,040",
                "text": "first migraine I've ever experienced in"
            },
            {
                "start": "00:11:53,440",
                "end": "00:11:57,920",
                "text": "my entire life and it got so bad that I"
            },
            {
                "start": "00:11:56,040",
                "end": "00:12:00,279",
                "text": "just really regretted buying a Vision"
            },
            {
                "start": "00:11:57,920",
                "end": "00:12:02,760",
                "text": "Pro but thankfully a third party"
            },
            {
                "start": "00:12:00,279",
                "end": "00:12:05,040",
                "text": "accessory maker came to my rescue I"
            },
            {
                "start": "00:12:02,760",
                "end": "00:12:07,200",
                "text": "bought this speeden Vision Pro headstrap"
            },
            {
                "start": "00:12:05,040",
                "end": "00:12:09,360",
                "text": "which is a similar design to what Apple"
            },
            {
                "start": "00:12:07,200",
                "end": "00:12:11,920",
                "text": "originally showed off with the solo nit"
            },
            {
                "start": "00:12:09,360",
                "end": "00:12:13,720",
                "text": "band and should have shipped even with"
            },
            {
                "start": "00:12:11,920",
                "end": "00:12:15,720",
                "text": "this strap and they're not a sponsor by"
            },
            {
                "start": "00:12:13,720",
                "end": "00:12:19,079",
                "text": "the way even with the strap The Vision"
            },
            {
                "start": "00:12:15,720",
                "end": "00:12:21,680",
                "text": "Pro it does still feel heavy yes but"
            },
            {
                "start": "00:12:19,079",
                "end": "00:12:23,440",
                "text": "it's not unmanageable since getting it"
            },
            {
                "start": "00:12:21,680",
                "end": "00:12:25,920",
                "text": "I've been able to comfortably wear"
            },
            {
                "start": "00:12:23,440",
                "end": "00:12:28,519",
                "text": "Vision Pro for well over an hour with no"
            },
            {
                "start": "00:12:25,920",
                "end": "00:12:30,079",
                "text": "Facial Pain or headaches afterward I've"
            },
            {
                "start": "00:12:28,519",
                "end": "00:12:32,079",
                "text": "left a link to it and the other"
            },
            {
                "start": "00:12:30,079",
                "end": "00:12:34,920",
                "text": "accessories for Vision Pro in the blog"
            },
            {
                "start": "00:12:32,079",
                "end": "00:12:37,240",
                "text": "post for this review at 6months l.net"
            },
            {
                "start": "00:12:34,920",
                "end": "00:12:39,120",
                "text": "link to that in the description below"
            },
            {
                "start": "00:12:37,240",
                "end": "00:12:40,680",
                "text": "now there is one more Comfort problem"
            },
            {
                "start": "00:12:39,120",
                "end": "00:12:43,160",
                "text": "though that Still Remains for me with"
            },
            {
                "start": "00:12:40,680",
                "end": "00:12:45,360",
                "text": "Vision Pro and that's eye strain and eye"
            },
            {
                "start": "00:12:43,160",
                "end": "00:12:47,000",
                "text": "fatigue because we all tend to Blink"
            },
            {
                "start": "00:12:45,360",
                "end": "00:12:49,519",
                "text": "less when we look at displays and"
            },
            {
                "start": "00:12:47,000",
                "end": "00:12:52,160",
                "text": "screens our eyes will then dry out feel"
            },
            {
                "start": "00:12:49,519",
                "end": "00:12:55,480",
                "text": "more strained and fatigued which is why"
            },
            {
                "start": "00:12:52,160",
                "end": "00:12:57,399",
                "text": "you've probably heard of the 202020 rule"
            },
            {
                "start": "00:12:55,480",
                "end": "00:12:59,920",
                "text": "where every 20 minutes you're supposed"
            },
            {
                "start": "00:12:57,399",
                "end": "00:13:02,360",
                "text": "to look at something 20 ft away for at"
            },
            {
                "start": "00:12:59,920",
                "end": "00:13:04,120",
                "text": "least 20 seconds well that's kind of"
            },
            {
                "start": "00:13:02,360",
                "end": "00:13:06,120",
                "text": "hard to do in The Vision Pro if you're"
            },
            {
                "start": "00:13:04,120",
                "end": "00:13:08,120",
                "text": "watching a movie it's not really"
            },
            {
                "start": "00:13:06,120",
                "end": "00:13:10,240",
                "text": "practical now I've noticed this is worse"
            },
            {
                "start": "00:13:08,120",
                "end": "00:13:12,360",
                "text": "when wearing contacts versus glasses"
            },
            {
                "start": "00:13:10,240",
                "end": "00:13:14,279",
                "text": "with headsets like Vision Pro if you do"
            },
            {
                "start": "00:13:12,360",
                "end": "00:13:16,720",
                "text": "wear contacts one thing I found that's"
            },
            {
                "start": "00:13:14,279",
                "end": "00:13:18,639",
                "text": "really helped me after a long session"
            },
            {
                "start": "00:13:16,720",
                "end": "00:13:20,680",
                "text": "with Vision Pro is getting some eye"
            },
            {
                "start": "00:13:18,639",
                "end": "00:13:23,279",
                "text": "drops like these and just putting a few"
            },
            {
                "start": "00:13:20,680",
                "end": "00:13:26,320",
                "text": "drops in each eye to help refreshen them"
            },
            {
                "start": "00:13:23,279",
                "end": "00:13:29,160",
                "text": "and cause them not to be as dry now what"
            },
            {
                "start": "00:13:26,320",
                "end": "00:13:31,399",
                "text": "about battery life 2 hours sounds like"
            },
            {
                "start": "00:13:29,160",
                "end": "00:13:33,320",
                "text": "not that much but when you take the ey"
            },
            {
                "start": "00:13:31,399",
                "end": "00:13:35,880",
                "text": "strain plus the weight of the device"
            },
            {
                "start": "00:13:33,320",
                "end": "00:13:38,079",
                "text": "into account to me the battery life has"
            },
            {
                "start": "00:13:35,880",
                "end": "00:13:40,399",
                "text": "actually been pretty adequate and if you"
            },
            {
                "start": "00:13:38,079",
                "end": "00:13:42,720",
                "text": "want to use Vision Pro longer you always"
            },
            {
                "start": "00:13:40,399",
                "end": "00:13:44,560",
                "text": "have the option to plug it in now"
            },
            {
                "start": "00:13:42,720",
                "end": "00:13:47,399",
                "text": "another reason why people might feel"
            },
            {
                "start": "00:13:44,560",
                "end": "00:13:49,680",
                "text": "like The Vision Pro is a flop is app"
            },
            {
                "start": "00:13:47,399",
                "end": "00:13:53,240",
                "text": "availability most of the apps just"
            },
            {
                "start": "00:13:49,680",
                "end": "00:13:55,680",
                "text": "provide novelty but again novelty can"
            },
            {
                "start": "00:13:53,240",
                "end": "00:13:57,800",
                "text": "only get you so far I just haven't"
            },
            {
                "start": "00:13:55,680",
                "end": "00:14:00,399",
                "text": "really found anything that's kept me"
            },
            {
                "start": "00:13:57,800",
                "end": "00:14:02,560",
                "text": "wanting to come back and use the headset"
            },
            {
                "start": "00:14:00,399",
                "end": "00:14:05,480",
                "text": "outside of core content apps like the"
            },
            {
                "start": "00:14:02,560",
                "end": "00:14:07,920",
                "text": "max app but the content app availability"
            },
            {
                "start": "00:14:05,480",
                "end": "00:14:10,759",
                "text": "is lacking 6 months in there's not an"
            },
            {
                "start": "00:14:07,920",
                "end": "00:14:12,639",
                "text": "official Netflix or YouTube app now one"
            },
            {
                "start": "00:14:10,759",
                "end": "00:14:14,720",
                "text": "reason developers of larger apps might"
            },
            {
                "start": "00:14:12,639",
                "end": "00:14:17,160",
                "text": "have been more hesitant to develop for"
            },
            {
                "start": "00:14:14,720",
                "end": "00:14:19,720",
                "text": "the Vision Pro is Apple's business model"
            },
            {
                "start": "00:14:17,160",
                "end": "00:14:22,199",
                "text": "for it the company has called Vision Pro"
            },
            {
                "start": "00:14:19,720",
                "end": "00:14:24,000",
                "text": "its first spatial computer I don't know"
            },
            {
                "start": "00:14:22,199",
                "end": "00:14:26,320",
                "text": "about you but when I hear the word"
            },
            {
                "start": "00:14:24,000",
                "end": "00:14:28,759",
                "text": "computer I typically think of file"
            },
            {
                "start": "00:14:26,320",
                "end": "00:14:30,959",
                "text": "systems open protocols oh and the"
            },
            {
                "start": "00:14:28,759",
                "end": "00:14:33,720",
                "text": "ability to download software freely"
            },
            {
                "start": "00:14:30,959",
                "end": "00:14:36,199",
                "text": "outside of Apple's App Store wal Garden"
            },
            {
                "start": "00:14:33,720",
                "end": "00:14:38,880",
                "text": "The Vision Pro isn't that it's more like"
            },
            {
                "start": "00:14:36,199",
                "end": "00:14:41,560",
                "text": "a spatial iPad and I think the software"
            },
            {
                "start": "00:14:38,880",
                "end": "00:14:43,240",
                "text": "development for this device has suffered"
            },
            {
                "start": "00:14:41,560",
                "end": "00:14:45,120",
                "text": "because of that the last thing about the"
            },
            {
                "start": "00:14:43,240",
                "end": "00:14:47,800",
                "text": "Vision Pro that I think contributes to"
            },
            {
                "start": "00:14:45,120",
                "end": "00:14:50,880",
                "text": "this feeling like this product is a flop"
            },
            {
                "start": "00:14:47,800",
                "end": "00:14:52,800",
                "text": "is Apple just over engineered it"
            },
            {
                "start": "00:14:50,880",
                "end": "00:14:54,600",
                "text": "eyesight is a good example of this it"
            },
            {
                "start": "00:14:52,800",
                "end": "00:14:57,040",
                "text": "makes it sort of look like you can see"
            },
            {
                "start": "00:14:54,600",
                "end": "00:14:59,240",
                "text": "the person's eyes as they look at you"
            },
            {
                "start": "00:14:57,040",
                "end": "00:15:02,160",
                "text": "while wearing Vision Pro but in in"
            },
            {
                "start": "00:14:59,240",
                "end": "00:15:04,519",
                "text": "reality from most angles it looks kind"
            },
            {
                "start": "00:15:02,160",
                "end": "00:15:06,639",
                "text": "of goofy oddly when looking at yourself"
            },
            {
                "start": "00:15:04,519",
                "end": "00:15:08,920",
                "text": "in the mirror though it looks pretty"
            },
            {
                "start": "00:15:06,639",
                "end": "00:15:11,160",
                "text": "decent Motions like when you blink your"
            },
            {
                "start": "00:15:08,920",
                "end": "00:15:13,920",
                "text": "eyes happen pretty much in real time"
            },
            {
                "start": "00:15:11,160",
                "end": "00:15:16,279",
                "text": "which is impressive now in order to get"
            },
            {
                "start": "00:15:13,920",
                "end": "00:15:19,360",
                "text": "eyesight to work Apple needed to create"
            },
            {
                "start": "00:15:16,279",
                "end": "00:15:21,560",
                "text": "a 3D scan of your face which is your"
            },
            {
                "start": "00:15:19,360",
                "end": "00:15:23,880",
                "text": "Apple Persona now how well my facial"
            },
            {
                "start": "00:15:21,560",
                "end": "00:15:26,600",
                "text": "movements here map to my Persona and"
            },
            {
                "start": "00:15:23,880",
                "end": "00:15:29,360",
                "text": "blinking the eyes everything that is"
            },
            {
                "start": "00:15:26,600",
                "end": "00:15:33,639",
                "text": "impressive but the end result is still a"
            },
            {
                "start": "00:15:29,360",
                "end": "00:15:35,639",
                "text": "little bit uh yikes Vision Pro's fit is"
            },
            {
                "start": "00:15:33,639",
                "end": "00:15:37,519",
                "text": "also complex Apple made like 30s"
            },
            {
                "start": "00:15:35,639",
                "end": "00:15:39,279",
                "text": "something different light seals for it"
            },
            {
                "start": "00:15:37,519",
                "end": "00:15:41,880",
                "text": "depending on which light seal you're"
            },
            {
                "start": "00:15:39,279",
                "end": "00:15:43,800",
                "text": "fitted with the field of view or the"
            },
            {
                "start": "00:15:41,880",
                "end": "00:15:46,079",
                "text": "amount of virtual space that you see"
            },
            {
                "start": "00:15:43,800",
                "end": "00:15:48,759",
                "text": "when you put the Vision Pro on can"
            },
            {
                "start": "00:15:46,079",
                "end": "00:15:51,839",
                "text": "actually decrease luckily I was fitted"
            },
            {
                "start": "00:15:48,759",
                "end": "00:15:54,160",
                "text": "with the 21w seal which has a decent"
            },
            {
                "start": "00:15:51,839",
                "end": "00:15:56,279",
                "text": "field of view another complication with"
            },
            {
                "start": "00:15:54,160",
                "end": "00:15:58,480",
                "text": "the Vision Pro Design is you can't wear"
            },
            {
                "start": "00:15:56,279",
                "end": "00:16:00,360",
                "text": "glasses while wearing the headset you'll"
            },
            {
                "start": "00:15:58,480",
                "end": "00:16:02,880",
                "text": "need to upload your prescription and"
            },
            {
                "start": "00:16:00,360",
                "end": "00:16:05,240",
                "text": "Order Zeiss Optical inserts which"
            },
            {
                "start": "00:16:02,880",
                "end": "00:16:08,160",
                "text": "magnetically pop into the Vision Pro and"
            },
            {
                "start": "00:16:05,240",
                "end": "00:16:10,920",
                "text": "cost anywhere from 100 to"
            },
            {
                "start": "00:16:08,160",
                "end": "00:16:13,600",
                "text": "$150 another downside with Vision Pro is"
            },
            {
                "start": "00:16:10,920",
                "end": "00:16:15,279",
                "text": "there's no multi-user support if you"
            },
            {
                "start": "00:16:13,600",
                "end": "00:16:17,560",
                "text": "live with somebody else that also wants"
            },
            {
                "start": "00:16:15,279",
                "end": "00:16:19,360",
                "text": "to use this on occasion every time they"
            },
            {
                "start": "00:16:17,560",
                "end": "00:16:21,680",
                "text": "want to use it they have to use guest"
            },
            {
                "start": "00:16:19,360",
                "end": "00:16:24,199",
                "text": "mode which means they have to reset up"
            },
            {
                "start": "00:16:21,680",
                "end": "00:16:26,440",
                "text": "their hand and eye tracking every single"
            },
            {
                "start": "00:16:24,199",
                "end": "00:16:28,639",
                "text": "time they use the headset there's also a"
            },
            {
                "start": "00:16:26,440",
                "end": "00:16:30,920",
                "text": "Content DRM that basically prevents you"
            },
            {
                "start": "00:16:28,639",
                "end": "00:16:33,480",
                "text": "from doing any screen recordings while"
            },
            {
                "start": "00:16:30,920",
                "end": "00:16:35,680",
                "text": "watching any movies or TV shows which"
            },
            {
                "start": "00:16:33,480",
                "end": "00:16:38,839",
                "text": "makes sharing how great the movie"
            },
            {
                "start": "00:16:35,680",
                "end": "00:16:41,240",
                "text": "watching experience is on social pretty"
            },
            {
                "start": "00:16:38,839",
                "end": "00:16:43,319",
                "text": "difficult you can also see Reflections"
            },
            {
                "start": "00:16:41,240",
                "end": "00:16:45,839",
                "text": "and some minimal glare towards the"
            },
            {
                "start": "00:16:43,319",
                "end": "00:16:48,240",
                "text": "bottom of the lens when viewing content"
            },
            {
                "start": "00:16:45,839",
                "end": "00:16:51,079",
                "text": "which some might find to be a"
            },
            {
                "start": "00:16:48,240",
                "end": "00:16:53,880",
                "text": "downside so do I recommend getting an"
            },
            {
                "start": "00:16:51,079",
                "end": "00:16:57,079",
                "text": "apple Vision Pro for almost everyone out"
            },
            {
                "start": "00:16:53,880",
                "end": "00:16:59,880",
                "text": "there the answer to that question is no"
            },
            {
                "start": "00:16:57,079",
                "end": "00:17:00,519",
                "text": "novelty will only entertain for so long"
            },
            {
                "start": "00:16:59,880",
                "end": "00:17:04,199",
                "text": "and"
            },
            {
                "start": "00:17:00,519",
                "end": "00:17:07,240",
                "text": "$3,500 is a lot to spend on novelty plus"
            },
            {
                "start": "00:17:04,199",
                "end": "00:17:09,679",
                "text": "a giant virtual TV and computer monitor"
            },
            {
                "start": "00:17:07,240",
                "end": "00:17:12,240",
                "text": "even for the use cases I use it for"
            },
            {
                "start": "00:17:09,679",
                "end": "00:17:15,919",
                "text": "you're probably better off getting a 75"
            },
            {
                "start": "00:17:12,240",
                "end": "00:17:18,760",
                "text": "or heck even an 83 in OLED television"
            },
            {
                "start": "00:17:15,919",
                "end": "00:17:21,880",
                "text": "and you'd still spend less than"
            },
            {
                "start": "00:17:18,760",
                "end": "00:17:24,919",
                "text": "$3500 and you could watch content with"
            },
            {
                "start": "00:17:21,880",
                "end": "00:17:28,960",
                "text": "other people but what if it wasn't"
            },
            {
                "start": "00:17:24,919",
                "end": "00:17:30,919",
                "text": "$3,500 what if it was $1,500"
            },
            {
                "start": "00:17:28,960",
                "end": "00:17:32,720",
                "text": "at that price I might very well"
            },
            {
                "start": "00:17:30,919",
                "end": "00:17:34,840",
                "text": "recommend it depending on what"
            },
            {
                "start": "00:17:32,720",
                "end": "00:17:37,080",
                "text": "trade-offs Apple made to get it down to"
            },
            {
                "start": "00:17:34,840",
                "end": "00:17:39,760",
                "text": "that price the TV watching and apple"
            },
            {
                "start": "00:17:37,080",
                "end": "00:17:41,679",
                "text": "immersive video format are compelling if"
            },
            {
                "start": "00:17:39,760",
                "end": "00:17:44,520",
                "text": "they could somehow keep the excellent"
            },
            {
                "start": "00:17:41,679",
                "end": "00:17:47,799",
                "text": "displays make the device lighter I think"
            },
            {
                "start": "00:17:44,520",
                "end": "00:17:49,919",
                "text": "it would be a better product so overall"
            },
            {
                "start": "00:17:47,799",
                "end": "00:17:52,200",
                "text": "yes I have found a use for the Vision"
            },
            {
                "start": "00:17:49,919",
                "end": "00:17:54,799",
                "text": "Pro that does keep me coming back to the"
            },
            {
                "start": "00:17:52,200",
                "end": "00:17:57,000",
                "text": "headset time and time again I don't"
            },
            {
                "start": "00:17:54,799",
                "end": "00:17:59,280",
                "text": "think the device is a total flop the"
            },
            {
                "start": "00:17:57,000",
                "end": "00:18:02,360",
                "text": "technology platform Apple developed is"
            },
            {
                "start": "00:17:59,280",
                "end": "00:18:04,600",
                "text": "seriously impressive but I don't"
            },
            {
                "start": "00:18:02,360",
                "end": "00:18:07,320",
                "text": "recommend getting the device because too"
            },
            {
                "start": "00:18:04,600",
                "end": "00:18:09,799",
                "text": "many of the products downsides outweigh"
            },
            {
                "start": "00:18:07,320",
                "end": "00:18:11,720",
                "text": "its highlights it's a device that feels"
            },
            {
                "start": "00:18:09,799",
                "end": "00:18:14,480",
                "text": "like something from the future but is"
            },
            {
                "start": "00:18:11,720",
                "end": "00:18:17,320",
                "text": "hampered by the present form factor"
            },
            {
                "start": "00:18:14,480",
                "end": "00:18:19,000",
                "text": "business model and extra features Apple"
            },
            {
                "start": "00:18:17,320",
                "end": "00:18:21,440",
                "text": "decided to go"
            },
            {
                "start": "00:18:19,000",
                "end": "00:18:23,600",
                "text": "with if you want to learn even more"
            },
            {
                "start": "00:18:21,440",
                "end": "00:18:26,120",
                "text": "about the Vision Pro and how it compares"
            },
            {
                "start": "00:18:23,600",
                "end": "00:18:27,799",
                "text": "to the much cheaper meta Quest 3 as well"
            },
            {
                "start": "00:18:26,120",
                "end": "00:18:29,440",
                "text": "as my full six months later review of"
            },
            {
                "start": "00:18:27,799",
                "end": "00:18:31,720",
                "text": "The Meta quest Quest 3 you can get to"
            },
            {
                "start": "00:18:29,440",
                "end": "00:18:33,640",
                "text": "those videos by clicking here and to see"
            },
            {
                "start": "00:18:31,720",
                "end": "00:18:36,000",
                "text": "more of my Apple reviews you can get to"
            },
            {
                "start": "00:18:33,640",
                "end": "00:18:38,480",
                "text": "those by clicking the playlist here or"
            },
            {
                "start": "00:18:36,000",
                "end": "00:18:40,679",
                "text": "by simply following us at 6months"
            },
            {
                "start": "00:18:38,480",
                "end": "00:18:42,200",
                "text": "l.net if you like this video and found"
            },
            {
                "start": "00:18:40,679",
                "end": "00:18:44,159",
                "text": "it helpful make sure you hit that Thumbs"
            },
            {
                "start": "00:18:42,200",
                "end": "00:18:46,799",
                "text": "Up Button below and subscribe to the"
            },
            {
                "start": "00:18:44,159",
                "end": "00:18:51,480",
                "text": "channel for more for 6 months later I'm"
            },
            {
                "start": "00:18:46,799",
                "end": "00:18:51,480",
                "text": "Josh tedar thanks for watching"
            }
        ],
        "Introducing Apple Vision Pro.srt": [
            {
                "start": "00:00:00,530",
                "end": "00:00:07,480",
                "text": "[Music]"
            },
            {
                "start": "00:00:08,800",
                "end": "00:00:14,440",
                "text": "introducing Apple Vision"
            },
            {
                "start": "00:00:11,160",
                "end": "00:00:17,670",
                "text": "Pro the era of spatial"
            },
            {
                "start": "00:00:14,440",
                "end": "00:00:21,800",
                "text": "Computing is"
            },
            {
                "start": "00:00:17,670",
                "end": "00:00:25,000",
                "text": "[Music]"
            },
            {
                "start": "00:00:21,800",
                "end": "00:00:28,039",
                "text": "here when you put on Apple Vision Pro"
            },
            {
                "start": "00:00:25,000",
                "end": "00:00:30,320",
                "text": "you see your world and everything in it"
            },
            {
                "start": "00:00:28,039",
                "end": "00:00:33,280",
                "text": "your favorite apps live right in front"
            },
            {
                "start": "00:00:30,320",
                "end": "00:00:37,239",
                "text": "of you but now they're in your"
            },
            {
                "start": "00:00:33,280",
                "end": "00:00:39,920",
                "text": "space this is Vision OS Apple's first"
            },
            {
                "start": "00:00:37,239",
                "end": "00:00:43,520",
                "text": "ever spatial operating"
            },
            {
                "start": "00:00:39,920",
                "end": "00:00:46,640",
                "text": "system it's familiar yet"
            },
            {
                "start": "00:00:43,520",
                "end": "00:00:50,559",
                "text": "groundbreaking you navigate with your"
            },
            {
                "start": "00:00:46,640",
                "end": "00:00:55,640",
                "text": "eyes simply tap to select flick to"
            },
            {
                "start": "00:00:50,559",
                "end": "00:00:55,640",
                "text": "scroll s and use your voice to"
            },
            {
                "start": "00:00:55,760",
                "end": "00:01:00,840",
                "text": "dictate it's like"
            },
            {
                "start": "00:00:58,519",
                "end": "00:01:03,280",
                "text": "magic apps"
            },
            {
                "start": "00:01:00,840",
                "end": "00:01:06,680",
                "text": "Dimension react to"
            },
            {
                "start": "00:01:03,280",
                "end": "00:01:08,840",
                "text": "light and cast"
            },
            {
                "start": "00:01:06,680",
                "end": "00:01:11,280",
                "text": "Shadows even though these spatial"
            },
            {
                "start": "00:01:08,840",
                "end": "00:01:14,759",
                "text": "experiences are happening inside Vision"
            },
            {
                "start": "00:01:11,280",
                "end": "00:01:17,520",
                "text": "Pro it looks sounds and feels like they"
            },
            {
                "start": "00:01:14,759",
                "end": "00:01:17,520",
                "text": "are physically"
            },
            {
                "start": "00:01:17,759",
                "end": "00:01:23,320",
                "text": "there foundational to Apple Vision Pro"
            },
            {
                "start": "00:01:20,840",
                "end": "00:01:26,079",
                "text": "is that you're not isolated from other"
            },
            {
                "start": "00:01:23,320",
                "end": "00:01:30,240",
                "text": "people when someone else is in the room"
            },
            {
                "start": "00:01:26,079",
                "end": "00:01:32,840",
                "text": "you can see them and they can see you to"
            },
            {
                "start": "00:01:30,240",
                "end": "00:01:34,799",
                "text": "talk to me about sushi sushi all right"
            },
            {
                "start": "00:01:32,840",
                "end": "00:01:37,840",
                "text": "see you take"
            },
            {
                "start": "00:01:34,799",
                "end": "00:01:40,920",
                "text": "care because you're not limited by a"
            },
            {
                "start": "00:01:37,840",
                "end": "00:01:45,399",
                "text": "display apps live in your"
            },
            {
                "start": "00:01:40,920",
                "end": "00:01:50,360",
                "text": "space your photos can be life-size or"
            },
            {
                "start": "00:01:45,399",
                "end": "00:01:53,759",
                "text": "any size so your living room becomes a"
            },
            {
                "start": "00:01:50,360",
                "end": "00:01:57,160",
                "text": "gallery and panoramas wrap around you as"
            },
            {
                "start": "00:01:53,759",
                "end": "00:01:58,840",
                "text": "if you're right where you took"
            },
            {
                "start": "00:01:57,160",
                "end": "00:02:02,119",
                "text": "[Music]"
            },
            {
                "start": "00:01:58,840",
                "end": "00:02:03,680",
                "text": "them Apple Vision Pro is Apple's first"
            },
            {
                "start": "00:02:02,119",
                "end": "00:02:06,920",
                "text": "ever 3D"
            },
            {
                "start": "00:02:03,680",
                "end": "00:02:10,280",
                "text": "camera now you can capture photos and"
            },
            {
                "start": "00:02:06,920",
                "end": "00:02:13,720",
                "text": "videos with remarkable depth and relive"
            },
            {
                "start": "00:02:10,280",
                "end": "00:02:15,140",
                "text": "a memory as if you're right back in the"
            },
            {
                "start": "00:02:13,720",
                "end": "00:02:17,280",
                "text": "exact"
            },
            {
                "start": "00:02:15,140",
                "end": "00:02:20,879",
                "text": "[Music]"
            },
            {
                "start": "00:02:17,280",
                "end": "00:02:20,879",
                "text": "moment hey"
            },
            {
                "start": "00:02:21,519",
                "end": "00:02:28,360",
                "text": "Dad experiences on Vision Pro can also"
            },
            {
                "start": "00:02:25,120",
                "end": "00:02:31,720",
                "text": "expand in three dimensions filling the"
            },
            {
                "start": "00:02:28,360",
                "end": "00:02:34,599",
                "text": "entirety of your space"
            },
            {
                "start": "00:02:31,720",
                "end": "00:02:37,300",
                "text": "like in the mindfulness app where you"
            },
            {
                "start": "00:02:34,599",
                "end": "00:02:40,479",
                "text": "can create a moment of"
            },
            {
                "start": "00:02:37,300",
                "end": "00:02:40,479",
                "text": "[Music]"
            },
            {
                "start": "00:02:44,000",
                "end": "00:02:49,040",
                "text": "calm Apple Vision Pro brings the scale"
            },
            {
                "start": "00:02:47,040",
                "end": "00:02:51,319",
                "text": "and wonder of a movie theater to"
            },
            {
                "start": "00:02:49,040",
                "end": "00:02:53,440",
                "text": "whatever space you're in it"
            },
            {
                "start": "00:02:51,319",
                "end": "00:02:55,480",
                "text": "automatically darkens and casts a"
            },
            {
                "start": "00:02:53,440",
                "end": "00:02:58,159",
                "text": "beautiful glow into the"
            },
            {
                "start": "00:02:55,480",
                "end": "00:03:01,840",
                "text": "room and you can make the screen as big"
            },
            {
                "start": "00:02:58,159",
                "end": "00:03:03,680",
                "text": "as you want and spatial audio surrounds"
            },
            {
                "start": "00:03:01,840",
                "end": "00:03:06,200",
                "text": "you and makes you feel like you're a"
            },
            {
                "start": "00:03:03,680",
                "end": "00:03:06,200",
                "text": "part of the"
            },
            {
                "start": "00:03:06,840",
                "end": "00:03:11,000",
                "text": "action and for an extraordinary"
            },
            {
                "start": "00:03:09,400",
                "end": "00:03:13,560",
                "text": "cinematic"
            },
            {
                "start": "00:03:11,000",
                "end": "00:03:16,239",
                "text": "experience you can bring in a beautiful"
            },
            {
                "start": "00:03:13,560",
                "end": "00:03:17,830",
                "text": "environment and make your screen feel"
            },
            {
                "start": "00:03:16,239",
                "end": "00:03:21,440",
                "text": "100 ft"
            },
            {
                "start": "00:03:17,830",
                "end": "00:03:24,640",
                "text": "[Music]"
            },
            {
                "start": "00:03:21,440",
                "end": "00:03:26,760",
                "text": "wide now here to start Vision Pro is a"
            },
            {
                "start": "00:03:24,640",
                "end": "00:03:29,239",
                "text": "wonderful way to play your favorite"
            },
            {
                "start": "00:03:26,760",
                "end": "00:03:30,439",
                "text": "games Curry against just connect your"
            },
            {
                "start": "00:03:29,239",
                "end": "00:03:32,720",
                "text": "controller"
            },
            {
                "start": "00:03:30,439",
                "end": "00:03:33,970",
                "text": "and play on a massive screen with"
            },
            {
                "start": "00:03:32,720",
                "end": "00:03:38,159",
                "text": "Incredible"
            },
            {
                "start": "00:03:33,970",
                "end": "00:03:40,920",
                "text": "[Applause]"
            },
            {
                "start": "00:03:38,159",
                "end": "00:03:43,519",
                "text": "audio with apple Vision Pro you can"
            },
            {
                "start": "00:03:40,920",
                "end": "00:03:45,080",
                "text": "create the perfect workspace no matter"
            },
            {
                "start": "00:03:43,519",
                "end": "00:03:48,640",
                "text": "where you"
            },
            {
                "start": "00:03:45,080",
                "end": "00:03:52,560",
                "text": "are the web comes to life at Fantastic"
            },
            {
                "start": "00:03:48,640",
                "end": "00:03:57,200",
                "text": "scale text is crisp and easy to"
            },
            {
                "start": "00:03:52,560",
                "end": "00:03:57,200",
                "text": "read browsing the internet feels"
            },
            {
                "start": "00:03:57,959",
                "end": "00:04:04,680",
                "text": "new and Safari expands so you can see"
            },
            {
                "start": "00:04:01,879",
                "end": "00:04:04,680",
                "text": "all your open"
            },
            {
                "start": "00:04:05,160",
                "end": "00:04:11,640",
                "text": "[Music]"
            },
            {
                "start": "00:04:08,760",
                "end": "00:04:14,040",
                "text": "tabs your favorite apps from Apple and"
            },
            {
                "start": "00:04:11,640",
                "end": "00:04:17,000",
                "text": "the App Store are"
            },
            {
                "start": "00:04:14,040",
                "end": "00:04:21,040",
                "text": "there you can arrange them however you"
            },
            {
                "start": "00:04:17,000",
                "end": "00:04:24,639",
                "text": "like and work seamlessly across"
            },
            {
                "start": "00:04:21,040",
                "end": "00:04:26,680",
                "text": "them hi hey hi did you receive the deck"
            },
            {
                "start": "00:04:24,639",
                "end": "00:04:29,400",
                "text": "yeah I'm looking at it now oh great you"
            },
            {
                "start": "00:04:26,680",
                "end": "00:04:32,759",
                "text": "got so what did you think FaceTime looks"
            },
            {
                "start": "00:04:29,400",
                "end": "00:04:35,560",
                "text": "and sounds amazing in apple Vision Pro"
            },
            {
                "start": "00:04:32,759",
                "end": "00:04:37,800",
                "text": "youu people life siize and with spatial"
            },
            {
                "start": "00:04:35,560",
                "end": "00:04:40,720",
                "text": "audio you hear them as if they're right"
            },
            {
                "start": "00:04:37,800",
                "end": "00:04:43,400",
                "text": "in front of you so conversation is more"
            },
            {
                "start": "00:04:40,720",
                "end": "00:04:45,520",
                "text": "natural and collaborating becomes even"
            },
            {
                "start": "00:04:43,400",
                "end": "00:04:49,360",
                "text": "easier and because you see the world"
            },
            {
                "start": "00:04:45,520",
                "end": "00:04:52,280",
                "text": "around you you can glance at a"
            },
            {
                "start": "00:04:49,360",
                "end": "00:04:56,639",
                "text": "notification and even connect your Mac"
            },
            {
                "start": "00:04:52,280",
                "end": "00:05:01,639",
                "text": "simply by looking at it turning a 13-in"
            },
            {
                "start": "00:04:56,639",
                "end": "00:05:01,639",
                "text": "screen into a giant display"
            },
            {
                "start": "00:05:09,120",
                "end": "00:05:14,400",
                "text": "in apple Vision Pro you can also"
            },
            {
                "start": "00:05:11,280",
                "end": "00:05:17,039",
                "text": "transform your space with environments"
            },
            {
                "start": "00:05:14,400",
                "end": "00:05:20,800",
                "text": "like on a plane you can now watch a"
            },
            {
                "start": "00:05:17,039",
                "end": "00:05:23,840",
                "text": "movie on a huge screen in a stunning"
            },
            {
                "start": "00:05:20,800",
                "end": "00:05:27,540",
                "text": "location and you control just how"
            },
            {
                "start": "00:05:23,840",
                "end": "00:05:33,880",
                "text": "immersed you want to be"
            },
            {
                "start": "00:05:27,540",
                "end": "00:05:36,280",
                "text": "[Music]"
            },
            {
                "start": "00:05:33,880",
                "end": "00:05:39,000",
                "text": "to make all these digital experiences"
            },
            {
                "start": "00:05:36,280",
                "end": "00:05:41,800",
                "text": "feel real in your space takes an"
            },
            {
                "start": "00:05:39,000",
                "end": "00:05:44,800",
                "text": "extraordinary amount of Technology yet"
            },
            {
                "start": "00:05:41,800",
                "end": "00:05:47,720",
                "text": "Apple Vision Pro is remarkably Compact"
            },
            {
                "start": "00:05:44,800",
                "end": "00:05:49,840",
                "text": "and beautiful a single piece of"
            },
            {
                "start": "00:05:47,720",
                "end": "00:05:52,560",
                "text": "three-dimensionally formed laminated"
            },
            {
                "start": "00:05:49,840",
                "end": "00:05:55,560",
                "text": "glass acts as a lens through which the"
            },
            {
                "start": "00:05:52,560",
                "end": "00:05:57,840",
                "text": "cameras and sensors view the world it"
            },
            {
                "start": "00:05:55,560",
                "end": "00:06:00,880",
                "text": "flows seamlessly into a lightweight"
            },
            {
                "start": "00:05:57,840",
                "end": "00:06:03,880",
                "text": "aluminum alloy frame that gently curves"
            },
            {
                "start": "00:06:00,880",
                "end": "00:06:06,960",
                "text": "to wrap around your face and we designed"
            },
            {
                "start": "00:06:03,880",
                "end": "00:06:08,319",
                "text": "a modular system so you can find the"
            },
            {
                "start": "00:06:06,960",
                "end": "00:06:11,360",
                "text": "right"
            },
            {
                "start": "00:06:08,319",
                "end": "00:06:15,160",
                "text": "fit the light seal keeps stray light"
            },
            {
                "start": "00:06:11,360",
                "end": "00:06:18,680",
                "text": "from your eyes and a soft frame gently"
            },
            {
                "start": "00:06:15,160",
                "end": "00:06:22,080",
                "text": "flexes and conforms to your unique"
            },
            {
                "start": "00:06:18,680",
                "end": "00:06:26,680",
                "text": "features the headband is 3D knitted to"
            },
            {
                "start": "00:06:22,080",
                "end": "00:06:29,639",
                "text": "provide cushioning breathability and"
            },
            {
                "start": "00:06:26,680",
                "end": "00:06:32,520",
                "text": "stretch and a high performance battery"
            },
            {
                "start": "00:06:29,639",
                "end": "00:06:35,800",
                "text": "reduces weight to a minimum and slips"
            },
            {
                "start": "00:06:32,520",
                "end": "00:06:35,800",
                "text": "easily into your"
            },
            {
                "start": "00:06:36,880",
                "end": "00:06:42,360",
                "text": "pocket because you wear Apple Vision Pro"
            },
            {
                "start": "00:06:39,960",
                "end": "00:06:44,440",
                "text": "and your eyes are covered we engineered"
            },
            {
                "start": "00:06:42,360",
                "end": "00:06:46,800",
                "text": "A system that uses Advanced machine"
            },
            {
                "start": "00:06:44,440",
                "end": "00:06:49,440",
                "text": "learning to represent you realistically"
            },
            {
                "start": "00:06:46,800",
                "end": "00:06:51,759",
                "text": "when you're in FaceTime your persona"
            },
            {
                "start": "00:06:49,440",
                "end": "00:06:54,120",
                "text": "dynamically reflects your face and head"
            },
            {
                "start": "00:06:51,759",
                "end": "00:06:57,479",
                "text": "movements well so when you're"
            },
            {
                "start": "00:06:54,120",
                "end": "00:07:00,960",
                "text": "chatting people see your eyes hands and"
            },
            {
                "start": "00:06:57,479",
                "end": "00:07:00,960",
                "text": "true expressions"
            },
            {
                "start": "00:07:02,319",
                "end": "00:07:06,879",
                "text": "to convincingly Place content in your"
            },
            {
                "start": "00:07:04,560",
                "end": "00:07:08,960",
                "text": "space took thousands of groundbreaking"
            },
            {
                "start": "00:07:06,879",
                "end": "00:07:11,120",
                "text": "Innovations and custom"
            },
            {
                "start": "00:07:08,960",
                "end": "00:07:13,599",
                "text": "Technologies since your eyes see the"
            },
            {
                "start": "00:07:11,120",
                "end": "00:07:16,160",
                "text": "world with Incredible resolution we"
            },
            {
                "start": "00:07:13,599",
                "end": "00:07:18,759",
                "text": "built a micro OLED display system that"
            },
            {
                "start": "00:07:16,160",
                "end": "00:07:22,400",
                "text": "fits 64 pixels in the same amount of"
            },
            {
                "start": "00:07:18,759",
                "end": "00:07:25,759",
                "text": "space as a single iPhone pixel and packs"
            },
            {
                "start": "00:07:22,400",
                "end": "00:07:26,720",
                "text": "23 million into two panels the size of a"
            },
            {
                "start": "00:07:25,759",
                "end": "00:07:30,440",
                "text": "postage"
            },
            {
                "start": "00:07:26,720",
                "end": "00:07:34,800",
                "text": "stamp that's more than a 4K TV for each"
            },
            {
                "start": "00:07:30,440",
                "end": "00:07:37,720",
                "text": "eye giving you jaw-dropping lifelike"
            },
            {
                "start": "00:07:34,800",
                "end": "00:07:40,319",
                "text": "Clarity Apple Vision Pro also features"
            },
            {
                "start": "00:07:37,720",
                "end": "00:07:43,120",
                "text": "our most advanced spatial audio system"
            },
            {
                "start": "00:07:40,319",
                "end": "00:07:46,159",
                "text": "ever personalized sound is delivered"
            },
            {
                "start": "00:07:43,120",
                "end": "00:07:48,960",
                "text": "directionally to your ear and audio Ray"
            },
            {
                "start": "00:07:46,159",
                "end": "00:07:50,759",
                "text": "tracing uses sophisticated sensors to"
            },
            {
                "start": "00:07:48,960",
                "end": "00:07:53,000",
                "text": "understand the materials and objects in"
            },
            {
                "start": "00:07:50,759",
                "end": "00:07:55,319",
                "text": "your room so sound feels like it's"
            },
            {
                "start": "00:07:53,000",
                "end": "00:07:58,759",
                "text": "coming from the world around"
            },
            {
                "start": "00:07:55,319",
                "end": "00:08:01,560",
                "text": "you 3D mapping provides a detailed"
            },
            {
                "start": "00:07:58,759",
                "end": "00:08:04,919",
                "text": "understanding of Walls Furniture and"
            },
            {
                "start": "00:08:01,560",
                "end": "00:08:08,879",
                "text": "even people so all experiences look"
            },
            {
                "start": "00:08:04,919",
                "end": "00:08:11,879",
                "text": "sound and feel like they are physically"
            },
            {
                "start": "00:08:08,879",
                "end": "00:08:14,720",
                "text": "there to power a spatial computer like"
            },
            {
                "start": "00:08:11,879",
                "end": "00:08:18,319",
                "text": "apple Vision Pro required an Innovative"
            },
            {
                "start": "00:08:14,720",
                "end": "00:08:21,639",
                "text": "dual chip design M2 provides phenomenal"
            },
            {
                "start": "00:08:18,319",
                "end": "00:08:23,919",
                "text": "performance and a brand new chip R1"
            },
            {
                "start": "00:08:21,639",
                "end": "00:08:26,919",
                "text": "processes sensor data at incredible"
            },
            {
                "start": "00:08:23,919",
                "end": "00:08:30,080",
                "text": "speed virtually eliminating lag so"
            },
            {
                "start": "00:08:26,919",
                "end": "00:08:31,680",
                "text": "experiences take place in real time"
            },
            {
                "start": "00:08:30,080",
                "end": "00:08:35,880",
                "text": "right in front of your"
            },
            {
                "start": "00:08:31,680",
                "end": "00:08:38,760",
                "text": "eyes dely great inside a stunning new"
            },
            {
                "start": "00:08:35,880",
                "end": "00:08:42,800",
                "text": "way to use the apps we"
            },
            {
                "start": "00:08:38,760",
                "end": "00:08:46,200",
                "text": "love a powerful way to relive our"
            },
            {
                "start": "00:08:42,800",
                "end": "00:08:49,040",
                "text": "memories a profound new way to be"
            },
            {
                "start": "00:08:46,200",
                "end": "00:08:52,839",
                "text": "together thank you so much and a magical"
            },
            {
                "start": "00:08:49,040",
                "end": "00:08:55,040",
                "text": "way to be immersed in"
            },
            {
                "start": "00:08:52,839",
                "end": "00:08:57,240",
                "text": "entertainment the era of spatial"
            },
            {
                "start": "00:08:55,040",
                "end": "00:09:02,800",
                "text": "Computing is"
            },
            {
                "start": "00:08:57,240",
                "end": "00:09:02,800",
                "text": "here this is Apple Vision Pro"
            }
        ],
        "Using Apple Vision Pro\uff1a What It\u2019s Actually Like!.srt": [
            {
                "start": "00:00:00,107",
                "end": "00:00:00,940",
                "text": "(upbeat music)"
            },
            {
                "start": "00:00:00,940",
                "end": "00:00:03,450",
                "text": "- All right, so you've seen the unboxing."
            },
            {
                "start": "00:00:03,450",
                "end": "00:00:05,040",
                "text": "Now it's time for the breakdown."
            },
            {
                "start": "00:00:05,040",
                "end": "00:00:09,903",
                "text": "What is using the Apple Vision Pro actually like?"
            },
            {
                "start": "00:00:13,560",
                "end": "00:00:18,210",
                "text": "This is easily one of Apple's craziest, most radical,"
            },
            {
                "start": "00:00:18,210",
                "end": "00:00:20,970",
                "text": "possibly dystopian products of all time."
            },
            {
                "start": "00:00:20,970",
                "end": "00:00:23,370",
                "text": "And I have a lot of thoughts here,"
            },
            {
                "start": "00:00:23,370",
                "end": "00:00:25,440",
                "text": "like I've been using it for about a week now."
            },
            {
                "start": "00:00:25,440",
                "end": "00:00:26,700",
                "text": "There are some parts of this thing"
            },
            {
                "start": "00:00:26,700",
                "end": "00:00:28,500",
                "text": "that are absolutely incredible,"
            },
            {
                "start": "00:00:28,500",
                "end": "00:00:30,870",
                "text": "and some other parts that feel weird,"
            },
            {
                "start": "00:00:30,870",
                "end": "00:00:33,060",
                "text": "or borderline unfinished."
            },
            {
                "start": "00:00:33,060",
                "end": "00:00:34,920",
                "text": "There are all kinds of new technologies,"
            },
            {
                "start": "00:00:34,920",
                "end": "00:00:38,460",
                "text": "from a new operating system to infrared eye tracking"
            },
            {
                "start": "00:00:38,460",
                "end": "00:00:41,610",
                "text": "to virtually reconstructed versions of you."
            },
            {
                "start": "00:00:41,610",
                "end": "00:00:45,120",
                "text": "I feel like there are so many actually new things"
            },
            {
                "start": "00:00:45,120",
                "end": "00:00:47,190",
                "text": "that you have to understand in order to get a sense"
            },
            {
                "start": "00:00:47,190",
                "end": "00:00:49,800",
                "text": "of what this headset actually is and what it does."
            },
            {
                "start": "00:00:49,800",
                "end": "00:00:52,380",
                "text": "So I'm gonna break this down into two parts."
            },
            {
                "start": "00:00:52,380",
                "end": "00:00:56,010",
                "text": "This video is all about using the Vision Pro."
            },
            {
                "start": "00:00:56,010",
                "end": "00:00:57,720",
                "text": "It's everything I've learned from the past week"
            },
            {
                "start": "00:00:57,720",
                "end": "00:01:01,260",
                "text": "of wearing and getting used to this thing every single day."
            },
            {
                "start": "00:01:01,260",
                "end": "00:01:04,530",
                "text": "But I'm also working on a more wide ranging,"
            },
            {
                "start": "00:01:04,530",
                "end": "00:01:07,230",
                "text": "possibly more existential, review video."
            },
            {
                "start": "00:01:07,230",
                "end": "00:01:09,300",
                "text": "But let's just start with the more"
            },
            {
                "start": "00:01:09,300",
                "end": "00:01:11,490",
                "text": "hardware fundamentals, right?"
            },
            {
                "start": "00:01:11,490",
                "end": "00:01:14,790",
                "text": "Like what is this thing that I'm holding literally?"
            },
            {
                "start": "00:01:14,790",
                "end": "00:01:17,280",
                "text": "Apple Vision Pro at its core,"
            },
            {
                "start": "00:01:17,280",
                "end": "00:01:19,230",
                "text": "well, it is a VR headset."
            },
            {
                "start": "00:01:19,230",
                "end": "00:01:20,610",
                "text": "Now, Apple would never say that,"
            },
            {
                "start": "00:01:20,610",
                "end": "00:01:23,040",
                "text": "and they probably won't like that I'm saying that word."
            },
            {
                "start": "00:01:23,040",
                "end": "00:01:24,360",
                "text": "You know, I made an entire video"
            },
            {
                "start": "00:01:24,360",
                "end": "00:01:26,520",
                "text": "about why they refuse to use those words,"
            },
            {
                "start": "00:01:26,520",
                "end": "00:01:29,850",
                "text": "and they're calling it spatial computing instead."
            },
            {
                "start": "00:01:29,850",
                "end": "00:01:30,683",
                "text": "We'll get there."
            },
            {
                "start": "00:01:30,683",
                "end": "00:01:33,300",
                "text": "But the truth is it's a really, really, really high end"
            },
            {
                "start": "00:01:33,300",
                "end": "00:01:35,550",
                "text": "virtual reality headset."
            },
            {
                "start": "00:01:35,550",
                "end": "00:01:37,410",
                "text": "It's something we've seen before, right?"
            },
            {
                "start": "00:01:37,410",
                "end": "00:01:40,530",
                "text": "It's got displays and lenses and speakers"
            },
            {
                "start": "00:01:40,530",
                "end": "00:01:42,420",
                "text": "and fans and buttons."
            },
            {
                "start": "00:01:42,420",
                "end": "00:01:44,010",
                "text": "And this is a form factor."
            },
            {
                "start": "00:01:44,010",
                "end": "00:01:46,230",
                "text": "This is a thing that we have seen before,"
            },
            {
                "start": "00:01:46,230",
                "end": "00:01:48,120",
                "text": "but before I even turn this thing on,"
            },
            {
                "start": "00:01:48,120",
                "end": "00:01:49,860",
                "text": "there are clearly several things"
            },
            {
                "start": "00:01:49,860",
                "end": "00:01:51,960",
                "text": "that are a little different about this one."
            },
            {
                "start": "00:01:51,960",
                "end": "00:01:53,940",
                "text": "So first of all, it's made of metal."
            },
            {
                "start": "00:01:53,940",
                "end": "00:01:57,420",
                "text": "Lots of metal and glass here, which are high quality,"
            },
            {
                "start": "00:01:57,420",
                "end": "00:02:00,570",
                "text": "but heavy materials, relatively speaking."
            },
            {
                "start": "00:02:00,570",
                "end": "00:02:03,510",
                "text": "So there's this precisely machined aluminum frame"
            },
            {
                "start": "00:02:03,510",
                "end": "00:02:04,470",
                "text": "around the outside."
            },
            {
                "start": "00:02:04,470",
                "end": "00:02:07,260",
                "text": "And yes, those are intakes for fans at the bottom."
            },
            {
                "start": "00:02:07,260",
                "end": "00:02:09,660",
                "text": "And then vents for those fans at the top."
            },
            {
                "start": "00:02:09,660",
                "end": "00:02:11,340",
                "text": "On the right side, there's your digital crown"
            },
            {
                "start": "00:02:11,340",
                "end": "00:02:13,140",
                "text": "that can be pressed in or turned."
            },
            {
                "start": "00:02:13,140",
                "end": "00:02:16,320",
                "text": "And then on the other side is just a single larger button."
            },
            {
                "start": "00:02:16,320",
                "end": "00:02:18,780",
                "text": "So kind of basically the same two buttons as an Apple Watch."
            },
            {
                "start": "00:02:18,780",
                "end": "00:02:20,040",
                "text": "And then when you get a little further back"
            },
            {
                "start": "00:02:20,040",
                "end": "00:02:22,260",
                "text": "on this band here, these little pods"
            },
            {
                "start": "00:02:22,260",
                "end": "00:02:25,230",
                "text": "with downward facing grills, these are speakers"
            },
            {
                "start": "00:02:25,230",
                "end": "00:02:27,240",
                "text": "which are pointed straight at your ears,"
            },
            {
                "start": "00:02:27,240",
                "end": "00:02:28,830",
                "text": "and work surprisingly well."
            },
            {
                "start": "00:02:28,830",
                "end": "00:02:32,010",
                "text": "Though of course, it also means that people around you"
            },
            {
                "start": "00:02:32,010",
                "end": "00:02:34,170",
                "text": "can hear a little bit of what you're hearing."
            },
            {
                "start": "00:02:34,170",
                "end": "00:02:35,430",
                "text": "There's a little bit of bleed,"
            },
            {
                "start": "00:02:35,430",
                "end": "00:02:37,650",
                "text": "and I have a lot to say about spatial audio,"
            },
            {
                "start": "00:02:37,650",
                "end": "00:02:39,120",
                "text": "so stay tuned for that."
            },
            {
                "start": "00:02:39,120",
                "end": "00:02:41,430",
                "text": "But the main event is at the front."
            },
            {
                "start": "00:02:41,430",
                "end": "00:02:43,667",
                "text": "There is an enormous piece of glass,"
            },
            {
                "start": "00:02:43,667",
                "end": "00:02:47,160",
                "text": "which, yes, is very easy to fingerprint and smudge."
            },
            {
                "start": "00:02:47,160",
                "end": "00:02:49,140",
                "text": "And then behind that thing, there's this outward-facing"
            },
            {
                "start": "00:02:49,140",
                "end": "00:02:52,350",
                "text": "OLED display and a bunch of sensors all the way around,"
            },
            {
                "start": "00:02:52,350",
                "end": "00:02:54,780",
                "text": "outside facing sensors that go forward,"
            },
            {
                "start": "00:02:54,780",
                "end": "00:02:57,150",
                "text": "sideways, and straight down."
            },
            {
                "start": "00:02:57,150",
                "end": "00:02:59,580",
                "text": "And there's depth sensors, infrared illuminators,"
            },
            {
                "start": "00:02:59,580",
                "end": "00:03:03,180",
                "text": "lidar scanners, and just regular old RGB cameras,"
            },
            {
                "start": "00:03:03,180",
                "end": "00:03:05,580",
                "text": "all being processed by an M2 chip"
            },
            {
                "start": "00:03:05,580",
                "end": "00:03:07,740",
                "text": "and an R1 chip inside this thing."
            },
            {
                "start": "00:03:07,740",
                "end": "00:03:09,270",
                "text": "And then maybe the craziest part,"
            },
            {
                "start": "00:03:09,270",
                "end": "00:03:12,450",
                "text": "inside the headset, there are a bunch more sensors"
            },
            {
                "start": "00:03:12,450",
                "end": "00:03:15,990",
                "text": "facing your eyes, tracking your eyes in real time,"
            },
            {
                "start": "00:03:15,990",
                "end": "00:03:18,360",
                "text": "for all the eye control and everything that comes with that."
            },
            {
                "start": "00:03:18,360",
                "end": "00:03:22,350",
                "text": "And also then to display a representation of your eyes"
            },
            {
                "start": "00:03:22,350",
                "end": "00:03:24,870",
                "text": "on the outside of the headset."
            },
            {
                "start": "00:03:24,870",
                "end": "00:03:26,640",
                "text": "Kinda, we'll get there."
            },
            {
                "start": "00:03:26,640",
                "end": "00:03:28,530",
                "text": "But overall, when you put it all together,"
            },
            {
                "start": "00:03:28,530",
                "end": "00:03:32,190",
                "text": "you get a very well made, very high end,"
            },
            {
                "start": "00:03:32,190",
                "end": "00:03:36,150",
                "text": "but also pretty heavy computer to wear on your face."
            },
            {
                "start": "00:03:36,150",
                "end": "00:03:39,510",
                "text": "So officially, this headset with this solo knit band"
            },
            {
                "start": "00:03:39,510",
                "end": "00:03:43,410",
                "text": "when I weighed it, showed up as 638 grams,"
            },
            {
                "start": "00:03:43,410",
                "end": "00:03:45,480",
                "text": "which some of you on Twitter have already pointed out"
            },
            {
                "start": "00:03:45,480",
                "end": "00:03:49,500",
                "text": "is actually slightly less than the plastic Meta Quest Pro."
            },
            {
                "start": "00:03:49,500",
                "end": "00:03:52,380",
                "text": "But that Quest Pro also has a lot of battery"
            },
            {
                "start": "00:03:52,380",
                "end": "00:03:55,680",
                "text": "on the back of your head as a sort of a counterbalance,"
            },
            {
                "start": "00:03:55,680",
                "end": "00:03:58,770",
                "text": "so the weight distribution is very different."
            },
            {
                "start": "00:03:58,770",
                "end": "00:04:01,080",
                "text": "Also, the Quest Pro is not that comfortable anyway."
            },
            {
                "start": "00:04:01,080",
                "end": "00:04:04,680",
                "text": "But the point is this, for Apple, made the choice"
            },
            {
                "start": "00:04:04,680",
                "end": "00:04:09,000",
                "text": "of taking the battery off of the headset, which means okay,"
            },
            {
                "start": "00:04:09,000",
                "end": "00:04:10,380",
                "text": "now there's nothing on the back of your head,"
            },
            {
                "start": "00:04:10,380",
                "end": "00:04:12,540",
                "text": "so you can wear it and lean up against things,"
            },
            {
                "start": "00:04:12,540",
                "end": "00:04:14,220",
                "text": "and that might be an upside,"
            },
            {
                "start": "00:04:14,220",
                "end": "00:04:16,110",
                "text": "but that also now means you have to deal"
            },
            {
                "start": "00:04:16,110",
                "end": "00:04:19,290",
                "text": "with this cable all the time running up to your head,"
            },
            {
                "start": "00:04:19,290",
                "end": "00:04:22,380",
                "text": "and the fact that it's very front weighted now."
            },
            {
                "start": "00:04:22,380",
                "end": "00:04:24,360",
                "text": "All of the weight is on the front of your face."
            },
            {
                "start": "00:04:24,360",
                "end": "00:04:26,970",
                "text": "So this is the battery, as you saw in the unboxing."
            },
            {
                "start": "00:04:26,970",
                "end": "00:04:29,400",
                "text": "If you haven't already seen the unboxing, that just went up."
            },
            {
                "start": "00:04:29,400",
                "end": "00:04:30,420",
                "text": "I'll link it below the like button."
            },
            {
                "start": "00:04:30,420",
                "end": "00:04:32,940",
                "text": "But this battery is a surprisingly small"
            },
            {
                "start": "00:04:32,940",
                "end": "00:04:35,550",
                "text": "3,366 milliamp hours."
            },
            {
                "start": "00:04:35,550",
                "end": "00:04:38,580",
                "text": "I say surprisingly small because a normal battery bank"
            },
            {
                "start": "00:04:38,580",
                "end": "00:04:41,627",
                "text": "of this size, you might expect to be 10, 15,"
            },
            {
                "start": "00:04:41,627",
                "end": "00:04:43,110",
                "text": "20,000 milliamp hours."
            },
            {
                "start": "00:04:43,110",
                "end": "00:04:46,680",
                "text": "I suspect there's a lot of heat insulation happening here."
            },
            {
                "start": "00:04:46,680",
                "end": "00:04:49,740",
                "text": "But it comes with a non-removable four foot cable,"
            },
            {
                "start": "00:04:49,740",
                "end": "00:04:52,320",
                "text": "and a proprietary connector at the end of the cable"
            },
            {
                "start": "00:04:52,320",
                "end": "00:04:54,270",
                "text": "that will twist and lock to the headset."
            },
            {
                "start": "00:04:54,270",
                "end": "00:04:55,680",
                "text": "And so the lock is really solid."
            },
            {
                "start": "00:04:55,680",
                "end": "00:04:57,390",
                "text": "It makes sense that it's not just straight USB"
            },
            {
                "start": "00:04:57,390",
                "end": "00:04:58,980",
                "text": "that could get disconnected easily."
            },
            {
                "start": "00:04:58,980",
                "end": "00:05:01,290",
                "text": "Once you connect it, it starts glowing,"
            },
            {
                "start": "00:05:01,290",
                "end": "00:05:02,550",
                "text": "and then it starts booting up."
            },
            {
                "start": "00:05:02,550",
                "end": "00:05:04,830",
                "text": "And there's even a little Apple logo that displays"
            },
            {
                "start": "00:05:04,830",
                "end": "00:05:07,590",
                "text": "on the outside screen while it takes, you know,"
            },
            {
                "start": "00:05:07,590",
                "end": "00:05:09,030",
                "text": "a little under a minute to turn on."
            },
            {
                "start": "00:05:09,030",
                "end": "00:05:10,860",
                "text": "So there is no on or off button"
            },
            {
                "start": "00:05:10,860",
                "end": "00:05:12,570",
                "text": "or switch anywhere on this headset."
            },
            {
                "start": "00:05:12,570",
                "end": "00:05:14,670",
                "text": "Maybe kind of like AirPods Max or something like that."
            },
            {
                "start": "00:05:14,670",
                "end": "00:05:16,830",
                "text": "So if you ever take the headset off"
            },
            {
                "start": "00:05:16,830",
                "end": "00:05:19,380",
                "text": "and put it down, it will enter a standby mode"
            },
            {
                "start": "00:05:19,380",
                "end": "00:05:21,630",
                "text": "after some time, but it won't turn off."
            },
            {
                "start": "00:05:21,630",
                "end": "00:05:24,840",
                "text": "If you wanna turn it off, you literally have to twist"
            },
            {
                "start": "00:05:24,840",
                "end": "00:05:26,250",
                "text": "and unplug the cable."
            },
            {
                "start": "00:05:26,250",
                "end": "00:05:28,980",
                "text": "That's the only way to actually turn the headset off."
            },
            {
                "start": "00:05:28,980",
                "end": "00:05:31,530",
                "text": "Now famously already, the battery life"
            },
            {
                "start": "00:05:31,530",
                "end": "00:05:34,170",
                "text": "with this included battery, is not super long"
            },
            {
                "start": "00:05:34,170",
                "end": "00:05:35,460",
                "text": "on this headset."
            },
            {
                "start": "00:05:35,460",
                "end": "00:05:37,590",
                "text": "Two to four hours is actually realistic"
            },
            {
                "start": "00:05:37,590",
                "end": "00:05:41,130",
                "text": "for what you can expect for just like this built-in battery."
            },
            {
                "start": "00:05:41,130",
                "end": "00:05:42,540",
                "text": "But that's also kind of right in line"
            },
            {
                "start": "00:05:42,540",
                "end": "00:05:43,800",
                "text": "with a lot of other VR headsets."
            },
            {
                "start": "00:05:43,800",
                "end": "00:05:46,320",
                "text": "Battery life on VR headsets is not that great in general."
            },
            {
                "start": "00:05:46,320",
                "end": "00:05:48,602",
                "text": "If you do wanna use it longer, the only way to do that"
            },
            {
                "start": "00:05:48,602",
                "end": "00:05:51,510",
                "text": "is there's USBC port on the battery,"
            },
            {
                "start": "00:05:51,510",
                "end": "00:05:53,430",
                "text": "and you have to plug the battery in."
            },
            {
                "start": "00:05:53,430",
                "end": "00:05:55,170",
                "text": "So you could plug the battery into the wall"
            },
            {
                "start": "00:05:55,170",
                "end": "00:05:56,850",
                "text": "for infinite battery life,"
            },
            {
                "start": "00:05:56,850",
                "end": "00:05:58,560",
                "text": "or I guess you could plug it into like a,"
            },
            {
                "start": "00:05:58,560",
                "end": "00:06:01,530",
                "text": "you could daisy chain another battery into the other pocket"
            },
            {
                "start": "00:06:01,530",
                "end": "00:06:02,880",
                "text": "or something for even longer life."
            },
            {
                "start": "00:06:02,880",
                "end": "00:06:04,680",
                "text": "But yeah, two to four hours."
            },
            {
                "start": "00:06:04,680",
                "end": "00:06:05,910",
                "text": "Now at first it seemed weird to me"
            },
            {
                "start": "00:06:05,910",
                "end": "00:06:08,130",
                "text": "that the port is on the same side of the battery"
            },
            {
                "start": "00:06:08,130",
                "end": "00:06:09,420",
                "text": "as the non-removable cable,"
            },
            {
                "start": "00:06:09,420",
                "end": "00:06:11,730",
                "text": "but I think it's because they just want you to default"
            },
            {
                "start": "00:06:11,730",
                "end": "00:06:14,070",
                "text": "to putting this battery in your pocket,"
            },
            {
                "start": "00:06:14,070",
                "end": "00:06:15,330",
                "text": "probably in your back pocket."
            },
            {
                "start": "00:06:15,330",
                "end": "00:06:17,520",
                "text": "So even if it's plugged into the wall,"
            },
            {
                "start": "00:06:17,520",
                "end": "00:06:20,100",
                "text": "it can still be in your back pocket."
            },
            {
                "start": "00:06:20,100",
                "end": "00:06:22,200",
                "text": "You're just gonna want to get a longer USBC cable."
            },
            {
                "start": "00:06:22,200",
                "end": "00:06:26,550",
                "text": "So there are no controllers that come with this headset."
            },
            {
                "start": "00:06:26,550",
                "end": "00:06:28,170",
                "text": "Now it does support other input methods"
            },
            {
                "start": "00:06:28,170",
                "end": "00:06:31,140",
                "text": "that are like game controllers, and mouse, and keyboard,"
            },
            {
                "start": "00:06:31,140",
                "end": "00:06:32,880",
                "text": "and those can be incredibly useful,"
            },
            {
                "start": "00:06:32,880",
                "end": "00:06:35,670",
                "text": "but by default the primary input method"
            },
            {
                "start": "00:06:35,670",
                "end": "00:06:37,650",
                "text": "for everyone using the Vision Pro"
            },
            {
                "start": "00:06:37,650",
                "end": "00:06:40,230",
                "text": "is your eyes and your hands."
            },
            {
                "start": "00:06:40,230",
                "end": "00:06:42,420",
                "text": "So the first time you put on this headset,"
            },
            {
                "start": "00:06:42,420",
                "end": "00:06:45,090",
                "text": "it goes through this calibration process,"
            },
            {
                "start": "00:06:45,090",
                "end": "00:06:46,590",
                "text": "and it's pretty interesting."
            },
            {
                "start": "00:06:46,590",
                "end": "00:06:48,180",
                "text": "So the first time you ever put it on,"
            },
            {
                "start": "00:06:48,180",
                "end": "00:06:51,120",
                "text": "it first adjusts the distance between the lenses,"
            },
            {
                "start": "00:06:51,120",
                "end": "00:06:53,040",
                "text": "physically moving them inside the headset"
            },
            {
                "start": "00:06:53,040",
                "end": "00:06:55,020",
                "text": "to match the distance between your eyes."
            },
            {
                "start": "00:06:55,020",
                "end": "00:06:56,820",
                "text": "Then it does this sort of a hand scan"
            },
            {
                "start": "00:06:56,820",
                "end": "00:06:57,960",
                "text": "so it understands your hands."
            },
            {
                "start": "00:06:57,960",
                "end": "00:06:59,070",
                "text": "And then you go through this process"
            },
            {
                "start": "00:06:59,070",
                "end": "00:07:01,230",
                "text": "of basically looking at a bunch of dots"
            },
            {
                "start": "00:07:01,230",
                "end": "00:07:02,550",
                "text": "all the way around the screen,"
            },
            {
                "start": "00:07:02,550",
                "end": "00:07:05,190",
                "text": "and then tapping your fingers together to select them."
            },
            {
                "start": "00:07:05,190",
                "end": "00:07:07,740",
                "text": "Kind of feels like an eye test or something."
            },
            {
                "start": "00:07:07,740",
                "end": "00:07:08,573",
                "text": "And then you're in."
            },
            {
                "start": "00:07:08,573",
                "end": "00:07:09,510",
                "text": "So first thing you're gonna notice"
            },
            {
                "start": "00:07:09,510",
                "end": "00:07:11,880",
                "text": "is you can actually kind of put your hands anywhere"
            },
            {
                "start": "00:07:11,880",
                "end": "00:07:15,030",
                "text": "as long as the headset can see this,"
            },
            {
                "start": "00:07:15,030",
                "end": "00:07:16,890",
                "text": "just your fingers touching together."
            },
            {
                "start": "00:07:16,890",
                "end": "00:07:19,710",
                "text": "So there's a lot of pictures of people using a headset"
            },
            {
                "start": "00:07:19,710",
                "end": "00:07:21,090",
                "text": "with their fingers, like out in front of them,"
            },
            {
                "start": "00:07:21,090",
                "end": "00:07:22,170",
                "text": "pinching like that."
            },
            {
                "start": "00:07:22,170",
                "end": "00:07:23,610",
                "text": "But you actually don't have to do that."
            },
            {
                "start": "00:07:23,610",
                "end": "00:07:26,160",
                "text": "It's such a wide angle because of the sensors"
            },
            {
                "start": "00:07:26,160",
                "end": "00:07:28,590",
                "text": "facing forward and sideways and down."
            },
            {
                "start": "00:07:28,590",
                "end": "00:07:31,050",
                "text": "You can kind of just rest your hand anywhere,"
            },
            {
                "start": "00:07:31,050",
                "end": "00:07:32,670",
                "text": "in front of you, in your lap."
            },
            {
                "start": "00:07:32,670",
                "end": "00:07:33,930",
                "text": "As long as you pinch like that,"
            },
            {
                "start": "00:07:33,930",
                "end": "00:07:36,300",
                "text": "it can generally pick it up, which is impressive."
            },
            {
                "start": "00:07:36,300",
                "end": "00:07:37,770",
                "text": "So you're pinching to control anywhere"
            },
            {
                "start": "00:07:37,770",
                "end": "00:07:39,630",
                "text": "in that 180 degree bubble in front of you."
            },
            {
                "start": "00:07:39,630",
                "end": "00:07:42,600",
                "text": "And then the digital crown, you hit that once,"
            },
            {
                "start": "00:07:42,600",
                "end": "00:07:45,300",
                "text": "and the app drawer comes up, pretty simple."
            },
            {
                "start": "00:07:45,300",
                "end": "00:07:46,530",
                "text": "Doesn't seem that impressive."
            },
            {
                "start": "00:07:46,530",
                "end": "00:07:49,260",
                "text": "But this is actually a peek at the first really impressive"
            },
            {
                "start": "00:07:49,260",
                "end": "00:07:52,530",
                "text": "thing about this headset to me, which is it seems to have"
            },
            {
                "start": "00:07:52,530",
                "end": "00:07:56,010",
                "text": "incredible spatial positioning lock,"
            },
            {
                "start": "00:07:56,010",
                "end": "00:08:00,750",
                "text": "and like, it's really hard to have you appreciate this"
            },
            {
                "start": "00:08:00,750",
                "end": "00:08:01,920",
                "text": "through a YouTube video."
            },
            {
                "start": "00:08:01,920",
                "end": "00:08:03,510",
                "text": "Reviewing VR headsets is hard."
            },
            {
                "start": "00:08:03,510",
                "end": "00:08:05,160",
                "text": "But turn around in the room you're in,"
            },
            {
                "start": "00:08:05,160",
                "end": "00:08:08,760",
                "text": "and picture a wall or a window"
            },
            {
                "start": "00:08:08,760",
                "end": "00:08:13,760",
                "text": "just appearing locked in place in 3D space in your room,"
            },
            {
                "start": "00:08:13,980",
                "end": "00:08:15,510",
                "text": "and no matter how much you move your head,"
            },
            {
                "start": "00:08:15,510",
                "end": "00:08:18,000",
                "text": "or move around, it stays exactly kind of floating"
            },
            {
                "start": "00:08:18,000",
                "end": "00:08:18,840",
                "text": "where it's supposed to be."
            },
            {
                "start": "00:08:18,840",
                "end": "00:08:21,360",
                "text": "But when I say floating, I think you're picturing like a,"
            },
            {
                "start": "00:08:21,360",
                "end": "00:08:25,320",
                "text": "a soft float, but it's locked, and that's how it starts."
            },
            {
                "start": "00:08:25,320",
                "end": "00:08:29,220",
                "text": "So now you're in Apple's new Vision OS"
            },
            {
                "start": "00:08:29,220",
                "end": "00:08:33,630",
                "text": "I would describe this as kind of similar to iPad OS,"
            },
            {
                "start": "00:08:33,630",
                "end": "00:08:36,360",
                "text": "but way more glassy, and of course"
            },
            {
                "start": "00:08:36,360",
                "end": "00:08:38,970",
                "text": "with the extra dimension of 3D space."
            },
            {
                "start": "00:08:38,970",
                "end": "00:08:41,400",
                "text": "So hitting a digital crown will always get the app drawer"
            },
            {
                "start": "00:08:41,400",
                "end": "00:08:45,030",
                "text": "back in front of you, and then simply look at the icon"
            },
            {
                "start": "00:08:45,030",
                "end": "00:08:46,620",
                "text": "you want and pinch your fingers together,"
            },
            {
                "start": "00:08:46,620",
                "end": "00:08:48,660",
                "text": "to select it and open that app."
            },
            {
                "start": "00:08:48,660",
                "end": "00:08:50,940",
                "text": "Scrolling is basically as you'd expect,"
            },
            {
                "start": "00:08:50,940",
                "end": "00:08:53,130",
                "text": "you just kind of pinch and grab in the air,"
            },
            {
                "start": "00:08:53,130",
                "end": "00:08:55,410",
                "text": "and then pull as if it's on a string,"
            },
            {
                "start": "00:08:55,410",
                "end": "00:08:57,810",
                "text": "and physics let you pull things through the air."
            },
            {
                "start": "00:08:57,810",
                "end": "00:09:01,470",
                "text": "It's pretty intuitive, it's responsive, it's fluid."
            },
            {
                "start": "00:09:01,470",
                "end": "00:09:03,240",
                "text": "Sometimes it's kind of bouncy even."
            },
            {
                "start": "00:09:03,240",
                "end": "00:09:05,340",
                "text": "I would say the biggest adjustment"
            },
            {
                "start": "00:09:05,340",
                "end": "00:09:07,590",
                "text": "is only being able to control"
            },
            {
                "start": "00:09:07,590",
                "end": "00:09:09,690",
                "text": "exactly what you're looking at."
            },
            {
                "start": "00:09:09,690",
                "end": "00:09:10,890",
                "text": "And I don't think people realize"
            },
            {
                "start": "00:09:10,890",
                "end": "00:09:12,420",
                "text": "how often they're controlling things"
            },
            {
                "start": "00:09:12,420",
                "end": "00:09:14,910",
                "text": "that they're not exactly looking directly at"
            },
            {
                "start": "00:09:14,910",
                "end": "00:09:16,770",
                "text": "with other computers and other UIs."
            },
            {
                "start": "00:09:16,770",
                "end": "00:09:20,400",
                "text": "But with this, you can look at the button to select it,"
            },
            {
                "start": "00:09:20,400",
                "end": "00:09:22,110",
                "text": "and if you look at the next thing you're gonna do,"
            },
            {
                "start": "00:09:22,110",
                "end": "00:09:23,610",
                "text": "you're no longer controlling the button."
            },
            {
                "start": "00:09:23,610",
                "end": "00:09:25,470",
                "text": "You have to look exactly where you're trying"
            },
            {
                "start": "00:09:25,470",
                "end": "00:09:26,640",
                "text": "to interact with things."
            },
            {
                "start": "00:09:26,640",
                "end": "00:09:28,170",
                "text": "It takes a few extra brain cycles"
            },
            {
                "start": "00:09:28,170",
                "end": "00:09:30,450",
                "text": "to remember to always be looking"
            },
            {
                "start": "00:09:30,450",
                "end": "00:09:32,100",
                "text": "exactly at the thing you're controlling."
            },
            {
                "start": "00:09:32,100",
                "end": "00:09:34,980",
                "text": "So when you open a window of a Vision OS app,"
            },
            {
                "start": "00:09:34,980",
                "end": "00:09:37,290",
                "text": "like any one of the default Apple apps here,"
            },
            {
                "start": "00:09:37,290",
                "end": "00:09:39,600",
                "text": "it locks into place, it's floating there."
            },
            {
                "start": "00:09:39,600",
                "end": "00:09:41,700",
                "text": "It kind of looks, again, like an iPad app,"
            },
            {
                "start": "00:09:41,700",
                "end": "00:09:44,700",
                "text": "but very glassy, like this frosted glass around the UI"
            },
            {
                "start": "00:09:44,700",
                "end": "00:09:46,110",
                "text": "sort of lets you see through a little bit"
            },
            {
                "start": "00:09:46,110",
                "end": "00:09:47,160",
                "text": "to the color behind it."
            },
            {
                "start": "00:09:47,160",
                "end": "00:09:50,670",
                "text": "And it even sometimes casts a shadow on the ground"
            },
            {
                "start": "00:09:50,670",
                "end": "00:09:53,580",
                "text": "in the correct Z space, so it really solidifies"
            },
            {
                "start": "00:09:53,580",
                "end": "00:09:55,350",
                "text": "that it's floating in front of you."
            },
            {
                "start": "00:09:55,350",
                "end": "00:09:57,360",
                "text": "All this makes it feel like the window"
            },
            {
                "start": "00:09:57,360",
                "end": "00:09:59,070",
                "text": "is in the space around you."
            },
            {
                "start": "00:09:59,070",
                "end": "00:10:01,020",
                "text": "Then if you look at the bottom of the window,"
            },
            {
                "start": "00:10:01,020",
                "end": "00:10:03,900",
                "text": "you get a little bar, you can always just look at that bar"
            },
            {
                "start": "00:10:03,900",
                "end": "00:10:06,030",
                "text": "and pinch to drag it around."
            },
            {
                "start": "00:10:06,030",
                "end": "00:10:09,210",
                "text": "So drag it forward, backward, anywhere you want"
            },
            {
                "start": "00:10:09,210",
                "end": "00:10:11,850",
                "text": "in X, Y, and Z space, and then let go"
            },
            {
                "start": "00:10:11,850",
                "end": "00:10:13,500",
                "text": "and it just stays absolutely locked."
            },
            {
                "start": "00:10:13,500",
                "end": "00:10:16,350",
                "text": "And then you can look at either bottom corner to resize"
            },
            {
                "start": "00:10:16,350",
                "end": "00:10:18,000",
                "text": "to make it bigger or smaller."
            },
            {
                "start": "00:10:18,000",
                "end": "00:10:20,430",
                "text": "And then finally there's a little X at the bottom,"
            },
            {
                "start": "00:10:20,430",
                "end": "00:10:22,170",
                "text": "you select that, that closes it."
            },
            {
                "start": "00:10:22,170",
                "end": "00:10:25,470",
                "text": "So that is the basics of Vision OS,"
            },
            {
                "start": "00:10:25,470",
                "end": "00:10:26,850",
                "text": "and just using an app."
            },
            {
                "start": "00:10:26,850",
                "end": "00:10:29,430",
                "text": "Now this entire time, by default,"
            },
            {
                "start": "00:10:29,430",
                "end": "00:10:32,700",
                "text": "and almost any time they can, passthrough is on,"
            },
            {
                "start": "00:10:32,700",
                "end": "00:10:34,140",
                "text": "which means you have the headset on,"
            },
            {
                "start": "00:10:34,140",
                "end": "00:10:35,970",
                "text": "but you can see with the cameras"
            },
            {
                "start": "00:10:35,970",
                "end": "00:10:37,320",
                "text": "right through to everything around you."
            },
            {
                "start": "00:10:37,320",
                "end": "00:10:38,850",
                "text": "And I think this is where Apple really wants"
            },
            {
                "start": "00:10:38,850",
                "end": "00:10:42,150",
                "text": "to normalize the term spatial computing,"
            },
            {
                "start": "00:10:42,150",
                "end": "00:10:44,910",
                "text": "because it feels like augmented reality."
            },
            {
                "start": "00:10:44,910",
                "end": "00:10:47,580",
                "text": "It feels like you're always able to see the space"
            },
            {
                "start": "00:10:47,580",
                "end": "00:10:50,190",
                "text": "around you, but technically it's not actually AR,"
            },
            {
                "start": "00:10:50,190",
                "end": "00:10:53,400",
                "text": "because you are still looking at a reconstructed version"
            },
            {
                "start": "00:10:53,400",
                "end": "00:10:55,200",
                "text": "through a camera feed of the world around you"
            },
            {
                "start": "00:10:55,200",
                "end": "00:10:57,630",
                "text": "instead of the actual world around you."
            },
            {
                "start": "00:10:57,630",
                "end": "00:10:59,700",
                "text": "But maybe it's all just semantics."
            },
            {
                "start": "00:10:59,700",
                "end": "00:11:03,660",
                "text": "I will say, this is the best passthrough of any VR headset"
            },
            {
                "start": "00:11:03,660",
                "end": "00:11:05,730",
                "text": "I've ever used, and it's not even that close."
            },
            {
                "start": "00:11:05,730",
                "end": "00:11:09,450",
                "text": "Now again, it's so hard to get this through a YouTube video."
            },
            {
                "start": "00:11:09,450",
                "end": "00:11:11,160",
                "text": "It does have screen recording built in,"
            },
            {
                "start": "00:11:11,160",
                "end": "00:11:12,330",
                "text": "so I'm gonna try to use that."
            },
            {
                "start": "00:11:12,330",
                "end": "00:11:14,730",
                "text": "But imagine putting a headset on,"
            },
            {
                "start": "00:11:14,730",
                "end": "00:11:17,880",
                "text": "and not really feeling like you're looking at a screen"
            },
            {
                "start": "00:11:17,880",
                "end": "00:11:19,380",
                "text": "with the real world."
            },
            {
                "start": "00:11:19,380",
                "end": "00:11:20,670",
                "text": "Because of the pixel density,"
            },
            {
                "start": "00:11:20,670",
                "end": "00:11:22,620",
                "text": "because of the 90 hertz refresh rate,"
            },
            {
                "start": "00:11:22,620",
                "end": "00:11:25,170",
                "text": "and because of the impressive dynamic range of the cameras"
            },
            {
                "start": "00:11:25,170",
                "end": "00:11:27,390",
                "text": "and the correctly adjusting shutter speed,"
            },
            {
                "start": "00:11:27,390",
                "end": "00:11:29,040",
                "text": "you just almost don't,"
            },
            {
                "start": "00:11:29,040",
                "end": "00:11:31,140",
                "text": "you almost just feel like you're looking"
            },
            {
                "start": "00:11:31,140",
                "end": "00:11:32,850",
                "text": "at the real world, not through a headset."
            },
            {
                "start": "00:11:32,850",
                "end": "00:11:36,150",
                "text": "Also the passthrough is so close to real time"
            },
            {
                "start": "00:11:36,150",
                "end": "00:11:39,270",
                "text": "that I could legitimately interact with all kinds of things."
            },
            {
                "start": "00:11:39,270",
                "end": "00:11:41,670",
                "text": "I could catch items flying at me."
            },
            {
                "start": "00:11:41,670",
                "end": "00:11:43,620",
                "text": "I even tried playing ping pong."
            },
            {
                "start": "00:11:43,620",
                "end": "00:11:45,420",
                "text": "It was easy, no hesitation."
            },
            {
                "start": "00:11:45,420",
                "end": "00:11:48,360",
                "text": "So officially, the R1 chip is doing all the processing"
            },
            {
                "start": "00:11:48,360",
                "end": "00:11:50,340",
                "text": "of all this stuff and adjusting the shutter speed"
            },
            {
                "start": "00:11:50,340",
                "end": "00:11:51,480",
                "text": "for different lighting conditions"
            },
            {
                "start": "00:11:51,480",
                "end": "00:11:53,670",
                "text": "and always keeping passthrough latency"
            },
            {
                "start": "00:11:53,670",
                "end": "00:11:57,540",
                "text": "under 12 milliseconds, which is the lowest in the industry."
            },
            {
                "start": "00:11:57,540",
                "end": "00:12:01,410",
                "text": "But it's really combining that with how close to reality"
            },
            {
                "start": "00:12:01,410",
                "end": "00:12:03,780",
                "text": "the colors and brightness and everything are"
            },
            {
                "start": "00:12:03,780",
                "end": "00:12:06,150",
                "text": "that keeps it feeling kind of real."
            },
            {
                "start": "00:12:06,150",
                "end": "00:12:08,340",
                "text": "Basically, the only noticeable restriction"
            },
            {
                "start": "00:12:08,340",
                "end": "00:12:12,000",
                "text": "is super close up items and objects can get a bit blurry,"
            },
            {
                "start": "00:12:12,000",
                "end": "00:12:14,610",
                "text": "and then you can't quite make out really small"
            },
            {
                "start": "00:12:14,610",
                "end": "00:12:17,130",
                "text": "or fine texts, so you can't read an email"
            },
            {
                "start": "00:12:17,130",
                "end": "00:12:19,200",
                "text": "or a tiny text on your phone in your hand,"
            },
            {
                "start": "00:12:19,200",
                "end": "00:12:21,270",
                "text": "but you can absolutely text people,"
            },
            {
                "start": "00:12:21,270",
                "end": "00:12:23,730",
                "text": "or read your notifications, while keeping the headset on."
            },
            {
                "start": "00:12:23,730",
                "end": "00:12:25,050",
                "text": "If you've tried other VR headsets,"
            },
            {
                "start": "00:12:25,050",
                "end": "00:12:26,310",
                "text": "you know how impressive that is."
            },
            {
                "start": "00:12:26,310",
                "end": "00:12:29,460",
                "text": "It's just, it's really good with the tech"
            },
            {
                "start": "00:12:29,460",
                "end": "00:12:31,683",
                "text": "that exists now for VR headsets."
            },
            {
                "start": "00:12:32,730",
                "end": "00:12:35,010",
                "text": "But you can definitely still take the headset off"
            },
            {
                "start": "00:12:35,010",
                "end": "00:12:36,990",
                "text": "and be like, oh, it's way brighter in here"
            },
            {
                "start": "00:12:36,990",
                "end": "00:12:38,580",
                "text": "than I thought it was."
            },
            {
                "start": "00:12:38,580",
                "end": "00:12:40,800",
                "text": "Either way, that's all passthrough,"
            },
            {
                "start": "00:12:40,800",
                "end": "00:12:43,260",
                "text": "but if you ever wanna fully immerse yourself,"
            },
            {
                "start": "00:12:43,260",
                "end": "00:12:45,630",
                "text": "I mean it is a VR headset after all,"
            },
            {
                "start": "00:12:45,630",
                "end": "00:12:49,440",
                "text": "all you gotta do is rotate this digital crown clockwise,"
            },
            {
                "start": "00:12:49,440",
                "end": "00:12:51,360",
                "text": "just keep turning it, and it will slowly"
            },
            {
                "start": "00:12:51,360",
                "end": "00:12:55,380",
                "text": "dial your environment more and more into your field of view"
            },
            {
                "start": "00:12:55,380",
                "end": "00:12:57,990",
                "text": "until you dial it all the way up to fully surrounding you."
            },
            {
                "start": "00:12:57,990",
                "end": "00:13:00,210",
                "text": "So all of the windows you might have had open"
            },
            {
                "start": "00:13:00,210",
                "end": "00:13:01,740",
                "text": "will still stay stuck where they were,"
            },
            {
                "start": "00:13:01,740",
                "end": "00:13:06,150",
                "text": "but everything you're doing is just on the moon now."
            },
            {
                "start": "00:13:06,150",
                "end": "00:13:07,740",
                "text": "So yeah, there's a couple environments"
            },
            {
                "start": "00:13:07,740",
                "end": "00:13:09,150",
                "text": "Apple has built in here,"
            },
            {
                "start": "00:13:09,150",
                "end": "00:13:12,240",
                "text": "most of them relaxing scenic locations,"
            },
            {
                "start": "00:13:12,240",
                "end": "00:13:14,220",
                "text": "like in California somewhere,"
            },
            {
                "start": "00:13:14,220",
                "end": "00:13:16,230",
                "text": "or one really nice one is Mount Hood"
            },
            {
                "start": "00:13:16,230",
                "end": "00:13:17,760",
                "text": "with a little bit of rain falling."
            },
            {
                "start": "00:13:17,760",
                "end": "00:13:20,610",
                "text": "They're not quite photorealistic,"
            },
            {
                "start": "00:13:20,610",
                "end": "00:13:22,710",
                "text": "but they're just short of photorealistic,"
            },
            {
                "start": "00:13:22,710",
                "end": "00:13:26,010",
                "text": "like they're the most realistic digital environments"
            },
            {
                "start": "00:13:26,010",
                "end": "00:13:26,843",
                "text": "that I've seen."
            },
            {
                "start": "00:13:26,843",
                "end": "00:13:31,843",
                "text": "So then the last two big quirks of the UI, control center."
            },
            {
                "start": "00:13:32,250",
                "end": "00:13:33,780",
                "text": "So the only way to get to control center"
            },
            {
                "start": "00:13:33,780",
                "end": "00:13:36,180",
                "text": "is to look up, and you can't just look up,"
            },
            {
                "start": "00:13:36,180",
                "end": "00:13:38,040",
                "text": "but you have to physically turn your head up"
            },
            {
                "start": "00:13:38,040",
                "end": "00:13:39,660",
                "text": "and look at this arrow that appears above you."
            },
            {
                "start": "00:13:39,660",
                "end": "00:13:41,250",
                "text": "So once you see that, you select that"
            },
            {
                "start": "00:13:41,250",
                "end": "00:13:43,380",
                "text": "and then you get your control center for things like,"
            },
            {
                "start": "00:13:43,380",
                "end": "00:13:46,380",
                "text": "you know, battery life and notifications, focus modes,"
            },
            {
                "start": "00:13:46,380",
                "end": "00:13:49,200",
                "text": "and screen recording, and pairing to a Mac."
            },
            {
                "start": "00:13:49,200",
                "end": "00:13:52,470",
                "text": "But the other big quirk is text input."
            },
            {
                "start": "00:13:52,470",
                "end": "00:13:55,350",
                "text": "So you might be wondering how does text input work"
            },
            {
                "start": "00:13:55,350",
                "end": "00:13:58,170",
                "text": "with no physical controllers?"
            },
            {
                "start": "00:13:58,170",
                "end": "00:14:00,240",
                "text": "So there's basically three ways to do this."
            },
            {
                "start": "00:14:00,240",
                "end": "00:14:02,400",
                "text": "So let's say you are in Safari,"
            },
            {
                "start": "00:14:02,400",
                "end": "00:14:04,407",
                "text": "and you want to go to mkbhd.com."
            },
            {
                "start": "00:14:04,407",
                "end": "00:14:07,320",
                "text": "You really want one of those shiny new Chevron hoodies"
            },
            {
                "start": "00:14:07,320",
                "end": "00:14:08,430",
                "text": "for the rest of winter."
            },
            {
                "start": "00:14:08,430",
                "end": "00:14:09,660",
                "text": "Great, how do you do it?"
            },
            {
                "start": "00:14:09,660",
                "end": "00:14:12,780",
                "text": "So the first way is to literally hunt and peck"
            },
            {
                "start": "00:14:12,780",
                "end": "00:14:14,610",
                "text": "poking the keys on the keyboard"
            },
            {
                "start": "00:14:14,610",
                "end": "00:14:17,070",
                "text": "that appears in the air in front of you."
            },
            {
                "start": "00:14:17,070",
                "end": "00:14:20,550",
                "text": "So this one is tough, because it literally only reacts"
            },
            {
                "start": "00:14:20,550",
                "end": "00:14:22,650",
                "text": "to your pointer finger on each hand."
            },
            {
                "start": "00:14:22,650",
                "end": "00:14:24,060",
                "text": "So you actually can't type fast,"
            },
            {
                "start": "00:14:24,060",
                "end": "00:14:26,100",
                "text": "like with home row or anything like that."
            },
            {
                "start": "00:14:26,100",
                "end": "00:14:26,933",
                "text": "Not great."
            },
            {
                "start": "00:14:26,933",
                "end": "00:14:29,190",
                "text": "The second way, though, I think is actually kind of good."
            },
            {
                "start": "00:14:29,190",
                "end": "00:14:32,280",
                "text": "It's at least faster, which is looking at the key"
            },
            {
                "start": "00:14:32,280",
                "end": "00:14:35,370",
                "text": "you want to interact with, and then pinching to select it."
            },
            {
                "start": "00:14:35,370",
                "end": "00:14:38,160",
                "text": "So just looking around the keyboard like this,"
            },
            {
                "start": "00:14:38,160",
                "end": "00:14:39,060",
                "text": "and selecting the keys."
            },
            {
                "start": "00:14:39,060",
                "end": "00:14:41,220",
                "text": "And you might be surprised how fast you can type like this"
            },
            {
                "start": "00:14:41,220",
                "end": "00:14:43,920",
                "text": "if you actually know your way around a keyboard pretty well."
            },
            {
                "start": "00:14:43,920",
                "end": "00:14:47,070",
                "text": "I actually prefer this to poking the virtual keys"
            },
            {
                "start": "00:14:47,070",
                "end": "00:14:49,380",
                "text": "because I at least get a little bit of haptic feedback"
            },
            {
                "start": "00:14:49,380",
                "end": "00:14:51,510",
                "text": "from my own fingers tapping together."
            },
            {
                "start": "00:14:51,510",
                "end": "00:14:53,100",
                "text": "But then in Safari, the last way to do it"
            },
            {
                "start": "00:14:53,100",
                "end": "00:14:54,990",
                "text": "is literally to just look up at the microphone"
            },
            {
                "start": "00:14:54,990",
                "end": "00:14:56,910",
                "text": "and say the URL out loud."
            },
            {
                "start": "00:14:56,910",
                "end": "00:14:58,470",
                "text": "MKBHD.com."
            },
            {
                "start": "00:14:58,470",
                "end": "00:14:59,460",
                "text": "And then it just hears you"
            },
            {
                "start": "00:14:59,460",
                "end": "00:15:01,500",
                "text": "and goes to the site pretty quick,"
            },
            {
                "start": "00:15:01,500",
                "end": "00:15:04,800",
                "text": "if it's a URL that you can actually say out loud."
            },
            {
                "start": "00:15:04,800",
                "end": "00:15:09,450",
                "text": "So, what can you actually do with this thing?"
            },
            {
                "start": "00:15:09,450",
                "end": "00:15:12,780",
                "text": "Like now that we know what it is, it's the M2 chip,"
            },
            {
                "start": "00:15:12,780",
                "end": "00:15:15,600",
                "text": "a computer on your face with the displays"
            },
            {
                "start": "00:15:15,600",
                "end": "00:15:18,030",
                "text": "and the lenses inside, and all sorts of sensors everywhere."
            },
            {
                "start": "00:15:18,030",
                "end": "00:15:19,710",
                "text": "What can this thing actually do?"
            },
            {
                "start": "00:15:19,710",
                "end": "00:15:21,720",
                "text": "And I feel like the most common way to phrase that"
            },
            {
                "start": "00:15:21,720",
                "end": "00:15:23,640",
                "text": "is what is the killer app?"
            },
            {
                "start": "00:15:23,640",
                "end": "00:15:25,560",
                "text": "Because that's, we feel like we need some sort"
            },
            {
                "start": "00:15:25,560",
                "end": "00:15:29,940",
                "text": "of justification to spend three, $4,000 on this thing."
            },
            {
                "start": "00:15:29,940",
                "end": "00:15:33,600",
                "text": "Like applications made the iPhone what it is as we know it,"
            },
            {
                "start": "00:15:33,600",
                "end": "00:15:35,460",
                "text": "like apps made the iPad."
            },
            {
                "start": "00:15:35,460",
                "end": "00:15:38,733",
                "text": "So what is the app situation on the Vision Pro?"
            },
            {
                "start": "00:15:39,840",
                "end": "00:15:43,080",
                "text": "So there are two types of apps on the Vision Pro, actually."
            },
            {
                "start": "00:15:43,080",
                "end": "00:15:46,440",
                "text": "The first is apps that are built specifically"
            },
            {
                "start": "00:15:46,440",
                "end": "00:15:48,600",
                "text": "for the Vision Pro to take advantage"
            },
            {
                "start": "00:15:48,600",
                "end": "00:15:50,580",
                "text": "of its awesome experiences."
            },
            {
                "start": "00:15:50,580",
                "end": "00:15:52,920",
                "text": "And there are a few of those right now,"
            },
            {
                "start": "00:15:52,920",
                "end": "00:15:55,140",
                "text": "and then there are all the other apps,"
            },
            {
                "start": "00:15:55,140",
                "end": "00:15:57,750",
                "text": "which basically are iPhone and iPad apps"
            },
            {
                "start": "00:15:57,750",
                "end": "00:15:59,910",
                "text": "that happen to be compatible"
            },
            {
                "start": "00:15:59,910",
                "end": "00:16:02,673",
                "text": "because the developer didn't opt out."
            },
            {
                "start": "00:16:03,510",
                "end": "00:16:05,790",
                "text": "And the first kind is way cooler."
            },
            {
                "start": "00:16:05,790",
                "end": "00:16:08,250",
                "text": "So these are Apple's stock apps here"
            },
            {
                "start": "00:16:08,250",
                "end": "00:16:09,780",
                "text": "that come with the Vision Pro."
            },
            {
                "start": "00:16:09,780",
                "end": "00:16:13,620",
                "text": "And so these are all, of course, made just for Vision Pro."
            },
            {
                "start": "00:16:13,620",
                "end": "00:16:16,320",
                "text": "So they're gonna have stuff that takes full advantage"
            },
            {
                "start": "00:16:16,320",
                "end": "00:16:17,760",
                "text": "of what this thing is capable of."
            },
            {
                "start": "00:16:17,760",
                "end": "00:16:19,260",
                "text": "Apple Music is a pretty classic one,"
            },
            {
                "start": "00:16:19,260",
                "end": "00:16:20,910",
                "text": "like it has all the same functionality"
            },
            {
                "start": "00:16:20,910",
                "end": "00:16:22,230",
                "text": "of any other Apple Music app,"
            },
            {
                "start": "00:16:22,230",
                "end": "00:16:25,260",
                "text": "but in this super glassy frosted window,"
            },
            {
                "start": "00:16:25,260",
                "end": "00:16:27,720",
                "text": "and shows the colors of whatever's behind it."
            },
            {
                "start": "00:16:27,720",
                "end": "00:16:31,500",
                "text": "And you have the sort of sorting menu on the left hand side"
            },
            {
                "start": "00:16:31,500",
                "end": "00:16:32,700",
                "text": "instead of across the bottom."
            },
            {
                "start": "00:16:32,700",
                "end": "00:16:34,080",
                "text": "That's the basic layout."
            },
            {
                "start": "00:16:34,080",
                "end": "00:16:36,180",
                "text": "Same thing with the Notes app and the Settings app."
            },
            {
                "start": "00:16:36,180",
                "end": "00:16:39,210",
                "text": "Very glassy, almost looking like an iPad app in the air,"
            },
            {
                "start": "00:16:39,210",
                "end": "00:16:42,120",
                "text": "just rebuilt with this new material design."
            },
            {
                "start": "00:16:42,120",
                "end": "00:16:44,070",
                "text": "And then there's the media apps."
            },
            {
                "start": "00:16:44,070",
                "end": "00:16:48,090",
                "text": "So Apple TV and Disney+, they both come pre-installed,"
            },
            {
                "start": "00:16:48,090",
                "end": "00:16:50,760",
                "text": "which they have built entire environments"
            },
            {
                "start": "00:16:50,760",
                "end": "00:16:52,800",
                "text": "inside of them for watching media."
            },
            {
                "start": "00:16:52,800",
                "end": "00:16:55,500",
                "text": "And there's even a small collection of videos"
            },
            {
                "start": "00:16:55,500",
                "end": "00:16:57,270",
                "text": "on the Apple TV app that are shot"
            },
            {
                "start": "00:16:57,270",
                "end": "00:16:58,740",
                "text": "on a new proprietary format"
            },
            {
                "start": "00:16:58,740",
                "end": "00:17:00,300",
                "text": "specifically for Vision Pro."
            },
            {
                "start": "00:17:00,300",
                "end": "00:17:04,830",
                "text": "So it drops you into a space with a full 180 degree video,"
            },
            {
                "start": "00:17:04,830",
                "end": "00:17:07,110",
                "text": "and Alicia Keys walks right up to you"
            },
            {
                "start": "00:17:07,110",
                "end": "00:17:09,060",
                "text": "and starts singing right to your face."
            },
            {
                "start": "00:17:09,060",
                "end": "00:17:09,893",
                "text": "It's crazy."
            },
            {
                "start": "00:17:09,893",
                "end": "00:17:10,726",
                "text": "There's also the Photos app,"
            },
            {
                "start": "00:17:10,726",
                "end": "00:17:13,230",
                "text": "which will let you look at panoramic photos,"
            },
            {
                "start": "00:17:13,230",
                "end": "00:17:15,840",
                "text": "for example, in this fully immersive view."
            },
            {
                "start": "00:17:15,840",
                "end": "00:17:18,000",
                "text": "So you can blow them up to full screen,"
            },
            {
                "start": "00:17:18,000",
                "end": "00:17:19,950",
                "text": "and then it gives you a bit of a parallax effect"
            },
            {
                "start": "00:17:19,950",
                "end": "00:17:22,260",
                "text": "around the edges, so it feels like you're looking"
            },
            {
                "start": "00:17:22,260",
                "end": "00:17:25,620",
                "text": "into a window of your own photo and looking around."
            },
            {
                "start": "00:17:25,620",
                "end": "00:17:26,520",
                "text": "It's kind of incredible."
            },
            {
                "start": "00:17:26,520",
                "end": "00:17:28,140",
                "text": "And then there's also some other really fun"
            },
            {
                "start": "00:17:28,140",
                "end": "00:17:29,580",
                "text": "third party apps that I've tried"
            },
            {
                "start": "00:17:29,580",
                "end": "00:17:30,570",
                "text": "that were built ahead of time."
            },
            {
                "start": "00:17:30,570",
                "end": "00:17:32,280",
                "text": "So Sky Guide, this is a good one."
            },
            {
                "start": "00:17:32,280",
                "end": "00:17:35,220",
                "text": "You can look around a real representation of the sky"
            },
            {
                "start": "00:17:35,220",
                "end": "00:17:39,390",
                "text": "around you or any of the constellations would normally be,"
            },
            {
                "start": "00:17:39,390",
                "end": "00:17:42,090",
                "text": "you can look at it a little longer and it'll pop it out."
            },
            {
                "start": "00:17:42,090",
                "end": "00:17:43,920",
                "text": "You can pull it outta the sky"
            },
            {
                "start": "00:17:43,920",
                "end": "00:17:45,660",
                "text": "to get more information about it."
            },
            {
                "start": "00:17:45,660",
                "end": "00:17:47,130",
                "text": "It's a pretty great idea."
            },
            {
                "start": "00:17:47,130",
                "end": "00:17:49,050",
                "text": "There's another one called Jig Space,"
            },
            {
                "start": "00:17:49,050",
                "end": "00:17:50,640",
                "text": "which is, it's a sick app,"
            },
            {
                "start": "00:17:50,640",
                "end": "00:17:51,840",
                "text": "I don't know if I'd ever use it,"
            },
            {
                "start": "00:17:51,840",
                "end": "00:17:54,330",
                "text": "but basically it lets you load 3D models"
            },
            {
                "start": "00:17:54,330",
                "end": "00:17:57,000",
                "text": "into the space you're in and mess around with them,"
            },
            {
                "start": "00:17:57,000",
                "end": "00:17:59,730",
                "text": "take 'em apart, view them in actual size."
            },
            {
                "start": "00:17:59,730",
                "end": "00:18:01,770",
                "text": "And this really takes advantage of how good"
            },
            {
                "start": "00:18:01,770",
                "end": "00:18:03,540",
                "text": "the placement lock is on the Vision Pro."
            },
            {
                "start": "00:18:03,540",
                "end": "00:18:05,610",
                "text": "And you can walk around, and really gets you"
            },
            {
                "start": "00:18:05,610",
                "end": "00:18:07,920",
                "text": "a better understanding of the scale of things"
            },
            {
                "start": "00:18:07,920",
                "end": "00:18:10,410",
                "text": "that you don't get to see up close very often."
            },
            {
                "start": "00:18:10,410",
                "end": "00:18:12,420",
                "text": "And then Keynote is another funny one."
            },
            {
                "start": "00:18:12,420",
                "end": "00:18:15,780",
                "text": "So you can of course go through and edit a Keynote"
            },
            {
                "start": "00:18:15,780",
                "end": "00:18:17,340",
                "text": "just like normal if you want to,"
            },
            {
                "start": "00:18:17,340",
                "end": "00:18:20,280",
                "text": "but then they've built this whole environment"
            },
            {
                "start": "00:18:20,280",
                "end": "00:18:22,620",
                "text": "for practicing your presentation skills."
            },
            {
                "start": "00:18:22,620",
                "end": "00:18:24,510",
                "text": "So you press that and it says, oh, would you like to go"
            },
            {
                "start": "00:18:24,510",
                "end": "00:18:27,930",
                "text": "to a conference room, or the literal Steve Jobs Theater,"
            },
            {
                "start": "00:18:27,930",
                "end": "00:18:30,720",
                "text": "so you can rehearse talking to your audience"
            },
            {
                "start": "00:18:30,720",
                "end": "00:18:32,850",
                "text": "with your Keynote slides behind you."
            },
            {
                "start": "00:18:32,850",
                "end": "00:18:35,580",
                "text": "It is genuinely incredibly immersive."
            },
            {
                "start": "00:18:35,580",
                "end": "00:18:37,200",
                "text": "And there's already a bunch more apps like this"
            },
            {
                "start": "00:18:37,200",
                "end": "00:18:38,550",
                "text": "in the App Store already at launch"
            },
            {
                "start": "00:18:38,550",
                "end": "00:18:41,520",
                "text": "that are specifically built for Vision Pro."
            },
            {
                "start": "00:18:41,520",
                "end": "00:18:44,430",
                "text": "So they'll take advantage of its various strengths."
            },
            {
                "start": "00:18:44,430",
                "end": "00:18:47,883",
                "text": "Now, are any of these a killer app?"
            },
            {
                "start": "00:18:48,930",
                "end": "00:18:49,763",
                "text": "Not really."
            },
            {
                "start": "00:18:49,763",
                "end": "00:18:52,410",
                "text": "I mean I don't, if you're looking for any one of these"
            },
            {
                "start": "00:18:52,410",
                "end": "00:18:55,080",
                "text": "to be the reason why you spend like $4,000 on this headset,"
            },
            {
                "start": "00:18:55,080",
                "end": "00:18:57,390",
                "text": "I don't think we have that yet."
            },
            {
                "start": "00:18:57,390",
                "end": "00:19:00,570",
                "text": "But then at least there's all the other non-native,"
            },
            {
                "start": "00:19:00,570",
                "end": "00:19:03,390",
                "text": "but technically still compatible, apps"
            },
            {
                "start": "00:19:03,390",
                "end": "00:19:04,740",
                "text": "that are in the App Store."
            },
            {
                "start": "00:19:04,740",
                "end": "00:19:07,380",
                "text": "And these are gonna look just like iPhone and iPad apps."
            },
            {
                "start": "00:19:07,380",
                "end": "00:19:10,260",
                "text": "Actually, there's a pre-installed folder on the home screen"
            },
            {
                "start": "00:19:10,260",
                "end": "00:19:13,950",
                "text": "when you get this thing literally called Compatible Apps,"
            },
            {
                "start": "00:19:13,950",
                "end": "00:19:16,230",
                "text": "and there's a bunch of them from Apple here."
            },
            {
                "start": "00:19:16,230",
                "end": "00:19:17,970",
                "text": "They look exactly like iPad apps."
            },
            {
                "start": "00:19:17,970",
                "end": "00:19:20,490",
                "text": "I'm surprised actually that more of them aren't"
            },
            {
                "start": "00:19:20,490",
                "end": "00:19:23,010",
                "text": "fully built out to take advantage of Vision Pro,"
            },
            {
                "start": "00:19:23,010",
                "end": "00:19:26,400",
                "text": "but like, Apple Maps is just the iPad app."
            },
            {
                "start": "00:19:26,400",
                "end": "00:19:29,400",
                "text": "And so it would be cool if there were some fun"
            },
            {
                "start": "00:19:29,400",
                "end": "00:19:32,190",
                "text": "augmented reality overlay walking directions type stuff,"
            },
            {
                "start": "00:19:32,190",
                "end": "00:19:35,250",
                "text": "but nope, it's all the exact same functionality"
            },
            {
                "start": "00:19:35,250",
                "end": "00:19:37,350",
                "text": "that you would find if you opened this app on your iPad."
            },
            {
                "start": "00:19:37,350",
                "end": "00:19:38,550",
                "text": "And you can go to the App Store"
            },
            {
                "start": "00:19:38,550",
                "end": "00:19:40,140",
                "text": "and search a bunch of the names of apps"
            },
            {
                "start": "00:19:40,140",
                "end": "00:19:42,750",
                "text": "you already know and love, and find them by name"
            },
            {
                "start": "00:19:42,750",
                "end": "00:19:44,880",
                "text": "and grab them, and they'll work the exact same way."
            },
            {
                "start": "00:19:44,880",
                "end": "00:19:47,310",
                "text": "Crazily enough though, there are already"
            },
            {
                "start": "00:19:47,310",
                "end": "00:19:50,370",
                "text": "some notable exceptions."
            },
            {
                "start": "00:19:50,370",
                "end": "00:19:54,120",
                "text": "No Netflix app for the Vision Pro, no YouTube app"
            },
            {
                "start": "00:19:54,120",
                "end": "00:19:57,960",
                "text": "for the Vision Pro, no Spotify app for the Vision Pro."
            },
            {
                "start": "00:19:57,960",
                "end": "00:20:01,440",
                "text": "Apple has kind of a contentious relationship"
            },
            {
                "start": "00:20:01,440",
                "end": "00:20:02,730",
                "text": "with a lot of developers right now,"
            },
            {
                "start": "00:20:02,730",
                "end": "00:20:04,890",
                "text": "especially some of the bigger ones."
            },
            {
                "start": "00:20:04,890",
                "end": "00:20:08,730",
                "text": "And so some have made the active choice to opt out."
            },
            {
                "start": "00:20:08,730",
                "end": "00:20:10,770",
                "text": "They're like, we don't wanna be there."
            },
            {
                "start": "00:20:10,770",
                "end": "00:20:13,620",
                "text": "This won't be a big enough platform to matter to us"
            },
            {
                "start": "00:20:13,620",
                "end": "00:20:14,670",
                "text": "to justify the work."
            },
            {
                "start": "00:20:14,670",
                "end": "00:20:15,503",
                "text": "So they're not there."
            },
            {
                "start": "00:20:15,503",
                "end": "00:20:16,410",
                "text": "Now I totally get it,"
            },
            {
                "start": "00:20:16,410",
                "end": "00:20:18,420",
                "text": "but also now as a Vision Pro owner"
            },
            {
                "start": "00:20:18,420",
                "end": "00:20:19,920",
                "text": "and someone who's using it,"
            },
            {
                "start": "00:20:19,920",
                "end": "00:20:22,140",
                "text": "I'm like, oh, it's kind of a bummer."
            },
            {
                "start": "00:20:22,140",
                "end": "00:20:26,520",
                "text": "I really wanted to be able to watch a Netflix show offline,"
            },
            {
                "start": "00:20:26,520",
                "end": "00:20:29,610",
                "text": "downloaded it ahead of time, but you can't do that now."
            },
            {
                "start": "00:20:29,610",
                "end": "00:20:32,010",
                "text": "But at least, at least for now, for the record,"
            },
            {
                "start": "00:20:32,010",
                "end": "00:20:33,540",
                "text": "you can use the browser,"
            },
            {
                "start": "00:20:33,540",
                "end": "00:20:35,340",
                "text": "and anything that would work in the browser."
            },
            {
                "start": "00:20:35,340",
                "end": "00:20:36,420",
                "text": "So if you pull up Safari,"
            },
            {
                "start": "00:20:36,420",
                "end": "00:20:39,330",
                "text": "and you get a full screen 4K YouTube video going,"
            },
            {
                "start": "00:20:39,330",
                "end": "00:20:42,510",
                "text": "and locked in space, or even in an environment,"
            },
            {
                "start": "00:20:42,510",
                "end": "00:20:43,343",
                "text": "it looks great."
            },
            {
                "start": "00:20:43,343",
                "end": "00:20:44,400",
                "text": "It's razor sharp."
            },
            {
                "start": "00:20:44,400",
                "end": "00:20:47,010",
                "text": "Like, I could totally watch YouTube videos like this."
            },
            {
                "start": "00:20:47,010",
                "end": "00:20:49,740",
                "text": "But you will definitely be missing the features"
            },
            {
                "start": "00:20:49,740",
                "end": "00:20:52,410",
                "text": "of having the dedicated app, like offline video."
            },
            {
                "start": "00:20:52,410",
                "end": "00:20:56,760",
                "text": "Honestly to me, the killer app of the Vision Pro"
            },
            {
                "start": "00:20:56,760",
                "end": "00:21:00,990",
                "text": "isn't just an app, it's actually the ecosystem."
            },
            {
                "start": "00:21:00,990",
                "end": "00:21:02,220",
                "text": "And we knew this was coming,"
            },
            {
                "start": "00:21:02,220",
                "end": "00:21:05,880",
                "text": "but the second you log into a Vision Pro with your Apple ID,"
            },
            {
                "start": "00:21:05,880",
                "end": "00:21:08,400",
                "text": "immediately it starts pulling all the services,"
            },
            {
                "start": "00:21:08,400",
                "end": "00:21:09,780",
                "text": "and all the stuff that you're used to"
            },
            {
                "start": "00:21:09,780",
                "end": "00:21:12,360",
                "text": "from all the other Apple devices you already have."
            },
            {
                "start": "00:21:12,360",
                "end": "00:21:14,010",
                "text": "And I said this before the Vision Pro was announced,"
            },
            {
                "start": "00:21:14,010",
                "end": "00:21:16,020",
                "text": "I was like, this is the most obvious strategy for Apple"
            },
            {
                "start": "00:21:16,020",
                "end": "00:21:18,030",
                "text": "because there are lots of people out there"
            },
            {
                "start": "00:21:18,030",
                "end": "00:21:20,520",
                "text": "who have never considered buying a VR headset"
            },
            {
                "start": "00:21:20,520",
                "end": "00:21:22,770",
                "text": "that are considering only this one"
            },
            {
                "start": "00:21:22,770",
                "end": "00:21:24,150",
                "text": "because they have an iPhone,"
            },
            {
                "start": "00:21:24,150",
                "end": "00:21:26,760",
                "text": "and this is the one that works with the iPhone,"
            },
            {
                "start": "00:21:26,760",
                "end": "00:21:28,440",
                "text": "and none of the others are particularly close."
            },
            {
                "start": "00:21:28,440",
                "end": "00:21:30,420",
                "text": "So all of your iMessages are already here,"
            },
            {
                "start": "00:21:30,420",
                "end": "00:21:32,190",
                "text": "all of your photos are already here"
            },
            {
                "start": "00:21:32,190",
                "end": "00:21:33,930",
                "text": "and loaded up and backed up."
            },
            {
                "start": "00:21:33,930",
                "end": "00:21:36,210",
                "text": "All your Notes are already at your fingertips."
            },
            {
                "start": "00:21:36,210",
                "end": "00:21:37,710",
                "text": "You already saw the Keynote app."
            },
            {
                "start": "00:21:37,710",
                "end": "00:21:40,620",
                "text": "But okay, easily my favorite feature"
            },
            {
                "start": "00:21:40,620",
                "end": "00:21:42,570",
                "text": "is connecting to your Mac, right?"
            },
            {
                "start": "00:21:42,570",
                "end": "00:21:44,310",
                "text": "So anytime your Mac is in front of you"
            },
            {
                "start": "00:21:44,310",
                "end": "00:21:46,110",
                "text": "and it's turned on, hit that arrow"
            },
            {
                "start": "00:21:46,110",
                "end": "00:21:47,310",
                "text": "and then there's this little icon"
            },
            {
                "start": "00:21:47,310",
                "end": "00:21:50,250",
                "text": "to Become My Mac's Virtual Display."
            },
            {
                "start": "00:21:50,250",
                "end": "00:21:52,440",
                "text": "So I click that, and then pick my Mac,"
            },
            {
                "start": "00:21:52,440",
                "end": "00:21:54,720",
                "text": "and it pretty much instantly, it actually blacks out"
            },
            {
                "start": "00:21:54,720",
                "end": "00:21:58,260",
                "text": "the display of my Mac, and then turns that display"
            },
            {
                "start": "00:21:58,260",
                "end": "00:22:02,130",
                "text": "into a 4K window inside of the headset."
            },
            {
                "start": "00:22:02,130",
                "end": "00:22:05,220",
                "text": "So now my keyboard and trackpad still work,"
            },
            {
                "start": "00:22:05,220",
                "end": "00:22:06,420",
                "text": "even if it is a desktop."
            },
            {
                "start": "00:22:06,420",
                "end": "00:22:08,550",
                "text": "The keyboard and the trackpad still control everything,"
            },
            {
                "start": "00:22:08,550",
                "end": "00:22:11,310",
                "text": "and you can continue using it just like a normal computer,"
            },
            {
                "start": "00:22:11,310",
                "end": "00:22:14,280",
                "text": "but with the ability to make your new 4K monitor"
            },
            {
                "start": "00:22:14,280",
                "end": "00:22:18,630",
                "text": "as big or as small or close or far away as you want,"
            },
            {
                "start": "00:22:18,630",
                "end": "00:22:19,800",
                "text": "which is super sick."
            },
            {
                "start": "00:22:19,800",
                "end": "00:22:22,710",
                "text": "And then the bonus is you can still open up"
            },
            {
                "start": "00:22:22,710",
                "end": "00:22:27,360",
                "text": "and place other Vision Pro apps around your Mac computer."
            },
            {
                "start": "00:22:27,360",
                "end": "00:22:29,190",
                "text": "So like you can have your Mac in the middle here,"
            },
            {
                "start": "00:22:29,190",
                "end": "00:22:32,250",
                "text": "and maybe you're editing or doing some work on the Mac app,"
            },
            {
                "start": "00:22:32,250",
                "end": "00:22:35,490",
                "text": "and then you have a Safari window, or Messages,"
            },
            {
                "start": "00:22:35,490",
                "end": "00:22:38,490",
                "text": "or whatever else you want right next to it around it."
            },
            {
                "start": "00:22:38,490",
                "end": "00:22:41,370",
                "text": "And then your keyboard and trackpad can move"
            },
            {
                "start": "00:22:41,370",
                "end": "00:22:45,600",
                "text": "seamlessly between them all to control all of them."
            },
            {
                "start": "00:22:45,600",
                "end": "00:22:49,800",
                "text": "This, to me, as a Mac user, the ease of use for setup"
            },
            {
                "start": "00:22:49,800",
                "end": "00:22:51,360",
                "text": "to make this happen, this feels like"
            },
            {
                "start": "00:22:51,360",
                "end": "00:22:52,470",
                "text": "the biggest game changer,"
            },
            {
                "start": "00:22:52,470",
                "end": "00:22:55,650",
                "text": "like the most compelling futuristic feeling"
            },
            {
                "start": "00:22:55,650",
                "end": "00:22:57,330",
                "text": "use of this headset to me."
            },
            {
                "start": "00:22:57,330",
                "end": "00:22:58,920",
                "text": "Especially on a plane."
            },
            {
                "start": "00:22:58,920",
                "end": "00:23:00,450",
                "text": "Oh my god, I can't tell you how many times"
            },
            {
                "start": "00:23:00,450",
                "end": "00:23:02,130",
                "text": "I've had an awkward conversation because,"
            },
            {
                "start": "00:23:02,130",
                "end": "00:23:03,630",
                "text": "like, I'm editing a video on the plane,"
            },
            {
                "start": "00:23:03,630",
                "end": "00:23:06,000",
                "text": "the person next to me sees I'm editing a video of myself,"
            },
            {
                "start": "00:23:06,000",
                "end": "00:23:08,280",
                "text": "and it's kind of weird and hard to explain,"
            },
            {
                "start": "00:23:08,280",
                "end": "00:23:11,040",
                "text": "but I'm picturing putting the headset on,"
            },
            {
                "start": "00:23:11,040",
                "end": "00:23:12,510",
                "text": "the display blacks out,"
            },
            {
                "start": "00:23:12,510",
                "end": "00:23:14,370",
                "text": "but now I can do all the editing I want,"
            },
            {
                "start": "00:23:14,370",
                "end": "00:23:16,110",
                "text": "and I can make the screen as big as I want."
            },
            {
                "start": "00:23:16,110",
                "end": "00:23:17,790",
                "text": "So I've really enjoyed using that feature."
            },
            {
                "start": "00:23:17,790",
                "end": "00:23:19,590",
                "text": "Again, the biggest challenge, though,"
            },
            {
                "start": "00:23:19,590",
                "end": "00:23:23,190",
                "text": "is still remembering to look exactly at the thing"
            },
            {
                "start": "00:23:23,190",
                "end": "00:23:24,600",
                "text": "you want to control."
            },
            {
                "start": "00:23:24,600",
                "end": "00:23:27,810",
                "text": "So aside from typing on the real keyboard"
            },
            {
                "start": "00:23:27,810",
                "end": "00:23:29,940",
                "text": "on whatever window is open, if you want"
            },
            {
                "start": "00:23:29,940",
                "end": "00:23:33,630",
                "text": "to control something, you have to be looking at it."
            },
            {
                "start": "00:23:33,630",
                "end": "00:23:34,830",
                "text": "Again, it doesn't sound like a big deal,"
            },
            {
                "start": "00:23:34,830",
                "end": "00:23:37,050",
                "text": "but when you try it, you'll see what I mean."
            },
            {
                "start": "00:23:37,050",
                "end": "00:23:40,830",
                "text": "And then also, odd limitation, one monitor only."
            },
            {
                "start": "00:23:40,830",
                "end": "00:23:44,010",
                "text": "From the Mac, one virtual monitor only at a time."
            },
            {
                "start": "00:23:44,010",
                "end": "00:23:46,560",
                "text": "So if you usually run a dual display setup like I do"
            },
            {
                "start": "00:23:46,560",
                "end": "00:23:49,080",
                "text": "for Final Cut Pro, big preview on one side,"
            },
            {
                "start": "00:23:49,080",
                "end": "00:23:51,270",
                "text": "timeline on the other side, you can't do that."
            },
            {
                "start": "00:23:51,270",
                "end": "00:23:55,140",
                "text": "You have to use the big one monitor version of your setup."
            },
            {
                "start": "00:23:55,140",
                "end": "00:23:56,850",
                "text": "All right, so you might have realized"
            },
            {
                "start": "00:23:56,850",
                "end": "00:24:00,030",
                "text": "I've left one thing out this whole time."
            },
            {
                "start": "00:24:00,030",
                "end": "00:24:02,940",
                "text": "One thing, you could call it one more thing, sure."
            },
            {
                "start": "00:24:02,940",
                "end": "00:24:06,030",
                "text": "It's one more huge crazy thing,"
            },
            {
                "start": "00:24:06,030",
                "end": "00:24:09,240",
                "text": "but it's kind of the defining characteristic of this product"
            },
            {
                "start": "00:24:09,240",
                "end": "00:24:11,910",
                "text": "and that is Personas."
            },
            {
                "start": "00:24:11,910",
                "end": "00:24:15,870",
                "text": "So in all the advertising you've seen of Vision Pro,"
            },
            {
                "start": "00:24:15,870",
                "end": "00:24:19,200",
                "text": "there's these eyes on the outside of the headset"
            },
            {
                "start": "00:24:19,200",
                "end": "00:24:21,960",
                "text": "that looks like they're kind of in a passthrough,"
            },
            {
                "start": "00:24:21,960",
                "end": "00:24:24,960",
                "text": "like in a dark astronaut helmet type of thing."
            },
            {
                "start": "00:24:24,960",
                "end": "00:24:27,420",
                "text": "Easily the most memed, most unique aspect"
            },
            {
                "start": "00:24:27,420",
                "end": "00:24:28,590",
                "text": "of this headset, right?"
            },
            {
                "start": "00:24:28,590",
                "end": "00:24:31,050",
                "text": "It's the only headset with an outward display."
            },
            {
                "start": "00:24:31,050",
                "end": "00:24:34,380",
                "text": "And I mean it's very, very prominent in those videos,"
            },
            {
                "start": "00:24:34,380",
                "end": "00:24:36,990",
                "text": "but in real life, as you've started to see"
            },
            {
                "start": "00:24:36,990",
                "end": "00:24:40,770",
                "text": "from some of my footage, it is very different,"
            },
            {
                "start": "00:24:40,770",
                "end": "00:24:42,510",
                "text": "and I think I figured out why."
            },
            {
                "start": "00:24:42,510",
                "end": "00:24:45,270",
                "text": "So first of all, it's not actually see-through, right?"
            },
            {
                "start": "00:24:45,270",
                "end": "00:24:46,680",
                "text": "There's a whole bunch of computer"
            },
            {
                "start": "00:24:46,680",
                "end": "00:24:48,270",
                "text": "in between me and you right now."
            },
            {
                "start": "00:24:48,270",
                "end": "00:24:50,610",
                "text": "So the eyes aren't on the outside."
            },
            {
                "start": "00:24:50,610",
                "end": "00:24:53,160",
                "text": "It's a representation of my eyes"
            },
            {
                "start": "00:24:53,160",
                "end": "00:24:55,680",
                "text": "based on what all the sensors on the inside are seeing."
            },
            {
                "start": "00:24:55,680",
                "end": "00:24:57,150",
                "text": "It's reconstructing it on the outside."
            },
            {
                "start": "00:24:57,150",
                "end": "00:25:00,660",
                "text": "So those sensors are tracking at 90 frames per second,"
            },
            {
                "start": "00:25:00,660",
                "end": "00:25:03,300",
                "text": "and they give you optic ID, which is,"
            },
            {
                "start": "00:25:03,300",
                "end": "00:25:05,370",
                "text": "it's how you log into the headset and keep things secure."
            },
            {
                "start": "00:25:05,370",
                "end": "00:25:08,880",
                "text": "It's basically the same as face ID, or touch ID,"
            },
            {
                "start": "00:25:08,880",
                "end": "00:25:11,130",
                "text": "it's just looking at and identifying your eyes."
            },
            {
                "start": "00:25:11,130",
                "end": "00:25:15,930",
                "text": "And it also powers the one beta feature of this headset,"
            },
            {
                "start": "00:25:15,930",
                "end": "00:25:20,670",
                "text": "which is Personas, which is, it's the most impressive"
            },
            {
                "start": "00:25:20,670",
                "end": "00:25:23,640",
                "text": "and weirdest thing about this headset at the same time."
            },
            {
                "start": "00:25:23,640",
                "end": "00:25:24,540",
                "text": "I'm calling it right now."
            },
            {
                "start": "00:25:24,540",
                "end": "00:25:26,700",
                "text": "So the purpose of the eyes on the outside"
            },
            {
                "start": "00:25:26,700",
                "end": "00:25:29,610",
                "text": "is really not for you, the wearer of the headset."
            },
            {
                "start": "00:25:29,610",
                "end": "00:25:30,870",
                "text": "In fact, you'll never see it."
            },
            {
                "start": "00:25:30,870",
                "end": "00:25:32,400",
                "text": "But it's for the people around you."
            },
            {
                "start": "00:25:32,400",
                "end": "00:25:34,710",
                "text": "So when you're in a passthrough mode,"
            },
            {
                "start": "00:25:34,710",
                "end": "00:25:36,870",
                "text": "your eyes will shine through"
            },
            {
                "start": "00:25:36,870",
                "end": "00:25:39,390",
                "text": "to indicate that you wearing the headset"
            },
            {
                "start": "00:25:39,390",
                "end": "00:25:41,430",
                "text": "can see the person outside."
            },
            {
                "start": "00:25:41,430",
                "end": "00:25:43,860",
                "text": "So that right there is already pretty unique."
            },
            {
                "start": "00:25:43,860",
                "end": "00:25:45,840",
                "text": "But then, when you're in something immersive"
            },
            {
                "start": "00:25:45,840",
                "end": "00:25:48,480",
                "text": "and you can't see what's around you, it covers up your eyes"
            },
            {
                "start": "00:25:48,480",
                "end": "00:25:52,020",
                "text": "with this sort of like a blue, purple glowing animation."
            },
            {
                "start": "00:25:52,020",
                "end": "00:25:53,400",
                "text": "So that intuitively makes sense."
            },
            {
                "start": "00:25:53,400",
                "end": "00:25:54,720",
                "text": "You can see the eyes when they can see you,"
            },
            {
                "start": "00:25:54,720",
                "end": "00:25:56,190",
                "text": "you can't see the eyes when they can't see you."
            },
            {
                "start": "00:25:56,190",
                "end": "00:25:57,900",
                "text": "But crazily enough, there's also a feature"
            },
            {
                "start": "00:25:57,900",
                "end": "00:26:00,930",
                "text": "where if you have someone who's outside the headset"
            },
            {
                "start": "00:26:00,930",
                "end": "00:26:02,280",
                "text": "looking at you, talking to you,"
            },
            {
                "start": "00:26:02,280",
                "end": "00:26:04,110",
                "text": "and you are in an immersion,"
            },
            {
                "start": "00:26:04,110",
                "end": "00:26:08,220",
                "text": "but you want to talk to them through that,"
            },
            {
                "start": "00:26:08,220",
                "end": "00:26:11,340",
                "text": "they will kind of appear through the fog"
            },
            {
                "start": "00:26:11,340",
                "end": "00:26:13,830",
                "text": "of whatever immersive environment you're in."
            },
            {
                "start": "00:26:13,830",
                "end": "00:26:16,260",
                "text": "So you just start talking and looking in their direction."
            },
            {
                "start": "00:26:16,260",
                "end": "00:26:20,070",
                "text": "It detects that, and sort of parts a little bit of a fog"
            },
            {
                "start": "00:26:20,070",
                "end": "00:26:23,070",
                "text": "and that person's eyes will show through the fog."
            },
            {
                "start": "00:26:23,070",
                "end": "00:26:24,090",
                "text": "It's pretty decent."
            },
            {
                "start": "00:26:24,090",
                "end": "00:26:26,760",
                "text": "It basically only shows one person at a time."
            },
            {
                "start": "00:26:26,760",
                "end": "00:26:29,850",
                "text": "And when this is happening on the outside of the headset,"
            },
            {
                "start": "00:26:29,850",
                "end": "00:26:32,370",
                "text": "it shows a little bit of your eyes poking through"
            },
            {
                "start": "00:26:32,370",
                "end": "00:26:35,160",
                "text": "the purple and blue glow."
            },
            {
                "start": "00:26:35,160",
                "end": "00:26:38,160",
                "text": "It's, as you can see, it's all working,"
            },
            {
                "start": "00:26:38,160",
                "end": "00:26:41,760",
                "text": "but also, I think it looks nothing like the eyes"
            },
            {
                "start": "00:26:41,760",
                "end": "00:26:42,593",
                "text": "from the ad."
            },
            {
                "start": "00:26:42,593",
                "end": "00:26:44,730",
                "text": "So in an effort to make the eyes"
            },
            {
                "start": "00:26:44,730",
                "end": "00:26:47,430",
                "text": "as presentable as possible, two things."
            },
            {
                "start": "00:26:47,430",
                "end": "00:26:50,040",
                "text": "First of all, this screen is actually behind"
            },
            {
                "start": "00:26:50,040",
                "end": "00:26:53,640",
                "text": "a lenticular film, which I didn't even realize that"
            },
            {
                "start": "00:26:53,640",
                "end": "00:26:55,380",
                "text": "from the initial media they had published."
            },
            {
                "start": "00:26:55,380",
                "end": "00:26:56,700",
                "text": "But if you've ever heard of that,"
            },
            {
                "start": "00:26:56,700",
                "end": "00:26:59,340",
                "text": "it's sort of what gives it this 3D depth."
            },
            {
                "start": "00:26:59,340",
                "end": "00:27:01,860",
                "text": "You might have seen this on other holographic displays"
            },
            {
                "start": "00:27:01,860",
                "end": "00:27:03,270",
                "text": "and stuff, but the point of that"
            },
            {
                "start": "00:27:03,270",
                "end": "00:27:07,350",
                "text": "is to make the eyes appear to be sunken into the display,"
            },
            {
                "start": "00:27:07,350",
                "end": "00:27:09,180",
                "text": "like on your actual face,"
            },
            {
                "start": "00:27:09,180",
                "end": "00:27:12,060",
                "text": "instead of glued to the front of the headset,"
            },
            {
                "start": "00:27:12,060",
                "end": "00:27:13,320",
                "text": "which would look a little more weird."
            },
            {
                "start": "00:27:13,320",
                "end": "00:27:16,680",
                "text": "But then two, to represent your actual eyes,"
            },
            {
                "start": "00:27:16,680",
                "end": "00:27:19,650",
                "text": "they've built in a way to scan in"
            },
            {
                "start": "00:27:19,650",
                "end": "00:27:22,890",
                "text": "and create a digital representation of your face,"
            },
            {
                "start": "00:27:22,890",
                "end": "00:27:25,110",
                "text": "which is called your Persona."
            },
            {
                "start": "00:27:25,110",
                "end": "00:27:26,160",
                "text": "And it looks like this."
            },
            {
                "start": "00:27:26,160",
                "end": "00:27:29,280",
                "text": "So to get those eyes on the outside"
            },
            {
                "start": "00:27:29,280",
                "end": "00:27:31,380",
                "text": "of the Vision Pro headset, you have to do something"
            },
            {
                "start": "00:27:31,380",
                "end": "00:27:33,780",
                "text": "called registering your Persona."
            },
            {
                "start": "00:27:33,780",
                "end": "00:27:36,600",
                "text": "This is how it creates the digital version of you"
            },
            {
                "start": "00:27:36,600",
                "end": "00:27:40,110",
                "text": "that includes your eyes that will show up here."
            },
            {
                "start": "00:27:40,110",
                "end": "00:27:42,090",
                "text": "So let's do that now."
            },
            {
                "start": "00:27:42,090",
                "end": "00:27:43,620",
                "text": "It's actually kind of a cool process."
            },
            {
                "start": "00:27:43,620",
                "end": "00:27:45,780",
                "text": "So I'm gonna put it on, and hopefully the screen recording"
            },
            {
                "start": "00:27:45,780",
                "end": "00:27:47,700",
                "text": "works so you can see exactly what I'm doing."
            },
            {
                "start": "00:27:47,700",
                "end": "00:27:48,840",
                "text": "I'll hit the digital crown."
            },
            {
                "start": "00:27:48,840",
                "end": "00:27:50,310",
                "text": "I'm gonna go to Settings."
            },
            {
                "start": "00:27:50,310",
                "end": "00:27:51,960",
                "text": "And you can do this when you first set it up."
            },
            {
                "start": "00:27:51,960",
                "end": "00:27:56,960",
                "text": "But I'm going to Persona, and I'm gonna hit Get Started."
            },
            {
                "start": "00:27:57,780",
                "end": "00:28:00,900",
                "text": "So let's refine my hands real quick."
            },
            {
                "start": "00:28:00,900",
                "end": "00:28:03,630",
                "text": "This is capturing detail from the front of the headset"
            },
            {
                "start": "00:28:03,630",
                "end": "00:28:05,193",
                "text": "of the hands in front of me."
            },
            {
                "start": "00:28:07,170",
                "end": "00:28:08,583",
                "text": "Once it's done with that-"
            },
            {
                "start": "00:28:08,583",
                "end": "00:28:10,410",
                "text": "- [Automated Voice] Your Persona, remove Apple Vision Pro."
            },
            {
                "start": "00:28:10,410",
                "end": "00:28:12,300",
                "text": "- It's gonna ask me to take it off."
            },
            {
                "start": "00:28:12,300",
                "end": "00:28:13,923",
                "text": "So this is how it goes."
            },
            {
                "start": "00:28:13,923",
                "end": "00:28:15,060",
                "text": "- [Automated Voice] When you're ready,"
            },
            {
                "start": "00:28:15,060",
                "end": "00:28:17,013",
                "text": "hold Apple Vision Pro at eye level."
            },
            {
                "start": "00:28:18,090",
                "end": "00:28:20,283",
                "text": "Keep your arms and shoulders relaxed."
            },
            {
                "start": "00:28:21,300",
                "end": "00:28:23,700",
                "text": "Align your entire face within the frame."
            },
            {
                "start": "00:28:23,700",
                "end": "00:28:25,650",
                "text": "- [Marques] My face shows up like face ID."
            },
            {
                "start": "00:28:25,650",
                "end": "00:28:28,133",
                "text": "- [Automated Voice] Slowly turn your head to the right."
            },
            {
                "start": "00:28:30,180",
                "end": "00:28:32,373",
                "text": "Now slowly turn your head to the left."
            },
            {
                "start": "00:28:36,090",
                "end": "00:28:37,683",
                "text": "Now tilt your head up,"
            },
            {
                "start": "00:28:41,250",
                "end": "00:28:43,143",
                "text": "then tilt your head down."
            },
            {
                "start": "00:28:46,020",
                "end": "00:28:48,660",
                "text": "Next, let's capture your facial expressions."
            },
            {
                "start": "00:28:48,660",
                "end": "00:28:50,673",
                "text": "Smile with your mouth closed."
            },
            {
                "start": "00:28:52,440",
                "end": "00:28:54,903",
                "text": "Then make a big smile with your teeth showing."
            },
            {
                "start": "00:28:56,580",
                "end": "00:28:58,143",
                "text": "Now raise your eyebrows."
            },
            {
                "start": "00:29:00,060",
                "end": "00:29:01,683",
                "text": "Close your eyes for a moment."
            },
            {
                "start": "00:29:03,720",
                "end": "00:29:04,923",
                "text": "Capture complete."
            },
            {
                "start": "00:29:05,970",
                "end": "00:29:08,223",
                "text": "Put Vision Pro back on to continue."
            },
            {
                "start": "00:29:10,500",
                "end": "00:29:11,370",
                "text": "- I will do that."
            },
            {
                "start": "00:29:11,370",
                "end": "00:29:15,303",
                "text": "So now I have a menu that says Creating Persona,"
            },
            {
                "start": "00:29:16,590",
                "end": "00:29:18,090",
                "text": "and it says it's in beta,"
            },
            {
                "start": "00:29:18,090",
                "end": "00:29:23,090",
                "text": "and now there's my Persona right there."
            },
            {
                "start": "00:29:24,000",
                "end": "00:29:26,880",
                "text": "Kind of uncanny."
            },
            {
                "start": "00:29:26,880",
                "end": "00:29:30,453",
                "text": "The hair's a little bit different, but the face."
            },
            {
                "start": "00:29:33,120",
                "end": "00:29:34,260",
                "text": "Wow, wow."
            },
            {
                "start": "00:29:34,260",
                "end": "00:29:35,093",
                "text": "Okay."
            },
            {
                "start": "00:29:35,093",
                "end": "00:29:35,926",
                "text": "So there's different lighting."
            },
            {
                "start": "00:29:35,926",
                "end": "00:29:37,650",
                "text": "You can choose it to always be in studio lighting,"
            },
            {
                "start": "00:29:37,650",
                "end": "00:29:39,180",
                "text": "and always be in contour lighting."
            },
            {
                "start": "00:29:39,180",
                "end": "00:29:43,140",
                "text": "I'll just leave it at natural, and hit next."
            },
            {
                "start": "00:29:43,140",
                "end": "00:29:47,280",
                "text": "You can change the color temperature of your skin tone."
            },
            {
                "start": "00:29:47,280",
                "end": "00:29:51,870",
                "text": "Cool to warm, I think I'm around there."
            },
            {
                "start": "00:29:51,870",
                "end": "00:29:54,630",
                "text": "Brightness, darkness."
            },
            {
                "start": "00:29:54,630",
                "end": "00:29:58,113",
                "text": "I think I'm around there, near the middle."
            },
            {
                "start": "00:29:59,520",
                "end": "00:30:01,170",
                "text": "Next."
            },
            {
                "start": "00:30:01,170",
                "end": "00:30:02,190",
                "text": "And then I can add glasses."
            },
            {
                "start": "00:30:02,190",
                "end": "00:30:03,690",
                "text": "So if I typically have glasses,"
            },
            {
                "start": "00:30:03,690",
                "end": "00:30:05,160",
                "text": "which obviously I wouldn't be able to wear"
            },
            {
                "start": "00:30:05,160",
                "end": "00:30:08,130",
                "text": "in the Vision Pro, you can still look like you have glasses,"
            },
            {
                "start": "00:30:08,130",
                "end": "00:30:10,680",
                "text": "anytime you're on that FaceTime call."
            },
            {
                "start": "00:30:10,680",
                "end": "00:30:11,913",
                "text": "And then next."
            },
            {
                "start": "00:30:13,530",
                "end": "00:30:14,363",
                "text": "Save."
            },
            {
                "start": "00:30:14,363",
                "end": "00:30:15,196",
                "text": "And that's it."
            },
            {
                "start": "00:30:16,410",
                "end": "00:30:17,710",
                "text": "So I think now"
            },
            {
                "start": "00:30:20,400",
                "end": "00:30:21,663",
                "text": "you should see my eyes."
            },
            {
                "start": "00:30:24,300",
                "end": "00:30:25,133",
                "text": "Maybe."
            },
            {
                "start": "00:30:26,310",
                "end": "00:30:30,540",
                "text": "And that that's the thing, it barely shows up."
            },
            {
                "start": "00:30:30,540",
                "end": "00:30:33,840",
                "text": "You can barely see my eyes when I'm wearing the headset."
            },
            {
                "start": "00:30:33,840",
                "end": "00:30:36,360",
                "text": "Now I've tried a couple other scans subsequently,"
            },
            {
                "start": "00:30:36,360",
                "end": "00:30:38,220",
                "text": "so I've tried different lighting conditions,"
            },
            {
                "start": "00:30:38,220",
                "end": "00:30:40,590",
                "text": "I've tried different backgrounds, simple backgrounds,"
            },
            {
                "start": "00:30:40,590",
                "end": "00:30:42,930",
                "text": "tried different shirts and things like that."
            },
            {
                "start": "00:30:42,930",
                "end": "00:30:44,850",
                "text": "It doesn't really ever appear any brighter."
            },
            {
                "start": "00:30:44,850",
                "end": "00:30:47,010",
                "text": "I think if you have a darker skin tone like me,"
            },
            {
                "start": "00:30:47,010",
                "end": "00:30:50,370",
                "text": "just don't expect the eyes to show up very brightly"
            },
            {
                "start": "00:30:50,370",
                "end": "00:30:51,420",
                "text": "on the outside of the headset."
            },
            {
                "start": "00:30:51,420",
                "end": "00:30:52,470",
                "text": "It's pretty subtle."
            },
            {
                "start": "00:30:52,470",
                "end": "00:30:55,980",
                "text": "Even when it does show up, it's a little weird looking."
            },
            {
                "start": "00:30:55,980",
                "end": "00:30:58,500",
                "text": "The eyes are a little too far apart sometimes."
            },
            {
                "start": "00:30:58,500",
                "end": "00:30:59,670",
                "text": "They're a little dim."
            },
            {
                "start": "00:30:59,670",
                "end": "00:31:01,140",
                "text": "You see one eye at a time."
            },
            {
                "start": "00:31:01,140",
                "end": "00:31:02,760",
                "text": "It's kind of weird."
            },
            {
                "start": "00:31:02,760",
                "end": "00:31:04,787",
                "text": "But that Persona though."
            },
            {
                "start": "00:31:04,787",
                "end": "00:31:05,620",
                "text": "Whew."
            },
            {
                "start": "00:31:05,620",
                "end": "00:31:07,740",
                "text": "That is some pretty interesting stuff."
            },
            {
                "start": "00:31:07,740",
                "end": "00:31:11,820",
                "text": "It's crazy that this is actually a real thing being shipped,"
            },
            {
                "start": "00:31:11,820",
                "end": "00:31:13,560",
                "text": "like first Meta started doing it."
            },
            {
                "start": "00:31:13,560",
                "end": "00:31:15,150",
                "text": "Now Apple's doing this."
            },
            {
                "start": "00:31:15,150",
                "end": "00:31:17,700",
                "text": "This is, again, it's technically in beta."
            },
            {
                "start": "00:31:17,700",
                "end": "00:31:19,950",
                "text": "So I dunno, there's room for improvement,"
            },
            {
                "start": "00:31:19,950",
                "end": "00:31:21,000",
                "text": "but it still works."
            },
            {
                "start": "00:31:21,000",
                "end": "00:31:23,730",
                "text": "But as of right now, I feel like this is"
            },
            {
                "start": "00:31:23,730",
                "end": "00:31:28,730",
                "text": "both incredibly impressive and slightly unsettling."
            },
            {
                "start": "00:31:28,830",
                "end": "00:31:32,250",
                "text": "Like, it's very impressive that this thing,"
            },
            {
                "start": "00:31:32,250",
                "end": "00:31:33,690",
                "text": "this headset I'm wearing on my face,"
            },
            {
                "start": "00:31:33,690",
                "end": "00:31:37,590",
                "text": "is tracking all these little micro expressions"
            },
            {
                "start": "00:31:37,590",
                "end": "00:31:39,990",
                "text": "and little movements for my eyes and my cheeks"
            },
            {
                "start": "00:31:39,990",
                "end": "00:31:42,120",
                "text": "and my mouth and everything."
            },
            {
                "start": "00:31:42,120",
                "end": "00:31:47,120",
                "text": "But at the same time, it's just not quite human."
            },
            {
                "start": "00:31:47,370",
                "end": "00:31:49,410",
                "text": "It's right at the edge of the uncanny valley"
            },
            {
                "start": "00:31:49,410",
                "end": "00:31:51,900",
                "text": "of I'm not looking at a person."
            },
            {
                "start": "00:31:51,900",
                "end": "00:31:54,180",
                "text": "So yeah."
            },
            {
                "start": "00:31:54,180",
                "end": "00:31:58,380",
                "text": "But the crazy part is you can now use this Persona"
            },
            {
                "start": "00:31:58,380",
                "end": "00:32:01,860",
                "text": "as your camera feed for any apps in Vision Pro"
            },
            {
                "start": "00:32:01,860",
                "end": "00:32:06,600",
                "text": "that require a front facing camera, like FaceTime."
            },
            {
                "start": "00:32:06,600",
                "end": "00:32:09,480",
                "text": "And so I've tried, I've been using FaceTime"
            },
            {
                "start": "00:32:09,480",
                "end": "00:32:11,010",
                "text": "a few times in the Vision Pro,"
            },
            {
                "start": "00:32:11,010",
                "end": "00:32:15,480",
                "text": "and it is, technically speaking, incredible."
            },
            {
                "start": "00:32:15,480",
                "end": "00:32:17,790",
                "text": "So I've made a few FaceTime calls in the past few days"
            },
            {
                "start": "00:32:17,790",
                "end": "00:32:19,230",
                "text": "with some fellow reviewers,"
            },
            {
                "start": "00:32:19,230",
                "end": "00:32:21,720",
                "text": "who you'll probably recognize from their Personas,"
            },
            {
                "start": "00:32:21,720",
                "end": "00:32:23,910",
                "text": "who are also testing the Vision Pro."
            },
            {
                "start": "00:32:23,910",
                "end": "00:32:27,540",
                "text": "And universally, once we all got past the shock of,"
            },
            {
                "start": "00:32:27,540",
                "end": "00:32:29,400",
                "text": "oh my god, it's you."
            },
            {
                "start": "00:32:29,400",
                "end": "00:32:30,720",
                "text": "It looks like a digital version of you."
            },
            {
                "start": "00:32:30,720",
                "end": "00:32:31,553",
                "text": "This is crazy."
            },
            {
                "start": "00:32:31,553",
                "end": "00:32:33,120",
                "text": "I've never seen anything like this before."
            },
            {
                "start": "00:32:33,120",
                "end": "00:32:36,810",
                "text": "Once we got past that, there is a ton happening here."
            },
            {
                "start": "00:32:36,810",
                "end": "00:32:39,180",
                "text": "So you can see the FaceTime windows"
            },
            {
                "start": "00:32:39,180",
                "end": "00:32:41,190",
                "text": "literally appear as just that."
            },
            {
                "start": "00:32:41,190",
                "end": "00:32:44,130",
                "text": "They're just like glassy windows floating in space"
            },
            {
                "start": "00:32:44,130",
                "end": "00:32:46,050",
                "text": "with people looking through them."
            },
            {
                "start": "00:32:46,050",
                "end": "00:32:49,530",
                "text": "And then the angle that you look into the window"
            },
            {
                "start": "00:32:49,530",
                "end": "00:32:54,090",
                "text": "is gonna match the angle that they see you looking at them."
            },
            {
                "start": "00:32:54,090",
                "end": "00:32:57,330",
                "text": "Meaning if we're all in Vision Pros on this call,"
            },
            {
                "start": "00:32:57,330",
                "end": "00:32:58,980",
                "text": "unlikely, but hear me out."
            },
            {
                "start": "00:32:58,980",
                "end": "00:33:01,080",
                "text": "If we're all in Vision Pros,"
            },
            {
                "start": "00:33:01,080",
                "end": "00:33:03,030",
                "text": "and you've got a bunch of people on this FaceTime call,"
            },
            {
                "start": "00:33:03,030",
                "end": "00:33:04,470",
                "text": "so there's somebody to the left,"
            },
            {
                "start": "00:33:04,470",
                "end": "00:33:07,260",
                "text": "and somebody to the right, if I look to the person,"
            },
            {
                "start": "00:33:07,260",
                "end": "00:33:09,720",
                "text": "and make eye contact with the person to the right,"
            },
            {
                "start": "00:33:09,720",
                "end": "00:33:13,500",
                "text": "the person to the left sees the side of my head,"
            },
            {
                "start": "00:33:13,500",
                "end": "00:33:16,410",
                "text": "because I'm looking at somebody else."
            },
            {
                "start": "00:33:16,410",
                "end": "00:33:17,940",
                "text": "That's already pretty cool."
            },
            {
                "start": "00:33:17,940",
                "end": "00:33:19,800",
                "text": "And then the same thing is true for hand gestures."
            },
            {
                "start": "00:33:19,800",
                "end": "00:33:20,940",
                "text": "So we tried this out."
            },
            {
                "start": "00:33:20,940",
                "end": "00:33:22,620",
                "text": "Turns out you can reach out"
            },
            {
                "start": "00:33:22,620",
                "end": "00:33:25,530",
                "text": "and make hand gestures that are tracked by the cameras"
            },
            {
                "start": "00:33:25,530",
                "end": "00:33:26,760",
                "text": "in this bubble in front of you,"
            },
            {
                "start": "00:33:26,760",
                "end": "00:33:29,790",
                "text": "and they show up at the correct angle"
            },
            {
                "start": "00:33:29,790",
                "end": "00:33:31,860",
                "text": "towards the person that you're gesturing at,"
            },
            {
                "start": "00:33:31,860",
                "end": "00:33:34,470",
                "text": "so not towards everybody else on the call."
            },
            {
                "start": "00:33:34,470",
                "end": "00:33:35,310",
                "text": "Oh wait, wait, wait."
            },
            {
                "start": "00:33:35,310",
                "end": "00:33:36,143",
                "text": "Okay, good test."
            },
            {
                "start": "00:33:36,143",
                "end": "00:33:37,650",
                "text": "So wait, Justine, do you see this?"
            },
            {
                "start": "00:33:37,650",
                "end": "00:33:38,483",
                "text": "- Yes."
            },
            {
                "start": "00:33:38,483",
                "end": "00:33:39,316",
                "text": "- And Brian, do you see? - I don't see that."
            },
            {
                "start": "00:33:39,316",
                "end": "00:33:40,350",
                "text": "I don't see that, Marques. - Whoa."
            },
            {
                "start": "00:33:40,350",
                "end": "00:33:41,723",
                "text": "- Now wait."
            },
            {
                "start": "00:33:41,723",
                "end": "00:33:42,556",
                "text": "So now Brian, do you see this? (Justine gasps)"
            },
            {
                "start": "00:33:42,556",
                "end": "00:33:43,590",
                "text": "- Now I can see that, Marques."
            },
            {
                "start": "00:33:43,590",
                "end": "00:33:45,750",
                "text": "- And then on top of that, spatial audio here"
            },
            {
                "start": "00:33:45,750",
                "end": "00:33:47,250",
                "text": "is incredibly well developed."
            },
            {
                "start": "00:33:47,250",
                "end": "00:33:50,280",
                "text": "So again, you're on the call, the voice of the person"
            },
            {
                "start": "00:33:50,280",
                "end": "00:33:52,140",
                "text": "to the right comes from the right side."
            },
            {
                "start": "00:33:52,140",
                "end": "00:33:54,300",
                "text": "The voice of the person to the left comes from the left."
            },
            {
                "start": "00:33:54,300",
                "end": "00:33:56,970",
                "text": "But also, you can just pick up and move the window around,"
            },
            {
                "start": "00:33:56,970",
                "end": "00:34:01,410",
                "text": "and that angle will match where the people are in the room"
            },
            {
                "start": "00:34:01,410",
                "end": "00:34:03,660",
                "text": "and where their sound and video comes from."
            },
            {
                "start": "00:34:03,660",
                "end": "00:34:06,300",
                "text": "If I put you on the other side of the room,"
            },
            {
                "start": "00:34:06,300",
                "end": "00:34:08,850",
                "text": "it sounds like they're further away."
            },
            {
                "start": "00:34:08,850",
                "end": "00:34:12,000",
                "text": "And if I turn up the environment,"
            },
            {
                "start": "00:34:12,000",
                "end": "00:34:16,380",
                "text": "and bring them into the moon, or some other 3D space,"
            },
            {
                "start": "00:34:16,380",
                "end": "00:34:20,130",
                "text": "it actually sounds much more like I'm in a gigantic space"
            },
            {
                "start": "00:34:20,130",
                "end": "00:34:22,710",
                "text": "with no echo, versus in the actual room."
            },
            {
                "start": "00:34:22,710",
                "end": "00:34:25,470",
                "text": "It's all very subtle, but very well considered."
            },
            {
                "start": "00:34:25,470",
                "end": "00:34:26,670",
                "text": "So once you're in this a while,"
            },
            {
                "start": "00:34:26,670",
                "end": "00:34:29,310",
                "text": "you start to notice all these little smaller things."
            },
            {
                "start": "00:34:29,310",
                "end": "00:34:31,500",
                "text": "Again, it's not quite human-like."
            },
            {
                "start": "00:34:31,500",
                "end": "00:34:34,203",
                "text": "It's not like looking at a video feed of a human face,"
            },
            {
                "start": "00:34:35,070",
                "end": "00:34:37,740",
                "text": "but it is still, like it has a lot of like,"
            },
            {
                "start": "00:34:37,740",
                "end": "00:34:40,590",
                "text": "this would be the best avatar anyone's ever made in 2K."
            },
            {
                "start": "00:34:40,590",
                "end": "00:34:42,240",
                "text": "Like no one's ever done a 2K face scan"
            },
            {
                "start": "00:34:42,240",
                "end": "00:34:43,650",
                "text": "and had it look this good,"
            },
            {
                "start": "00:34:43,650",
                "end": "00:34:46,620",
                "text": "but it's still not as good as a perfect reality."
            },
            {
                "start": "00:34:46,620",
                "end": "00:34:49,770",
                "text": "It's a, you've heard the uncanny valley thing before."
            },
            {
                "start": "00:34:49,770",
                "end": "00:34:52,710",
                "text": "I think the number one weakness for the avatars"
            },
            {
                "start": "00:34:52,710",
                "end": "00:34:55,200",
                "text": "or the Personas that I've seen is hair."
            },
            {
                "start": "00:34:55,200",
                "end": "00:34:56,940",
                "text": "So basically everyone I've talked to has"
            },
            {
                "start": "00:34:56,940",
                "end": "00:34:58,830",
                "text": "like a frozen lump of hair"
            },
            {
                "start": "00:34:58,830",
                "end": "00:35:01,170",
                "text": "instead of flowing realistic hair."
            },
            {
                "start": "00:35:01,170",
                "end": "00:35:02,970",
                "text": "And that's true about all flowing things,"
            },
            {
                "start": "00:35:02,970",
                "end": "00:35:05,580",
                "text": "like however your hair was when you did the scan,"
            },
            {
                "start": "00:35:05,580",
                "end": "00:35:06,870",
                "text": "it's frozen that way."
            },
            {
                "start": "00:35:06,870",
                "end": "00:35:08,880",
                "text": "And so is any necklace you're wearing,"
            },
            {
                "start": "00:35:08,880",
                "end": "00:35:10,620",
                "text": "whether it's crooked or not,"
            },
            {
                "start": "00:35:10,620",
                "end": "00:35:13,890",
                "text": "or I guess, technically also any makeup you had on,"
            },
            {
                "start": "00:35:13,890",
                "end": "00:35:15,510",
                "text": "or however you looked when you did the scan."
            },
            {
                "start": "00:35:15,510",
                "end": "00:35:17,267",
                "text": "Maybe that could be a good thing."
            },
            {
                "start": "00:35:17,267",
                "end": "00:35:19,080",
                "text": "Maybe you did a scan when you were looking all dolled up,"
            },
            {
                "start": "00:35:19,080",
                "end": "00:35:20,760",
                "text": "and then you get on a 7:00 AM call,"
            },
            {
                "start": "00:35:20,760",
                "end": "00:35:22,500",
                "text": "and you still look perfect even though"
            },
            {
                "start": "00:35:22,500",
                "end": "00:35:24,030",
                "text": "you look like you just woke up in real life."
            },
            {
                "start": "00:35:24,030",
                "end": "00:35:25,980",
                "text": "So I guess there's that too."
            },
            {
                "start": "00:35:25,980",
                "end": "00:35:28,440",
                "text": "But anyway, all that is to say FaceTime."
            },
            {
                "start": "00:35:28,440",
                "end": "00:35:33,300",
                "text": "FaceTime is the most well thought out,"
            },
            {
                "start": "00:35:33,300",
                "end": "00:35:37,920",
                "text": "like most futuristic Vision Pro experience."
            },
            {
                "start": "00:35:37,920",
                "end": "00:35:38,753",
                "text": "It just is."
            },
            {
                "start": "00:35:38,753",
                "end": "00:35:40,380",
                "text": "So I'll end this video with this."
            },
            {
                "start": "00:35:40,380",
                "end": "00:35:45,380",
                "text": "Now you know what it's like to use and operate"
            },
            {
                "start": "00:35:45,510",
                "end": "00:35:46,740",
                "text": "the Vision Pro."
            },
            {
                "start": "00:35:46,740",
                "end": "00:35:48,540",
                "text": "But there's still a lot more to consider"
            },
            {
                "start": "00:35:48,540",
                "end": "00:35:50,640",
                "text": "when actually considering if you should buy"
            },
            {
                "start": "00:35:50,640",
                "end": "00:35:53,520",
                "text": "and own this thing, from the use cases,"
            },
            {
                "start": "00:35:53,520",
                "end": "00:35:56,220",
                "text": "to the things that work well, and don't work well,"
            },
            {
                "start": "00:35:56,220",
                "end": "00:35:59,580",
                "text": "the philosophy behind it, the prices, all of that stuff."
            },
            {
                "start": "00:35:59,580",
                "end": "00:36:02,280",
                "text": "That's what's gonna be for my full review."
            },
            {
                "start": "00:36:02,280",
                "end": "00:36:03,510",
                "text": "Like there are parts of this thing"
            },
            {
                "start": "00:36:03,510",
                "end": "00:36:05,760",
                "text": "that are absolutely amazing,"
            },
            {
                "start": "00:36:05,760",
                "end": "00:36:08,250",
                "text": "unparalleled, best I've ever seen."
            },
            {
                "start": "00:36:08,250",
                "end": "00:36:09,810",
                "text": "But the reason it's so interesting"
            },
            {
                "start": "00:36:09,810",
                "end": "00:36:12,180",
                "text": "is because it's actually a young category."
            },
            {
                "start": "00:36:12,180",
                "end": "00:36:15,750",
                "text": "Like we're so used to this slow, boring iteration"
            },
            {
                "start": "00:36:15,750",
                "end": "00:36:18,450",
                "text": "in mature categories, like smartphones, and laptops,"
            },
            {
                "start": "00:36:18,450",
                "end": "00:36:19,500",
                "text": "and you always see the comments"
            },
            {
                "start": "00:36:19,500",
                "end": "00:36:21,540",
                "text": "talking about how tech is so boring,"
            },
            {
                "start": "00:36:21,540",
                "end": "00:36:23,580",
                "text": "but now they're actually jumping into something risky,"
            },
            {
                "start": "00:36:23,580",
                "end": "00:36:27,420",
                "text": "and it's actually fun, and there is downfalls and flaws,"
            },
            {
                "start": "00:36:27,420",
                "end": "00:36:29,910",
                "text": "and it's fun to actually weigh the pros and cons."
            },
            {
                "start": "00:36:29,910",
                "end": "00:36:31,590",
                "text": "So I'll be expanding on all these way more"
            },
            {
                "start": "00:36:31,590",
                "end": "00:36:33,510",
                "text": "in the full review, but I'll leave you with this."
            },
            {
                "start": "00:36:33,510",
                "end": "00:36:37,350",
                "text": "I've got my upsides and downsides to Vision Pro."
            },
            {
                "start": "00:36:37,350",
                "end": "00:36:38,310",
                "text": "It's been a week."
            },
            {
                "start": "00:36:38,310",
                "end": "00:36:40,473",
                "text": "Upsides, some of the stuff that's the best I've ever seen"
            },
            {
                "start": "00:36:40,473",
                "end": "00:36:41,580",
                "text": "in a headset."
            },
            {
                "start": "00:36:41,580",
                "end": "00:36:45,330",
                "text": "Immersion, placement in space, eye tracking"
            },
            {
                "start": "00:36:45,330",
                "end": "00:36:49,650",
                "text": "and hand control, passthrough, ecosystem,"
            },
            {
                "start": "00:36:49,650",
                "end": "00:36:51,420",
                "text": "and spatial audio."
            },
            {
                "start": "00:36:51,420",
                "end": "00:36:54,660",
                "text": "And the downsides, weight and comfort,"
            },
            {
                "start": "00:36:54,660",
                "end": "00:36:56,490",
                "text": "the eyes on the outside,"
            },
            {
                "start": "00:36:56,490",
                "end": "00:37:01,290",
                "text": "app selection right now, battery life, and price."
            },
            {
                "start": "00:37:01,290",
                "end": "00:37:03,210",
                "text": "So the full reviews in the works."
            },
            {
                "start": "00:37:03,210",
                "end": "00:37:05,280",
                "text": "Definitely get subscribed to be among the first"
            },
            {
                "start": "00:37:05,280",
                "end": "00:37:07,080",
                "text": "to see that when it drops."
            },
            {
                "start": "00:37:07,080",
                "end": "00:37:09,660",
                "text": "Either way, till the next one."
            },
            {
                "start": "00:37:09,660",
                "end": "00:37:11,220",
                "text": "Thanks for watching."
            },
            {
                "start": "00:37:11,220",
                "end": "00:37:12,510",
                "text": "Catch you later."
            },
            {
                "start": "00:37:12,510",
                "end": "00:37:13,343",
                "text": "Peace."
            }
        ],
        "Where is the Apple Vision Pro A Year Later\uff1f.srt": [
            {
                "start": "00:00:00,080",
                "end": "00:00:04,240",
                "text": "a year ago Apple released the Apple"
            },
            {
                "start": "00:00:01,920",
                "end": "00:00:06,200",
                "text": "Vision Pro their first spatial Computing"
            },
            {
                "start": "00:00:04,240",
                "end": "00:00:08,559",
                "text": "headset and for the first week it really"
            },
            {
                "start": "00:00:06,200",
                "end": "00:00:12,000",
                "text": "seemed like everyone excitedly went out"
            },
            {
                "start": "00:00:08,559",
                "end": "00:00:13,839",
                "text": "to buy a $3500 headset until 2 weeks"
            },
            {
                "start": "00:00:12,000",
                "end": "00:00:15,799",
                "text": "later when the content all dried up"
            },
            {
                "start": "00:00:13,839",
                "end": "00:00:18,920",
                "text": "because everyone who bought one returned"
            },
            {
                "start": "00:00:15,799",
                "end": "00:00:20,560",
                "text": "it but you know what I didn't so here's"
            },
            {
                "start": "00:00:18,920",
                "end": "00:00:22,960",
                "text": "what it's like using the Apple Vision"
            },
            {
                "start": "00:00:20,560",
                "end": "00:00:25,359",
                "text": "Pro one year later from someone who"
            },
            {
                "start": "00:00:22,960",
                "end": "00:00:27,599",
                "text": "didn't return the Apple Vision Pro is it"
            },
            {
                "start": "00:00:25,359",
                "end": "00:00:29,199",
                "text": "any better well let's talk about it okay"
            },
            {
                "start": "00:00:27,599",
                "end": "00:00:30,800",
                "text": "so to understand where it is today we"
            },
            {
                "start": "00:00:29,199",
                "end": "00:00:32,840",
                "text": "have to do a little bit of a"
            },
            {
                "start": "00:00:30,800",
                "end": "00:00:34,280",
                "text": "retrospective first why did everyone"
            },
            {
                "start": "00:00:32,840",
                "end": "00:00:36,160",
                "text": "find this thing so cool in the first"
            },
            {
                "start": "00:00:34,280",
                "end": "00:00:37,960",
                "text": "place well with every Apple product"
            },
            {
                "start": "00:00:36,160",
                "end": "00:00:40,320",
                "text": "launch there's some slick marketing and"
            },
            {
                "start": "00:00:37,960",
                "end": "00:00:41,760",
                "text": "hype maybe a little too much hype for a"
            },
            {
                "start": "00:00:40,320",
                "end": "00:00:43,840",
                "text": "product that seemed to have been rumored"
            },
            {
                "start": "00:00:41,760",
                "end": "00:00:46,039",
                "text": "forever VR and AR experiences are some"
            },
            {
                "start": "00:00:43,840",
                "end": "00:00:48,079",
                "text": "of the coolest things that you can try"
            },
            {
                "start": "00:00:46,039",
                "end": "00:00:49,920",
                "text": "for the first time for about 15 minutes"
            },
            {
                "start": "00:00:48,079",
                "end": "00:00:51,760",
                "text": "until the novelty wears off and you look"
            },
            {
                "start": "00:00:49,920",
                "end": "00:00:53,320",
                "text": "yourself in the mirror and realize just"
            },
            {
                "start": "00:00:51,760",
                "end": "00:00:55,719",
                "text": "how you look but honestly the Apple"
            },
            {
                "start": "00:00:53,320",
                "end": "00:00:58,320",
                "text": "Vision Pro is definitely a vision or"
            },
            {
                "start": "00:00:55,719",
                "end": "00:01:00,760",
                "text": "glimpse into the future of what good AR"
            },
            {
                "start": "00:00:58,320",
                "end": "00:01:02,519",
                "text": "and VR could be the you Y and resolution"
            },
            {
                "start": "00:01:00,760",
                "end": "00:01:04,000",
                "text": "is crisp and using just your hands"
            },
            {
                "start": "00:01:02,519",
                "end": "00:01:06,000",
                "text": "instead of a physical controller"
            },
            {
                "start": "00:01:04,000",
                "end": "00:01:08,080",
                "text": "genuinely does feel like the future you"
            },
            {
                "start": "00:01:06,000",
                "end": "00:01:10,040",
                "text": "can enjoy working in 3D spaces with"
            },
            {
                "start": "00:01:08,080",
                "end": "00:01:12,640",
                "text": "Windows and displays everywhere or you"
            },
            {
                "start": "00:01:10,040",
                "end": "00:01:14,520",
                "text": "can immerse yourself in a film with a"
            },
            {
                "start": "00:01:12,640",
                "end": "00:01:16,240",
                "text": "giant display right in front of you and"
            },
            {
                "start": "00:01:14,520",
                "end": "00:01:17,799",
                "text": "while there are limited games the games"
            },
            {
                "start": "00:01:16,240",
                "end": "00:01:20,640",
                "text": "that do work you can run them pretty"
            },
            {
                "start": "00:01:17,799",
                "end": "00:01:23,200",
                "text": "decently it's absolutely insane that all"
            },
            {
                "start": "00:01:20,640",
                "end": "00:01:24,840",
                "text": "of this could be done with today's Tech"
            },
            {
                "start": "00:01:23,200",
                "end": "00:01:26,520",
                "text": "in a device like this and for that"
            },
            {
                "start": "00:01:24,840",
                "end": "00:01:29,000",
                "text": "purpose it just can't be beat but"
            },
            {
                "start": "00:01:26,520",
                "end": "00:01:30,439",
                "text": "there's also many many different reasons"
            },
            {
                "start": "00:01:29,000",
                "end": "00:01:33,000",
                "text": "why it didn't stick for for regular"
            },
            {
                "start": "00:01:30,439",
                "end": "00:01:35,439",
                "text": "people first is price and the value that"
            },
            {
                "start": "00:01:33,000",
                "end": "00:01:37,159",
                "text": "you get for that price what it does"
            },
            {
                "start": "00:01:35,439",
                "end": "00:01:39,520",
                "text": "better than just owning a regular Mac"
            },
            {
                "start": "00:01:37,159",
                "end": "00:01:41,240",
                "text": "and a different VR headset is outshined"
            },
            {
                "start": "00:01:39,520",
                "end": "00:01:43,360",
                "text": "by just how much cheaper those things"
            },
            {
                "start": "00:01:41,240",
                "end": "00:01:45,479",
                "text": "are at doing those tasks and where the"
            },
            {
                "start": "00:01:43,360",
                "end": "00:01:47,680",
                "text": "Vision Pro excels and does things better"
            },
            {
                "start": "00:01:45,479",
                "end": "00:01:50,200",
                "text": "than any computer or VR headset can even"
            },
            {
                "start": "00:01:47,680",
                "end": "00:01:51,880",
                "text": "do doesn't justify paying that crazy"
            },
            {
                "start": "00:01:50,200",
                "end": "00:01:54,159",
                "text": "price tag don't get me wrong it's"
            },
            {
                "start": "00:01:51,880",
                "end": "00:01:56,159",
                "text": "fantastic and impressive every single"
            },
            {
                "start": "00:01:54,159",
                "end": "00:01:58,520",
                "text": "time you put the Vision Pro on nothing"
            },
            {
                "start": "00:01:56,159",
                "end": "00:02:00,759",
                "text": "comes close to it but it's an experience"
            },
            {
                "start": "00:01:58,520",
                "end": "00:02:03,320",
                "text": "that I don't think everyone deems is"
            },
            {
                "start": "00:02:00,759",
                "end": "00:02:04,880",
                "text": "worth 32 Grand there hasn't been a"
            },
            {
                "start": "00:02:03,320",
                "end": "00:02:06,439",
                "text": "single discount since it's been released"
            },
            {
                "start": "00:02:04,880",
                "end": "00:02:09,080",
                "text": "either then there's also how difficult"
            },
            {
                "start": "00:02:06,439",
                "end": "00:02:11,000",
                "text": "it is to show people visually how the"
            },
            {
                "start": "00:02:09,080",
                "end": "00:02:12,920",
                "text": "Apple Vision Pro Works Apple initially"
            },
            {
                "start": "00:02:11,000",
                "end": "00:02:14,800",
                "text": "released it in the US before expanding"
            },
            {
                "start": "00:02:12,920",
                "end": "00:02:17,200",
                "text": "to a couple more countries but at least"
            },
            {
                "start": "00:02:14,800",
                "end": "00:02:19,760",
                "text": "here in the US the only retailer that"
            },
            {
                "start": "00:02:17,200",
                "end": "00:02:21,400",
                "text": "sells the Apple Vision Pro is Apple so"
            },
            {
                "start": "00:02:19,760",
                "end": "00:02:23,440",
                "text": "it's not easy to just walk into your"
            },
            {
                "start": "00:02:21,400",
                "end": "00:02:25,000",
                "text": "local electronic store and try it out"
            },
            {
                "start": "00:02:23,440",
                "end": "00:02:26,800",
                "text": "and see if you like it you have to go"
            },
            {
                "start": "00:02:25,000",
                "end": "00:02:29,080",
                "text": "specifically to an Apple store which"
            },
            {
                "start": "00:02:26,800",
                "end": "00:02:30,720",
                "text": "there are way less of just to try it or"
            },
            {
                "start": "00:02:29,080",
                "end": "00:02:32,400",
                "text": "order it online line and I don't know"
            },
            {
                "start": "00:02:30,720",
                "end": "00:02:35,560",
                "text": "about you if I don't know much about a"
            },
            {
                "start": "00:02:32,400",
                "end": "00:02:37,959",
                "text": "product I'm not quick to drop 3 and2"
            },
            {
                "start": "00:02:35,560",
                "end": "00:02:39,840",
                "text": "Grand on something unseen and it doesn't"
            },
            {
                "start": "00:02:37,959",
                "end": "00:02:41,400",
                "text": "help that even in YouTube videos it's a"
            },
            {
                "start": "00:02:39,840",
                "end": "00:02:43,280",
                "text": "pain trying to show what using the"
            },
            {
                "start": "00:02:41,400",
                "end": "00:02:45,879",
                "text": "experience is like on camera since you"
            },
            {
                "start": "00:02:43,280",
                "end": "00:02:48,159",
                "text": "typically just get a standard 4K 2D"
            },
            {
                "start": "00:02:45,879",
                "end": "00:02:50,000",
                "text": "video of how it looks versus the entire"
            },
            {
                "start": "00:02:48,159",
                "end": "00:02:52,360",
                "text": "immersive view that you would with the"
            },
            {
                "start": "00:02:50,000",
                "end": "00:02:54,360",
                "text": "headset on like this video doesn't do it"
            },
            {
                "start": "00:02:52,360",
                "end": "00:02:56,760",
                "text": "justice then there's the device itself"
            },
            {
                "start": "00:02:54,360",
                "end": "00:02:59,280",
                "text": "it's nice to touch in the hand has lots"
            },
            {
                "start": "00:02:56,760",
                "end": "00:03:01,319",
                "text": "of Glass and Metal it's very premium"
            },
            {
                "start": "00:02:59,280",
                "end": "00:03:03,319",
                "text": "built but it's heavy it's hard to wear"
            },
            {
                "start": "00:03:01,319",
                "end": "00:03:05,680",
                "text": "comfortably for long periods of time and"
            },
            {
                "start": "00:03:03,319",
                "end": "00:03:07,360",
                "text": "takes up a ton of space in your backpack"
            },
            {
                "start": "00:03:05,680",
                "end": "00:03:09,360",
                "text": "so it's super inconvenient to use when"
            },
            {
                "start": "00:03:07,360",
                "end": "00:03:11,920",
                "text": "traveling making that private movie"
            },
            {
                "start": "00:03:09,360",
                "end": "00:03:14,040",
                "text": "viewing experience a huge hassle to Lug"
            },
            {
                "start": "00:03:11,920",
                "end": "00:03:16,040",
                "text": "around with you through airports I mean"
            },
            {
                "start": "00:03:14,040",
                "end": "00:03:18,319",
                "text": "you can fit like three pairs of clothes"
            },
            {
                "start": "00:03:16,040",
                "end": "00:03:20,280",
                "text": "in the space that A Vision Pro takes up"
            },
            {
                "start": "00:03:18,319",
                "end": "00:03:21,879",
                "text": "in a bag some people have issues with"
            },
            {
                "start": "00:03:20,280",
                "end": "00:03:23,799",
                "text": "the look but honestly I don't think"
            },
            {
                "start": "00:03:21,879",
                "end": "00:03:25,879",
                "text": "that's a major issue at all I mean they"
            },
            {
                "start": "00:03:23,799",
                "end": "00:03:27,640",
                "text": "are a bit strange but everyone made fun"
            },
            {
                "start": "00:03:25,879",
                "end": "00:03:29,360",
                "text": "of airpods when they came out calling"
            },
            {
                "start": "00:03:27,640",
                "end": "00:03:31,200",
                "text": "them toothbrush heads but after a few"
            },
            {
                "start": "00:03:29,360",
                "end": "00:03:33,120",
                "text": "years they were everywhere also because"
            },
            {
                "start": "00:03:31,200",
                "end": "00:03:35,799",
                "text": "these things are so expensive and so few"
            },
            {
                "start": "00:03:33,120",
                "end": "00:03:38,200",
                "text": "people have them using them is a very"
            },
            {
                "start": "00:03:35,799",
                "end": "00:03:39,879",
                "text": "lonely and isolating experience both as"
            },
            {
                "start": "00:03:38,200",
                "end": "00:03:42,000",
                "text": "an owner and the fact that when you're"
            },
            {
                "start": "00:03:39,879",
                "end": "00:03:44,159",
                "text": "using it it feels disconnected from the"
            },
            {
                "start": "00:03:42,000",
                "end": "00:03:46,840",
                "text": "physical world with very few ways to"
            },
            {
                "start": "00:03:44,159",
                "end": "00:03:49,040",
                "text": "share what you're experiencing and in"
            },
            {
                "start": "00:03:46,840",
                "end": "00:03:51,400",
                "text": "full immersion and lastly the biggest"
            },
            {
                "start": "00:03:49,040",
                "end": "00:03:53,480",
                "text": "issue with the Vision Pro at release was"
            },
            {
                "start": "00:03:51,400",
                "end": "00:03:55,360",
                "text": "that the app library and features were"
            },
            {
                "start": "00:03:53,480",
                "end": "00:03:57,200",
                "text": "just not enticing there just weren't"
            },
            {
                "start": "00:03:55,360",
                "end": "00:03:59,959",
                "text": "that many apps made specifically for the"
            },
            {
                "start": "00:03:57,200",
                "end": "00:04:02,360",
                "text": "Vision Pro I mean it did have iPad app"
            },
            {
                "start": "00:03:59,959",
                "end": "00:04:04,120",
                "text": "support but that was also pretty Limited"
            },
            {
                "start": "00:04:02,360",
                "end": "00:04:06,480",
                "text": "at launch the main issues were the high"
            },
            {
                "start": "00:04:04,120",
                "end": "00:04:08,959",
                "text": "price tag the barrier to actually use it"
            },
            {
                "start": "00:04:06,480",
                "end": "00:04:11,120",
                "text": "in action or try it the lack of great"
            },
            {
                "start": "00:04:08,959",
                "end": "00:04:13,439",
                "text": "apps and software and the overall"
            },
            {
                "start": "00:04:11,120",
                "end": "00:04:15,799",
                "text": "comfort of the device which all led to"
            },
            {
                "start": "00:04:13,439",
                "end": "00:04:18,040",
                "text": "an impressive device that doesn't feel"
            },
            {
                "start": "00:04:15,799",
                "end": "00:04:20,359",
                "text": "ready for Mass Appeal but okay Jimmy"
            },
            {
                "start": "00:04:18,040",
                "end": "00:04:23,440",
                "text": "that was all last year at release a lot"
            },
            {
                "start": "00:04:20,359",
                "end": "00:04:26,479",
                "text": "of things can change in 365 days but"
            },
            {
                "start": "00:04:23,440",
                "end": "00:04:29,360",
                "text": "does it change whether anyone should get"
            },
            {
                "start": "00:04:26,479",
                "end": "00:04:31,360",
                "text": "an Apple Vision Pro today well first the"
            },
            {
                "start": "00:04:29,360",
                "end": "00:04:32,840",
                "text": "device itself is a lot better Apple has"
            },
            {
                "start": "00:04:31,360",
                "end": "00:04:33,919",
                "text": "dropped new software updates that"
            },
            {
                "start": "00:04:32,840",
                "end": "00:04:35,600",
                "text": "probably should have been there from the"
            },
            {
                "start": "00:04:33,919",
                "end": "00:04:37,400",
                "text": "beginning like more screen real estate"
            },
            {
                "start": "00:04:35,600",
                "end": "00:04:39,400",
                "text": "when you mirror your Mac display new"
            },
            {
                "start": "00:04:37,400",
                "end": "00:04:41,360",
                "text": "gesture controls that make it easier to"
            },
            {
                "start": "00:04:39,400",
                "end": "00:04:42,960",
                "text": "access everything from your fingertips"
            },
            {
                "start": "00:04:41,360",
                "end": "00:04:44,840",
                "text": "instead of looking up to pull in the"
            },
            {
                "start": "00:04:42,960",
                "end": "00:04:47,000",
                "text": "control center and finally a better"
            },
            {
                "start": "00:04:44,840",
                "end": "00:04:48,080",
                "text": "guest mode that saves the previous guest"
            },
            {
                "start": "00:04:47,000",
                "end": "00:04:49,919",
                "text": "so that they don't have to go through"
            },
            {
                "start": "00:04:48,080",
                "end": "00:04:51,840",
                "text": "the annoying setup and the OS itself"
            },
            {
                "start": "00:04:49,919",
                "end": "00:04:53,919",
                "text": "does feel a bit more stable than it did"
            },
            {
                "start": "00:04:51,840",
                "end": "00:04:55,759",
                "text": "at launch all these software tweaks are"
            },
            {
                "start": "00:04:53,919",
                "end": "00:04:58,280",
                "text": "nice additions and make the Vision Pro"
            },
            {
                "start": "00:04:55,759",
                "end": "00:05:00,360",
                "text": "feel more complete and cohesive within"
            },
            {
                "start": "00:04:58,280",
                "end": "00:05:01,919",
                "text": "the Apple ecosystem but again it feels"
            },
            {
                "start": "00:05:00,360",
                "end": "00:05:04,120",
                "text": "like these features should have been"
            },
            {
                "start": "00:05:01,919",
                "end": "00:05:06,840",
                "text": "here in the first place but it still"
            },
            {
                "start": "00:05:04,120",
                "end": "00:05:08,800",
                "text": "does make the Vision Pro nicer to use"
            },
            {
                "start": "00:05:06,840",
                "end": "00:05:11,080",
                "text": "especially the giant ultrawide Mac"
            },
            {
                "start": "00:05:08,800",
                "end": "00:05:13,120",
                "text": "virtual display it just came way too"
            },
            {
                "start": "00:05:11,080",
                "end": "00:05:15,600",
                "text": "late I find that a good informal Health"
            },
            {
                "start": "00:05:13,120",
                "end": "00:05:18,000",
                "text": "indicator of how popular a tech product"
            },
            {
                "start": "00:05:15,600",
                "end": "00:05:20,000",
                "text": "is and how people use their device is"
            },
            {
                "start": "00:05:18,000",
                "end": "00:05:21,639",
                "text": "the third party accessory markets for it"
            },
            {
                "start": "00:05:20,000",
                "end": "00:05:24,000",
                "text": "all big electronic purchases whether"
            },
            {
                "start": "00:05:21,639",
                "end": "00:05:26,160",
                "text": "that's a laptop tablet smartphone game"
            },
            {
                "start": "00:05:24,000",
                "end": "00:05:27,639",
                "text": "console or even a camera have"
            },
            {
                "start": "00:05:26,160",
                "end": "00:05:29,240",
                "text": "accessories and you know once you get"
            },
            {
                "start": "00:05:27,639",
                "end": "00:05:30,560",
                "text": "your shiny new electronics you're"
            },
            {
                "start": "00:05:29,240",
                "end": "00:05:32,240",
                "text": "already planning some accessory"
            },
            {
                "start": "00:05:30,560",
                "end": "00:05:34,280",
                "text": "purchases for it so just a quick glance"
            },
            {
                "start": "00:05:32,240",
                "end": "00:05:36,600",
                "text": "on Apple's website and Amazon shows you"
            },
            {
                "start": "00:05:34,280",
                "end": "00:05:39,000",
                "text": "two things one how few accessories there"
            },
            {
                "start": "00:05:36,600",
                "end": "00:05:41,120",
                "text": "are for the Vision Pro and two how few"
            },
            {
                "start": "00:05:39,000",
                "end": "00:05:42,560",
                "text": "people are actually buying these"
            },
            {
                "start": "00:05:41,120",
                "end": "00:05:44,639",
                "text": "accessories it doesn't seem like the"
            },
            {
                "start": "00:05:42,560",
                "end": "00:05:46,400",
                "text": "Apple Vision Pro is all that popular at"
            },
            {
                "start": "00:05:44,639",
                "end": "00:05:48,160",
                "text": "least from an accessory standpoint and"
            },
            {
                "start": "00:05:46,400",
                "end": "00:05:50,280",
                "text": "even when looking at Google trends for"
            },
            {
                "start": "00:05:48,160",
                "end": "00:05:52,639",
                "text": "the Apple Vision Pro it seems like the"
            },
            {
                "start": "00:05:50,280",
                "end": "00:05:54,880",
                "text": "overall hype for this device is just"
            },
            {
                "start": "00:05:52,639",
                "end": "00:05:56,759",
                "text": "straight up dead so while the software"
            },
            {
                "start": "00:05:54,880",
                "end": "00:05:59,039",
                "text": "is a lot better A year later the"
            },
            {
                "start": "00:05:56,759",
                "end": "00:06:00,800",
                "text": "accessories market for the Vision Pro"
            },
            {
                "start": "00:05:59,039",
                "end": "00:06:03,600",
                "text": "and how many people people actually have"
            },
            {
                "start": "00:06:00,800",
                "end": "00:06:05,680",
                "text": "purchased this Vision Pro seems tiny"
            },
            {
                "start": "00:06:03,600",
                "end": "00:06:07,680",
                "text": "especially by Apple product standards so"
            },
            {
                "start": "00:06:05,680",
                "end": "00:06:09,680",
                "text": "the Apple Vision Pro has gotten better"
            },
            {
                "start": "00:06:07,680",
                "end": "00:06:11,919",
                "text": "over the last year even if sales are"
            },
            {
                "start": "00:06:09,680",
                "end": "00:06:13,360",
                "text": "sluggish but they don't live in a vacuum"
            },
            {
                "start": "00:06:11,919",
                "end": "00:06:15,800",
                "text": "there are other companies that are"
            },
            {
                "start": "00:06:13,360",
                "end": "00:06:18,000",
                "text": "working on better and better headsets as"
            },
            {
                "start": "00:06:15,800",
                "end": "00:06:19,919",
                "text": "well Samsung has their project muhan"
            },
            {
                "start": "00:06:18,000",
                "end": "00:06:21,520",
                "text": "headset that looks a little too similar"
            },
            {
                "start": "00:06:19,919",
                "end": "00:06:24,000",
                "text": "to the Apple Vision Pro it could"
            },
            {
                "start": "00:06:21,520",
                "end": "00:06:26,039",
                "text": "potentially be really interesting and"
            },
            {
                "start": "00:06:24,000",
                "end": "00:06:27,319",
                "text": "might be a solid alternative or you"
            },
            {
                "start": "00:06:26,039",
                "end": "00:06:31,120",
                "text": "could look at what's available on the"
            },
            {
                "start": "00:06:27,319",
                "end": "00:06:33,199",
                "text": "market today like meta Quest 3s which is"
            },
            {
                "start": "00:06:31,120",
                "end": "00:06:35,560",
                "text": "already a compelling headset which by"
            },
            {
                "start": "00:06:33,199",
                "end": "00:06:37,160",
                "text": "the way this thing costs 10 times less"
            },
            {
                "start": "00:06:35,560",
                "end": "00:06:39,599",
                "text": "than the Apple Vision Pro one thing I"
            },
            {
                "start": "00:06:37,160",
                "end": "00:06:42,199",
                "text": "want to make 100% clear is that this"
            },
            {
                "start": "00:06:39,599",
                "end": "00:06:44,319",
                "text": "thing is not a competitor to division"
            },
            {
                "start": "00:06:42,199",
                "end": "00:06:46,160",
                "text": "Pro so the comparisons are a little"
            },
            {
                "start": "00:06:44,319",
                "end": "00:06:47,919",
                "text": "unfair there if you're comparing what"
            },
            {
                "start": "00:06:46,160",
                "end": "00:06:50,160",
                "text": "type of things you can accomplish with"
            },
            {
                "start": "00:06:47,919",
                "end": "00:06:52,639",
                "text": "both device but what this does do is"
            },
            {
                "start": "00:06:50,160",
                "end": "00:06:55,160",
                "text": "give us an idea of how cheap VR and AR"
            },
            {
                "start": "00:06:52,639",
                "end": "00:06:57,199",
                "text": "headsets can get as well as how good"
            },
            {
                "start": "00:06:55,160",
                "end": "00:06:59,680",
                "text": "they can be at this price point what"
            },
            {
                "start": "00:06:57,199",
                "end": "00:07:03,240",
                "text": "regular everyday people can afford The"
            },
            {
                "start": "00:06:59,680",
                "end": "00:07:04,960",
                "text": "Vision Pro like inside is technically so"
            },
            {
                "start": "00:07:03,240",
                "end": "00:07:07,080",
                "text": "impressive it's got plenty of power"
            },
            {
                "start": "00:07:04,960",
                "end": "00:07:08,960",
                "text": "thanks to that M2 Chip and the displays"
            },
            {
                "start": "00:07:07,080",
                "end": "00:07:11,240",
                "text": "are beautiful it just doesn't have"
            },
            {
                "start": "00:07:08,960",
                "end": "00:07:14,160",
                "text": "enough going for it to justify that"
            },
            {
                "start": "00:07:11,240",
                "end": "00:07:16,199",
                "text": "large price tag while the meta Quest 3s"
            },
            {
                "start": "00:07:14,160",
                "end": "00:07:18,440",
                "text": "nothing about this device screams"
            },
            {
                "start": "00:07:16,199",
                "end": "00:07:20,479",
                "text": "premium but it's comfortable to wear has"
            },
            {
                "start": "00:07:18,440",
                "end": "00:07:23,000",
                "text": "the option to use controllers or finger"
            },
            {
                "start": "00:07:20,479",
                "end": "00:07:25,360",
                "text": "gestures to navigate the device and it's"
            },
            {
                "start": "00:07:23,000",
                "end": "00:07:27,840",
                "text": "cheap okay I hate making up random"
            },
            {
                "start": "00:07:25,360",
                "end": "00:07:31,280",
                "text": "numbers to describe my personal"
            },
            {
                "start": "00:07:27,840",
                "end": "00:07:33,520",
                "text": "experience but the Vision Pro experience"
            },
            {
                "start": "00:07:31,280",
                "end": "00:07:36,479",
                "text": "feels about three times better than the"
            },
            {
                "start": "00:07:33,520",
                "end": "00:07:38,919",
                "text": "meta Quest 3s now does it justify it"
            },
            {
                "start": "00:07:36,479",
                "end": "00:07:41,280",
                "text": "being 10 times more expensive for that"
            },
            {
                "start": "00:07:38,919",
                "end": "00:07:44,000",
                "text": "three times better experience no but"
            },
            {
                "start": "00:07:41,280",
                "end": "00:07:46,759",
                "text": "that's kind of like comparing a $300 TV"
            },
            {
                "start": "00:07:44,000",
                "end": "00:07:49,039",
                "text": "you see in a store to a $3,000 premium"
            },
            {
                "start": "00:07:46,759",
                "end": "00:07:51,159",
                "text": "OLED TV they both do the job but the"
            },
            {
                "start": "00:07:49,039",
                "end": "00:07:53,720",
                "text": "comparisons just aren't Fair could you"
            },
            {
                "start": "00:07:51,159",
                "end": "00:07:56,520",
                "text": "argue that a fancy money shredding OLED"
            },
            {
                "start": "00:07:53,720",
                "end": "00:07:58,560",
                "text": "TV does a job 10 times better than that"
            },
            {
                "start": "00:07:56,520",
                "end": "00:08:00,159",
                "text": "budget brand no but it's the latest and"
            },
            {
                "start": "00:07:58,560",
                "end": "00:08:02,159",
                "text": "greatest flagship and you're paying a"
            },
            {
                "start": "00:08:00,159",
                "end": "00:08:04,440",
                "text": "premium to be cutting edge that's kind"
            },
            {
                "start": "00:08:02,159",
                "end": "00:08:06,280",
                "text": "of what the Vision Pro is right now but"
            },
            {
                "start": "00:08:04,440",
                "end": "00:08:08,319",
                "text": "what will be interesting at least to me"
            },
            {
                "start": "00:08:06,280",
                "end": "00:08:10,560",
                "text": "is out of these two or any other"
            },
            {
                "start": "00:08:08,319",
                "end": "00:08:13,000",
                "text": "competitors that enter the market who"
            },
            {
                "start": "00:08:10,560",
                "end": "00:08:14,759",
                "text": "can reach that sweet sweet Middle Ground"
            },
            {
                "start": "00:08:13,000",
                "end": "00:08:16,360",
                "text": "first where you get nice premium"
            },
            {
                "start": "00:08:14,759",
                "end": "00:08:18,599",
                "text": "features that you see in the Vision Pro"
            },
            {
                "start": "00:08:16,360",
                "end": "00:08:21,400",
                "text": "today at a reasonable price that's when"
            },
            {
                "start": "00:08:18,599",
                "end": "00:08:23,680",
                "text": "I think these VR AR XR whatever you want"
            },
            {
                "start": "00:08:21,400",
                "end": "00:08:25,479",
                "text": "to call them spatial Computing devices"
            },
            {
                "start": "00:08:23,680",
                "end": "00:08:28,000",
                "text": "would be really interesting all right so"
            },
            {
                "start": "00:08:25,479",
                "end": "00:08:29,680",
                "text": "what's next for the Apple Vision Pro"
            },
            {
                "start": "00:08:28,000",
                "end": "00:08:31,319",
                "text": "well I think that Apple's just going to"
            },
            {
                "start": "00:08:29,680",
                "end": "00:08:32,680",
                "text": "look forward and try this path a little"
            },
            {
                "start": "00:08:31,319",
                "end": "00:08:34,599",
                "text": "bit longer there's rumors that"
            },
            {
                "start": "00:08:32,680",
                "end": "00:08:36,800",
                "text": "production ended for the Vision Pro in"
            },
            {
                "start": "00:08:34,599",
                "end": "00:08:38,599",
                "text": "late 2024 due to lower than expected"
            },
            {
                "start": "00:08:36,800",
                "end": "00:08:41,080",
                "text": "sales but that's not the end into"
            },
            {
                "start": "00:08:38,599",
                "end": "00:08:42,839",
                "text": "Apple's attempt into these type of"
            },
            {
                "start": "00:08:41,080",
                "end": "00:08:44,760",
                "text": "devices because apple is rumored to"
            },
            {
                "start": "00:08:42,839",
                "end": "00:08:46,160",
                "text": "release a more budget friendly version"
            },
            {
                "start": "00:08:44,760",
                "end": "00:08:47,399",
                "text": "sometime in the near future so in the"
            },
            {
                "start": "00:08:46,160",
                "end": "00:08:49,360",
                "text": "meantime they really should be"
            },
            {
                "start": "00:08:47,399",
                "end": "00:08:51,360",
                "text": "continuing to flesh out the features of"
            },
            {
                "start": "00:08:49,360",
                "end": "00:08:53,160",
                "text": "the Vision Pro so that when this new"
            },
            {
                "start": "00:08:51,360",
                "end": "00:08:54,959",
                "text": "cheaper model releases it'll hit the"
            },
            {
                "start": "00:08:53,160",
                "end": "00:08:56,800",
                "text": "ground running with a more thought out"
            },
            {
                "start": "00:08:54,959",
                "end": "00:08:59,040",
                "text": "OS hopefully you get some great apps"
            },
            {
                "start": "00:08:56,800",
                "end": "00:09:00,839",
                "text": "because it's still pretty Barren and is"
            },
            {
                "start": "00:08:59,040",
                "end": "00:09:02,800",
                "text": "mostly suited for consuming streamed"
            },
            {
                "start": "00:09:00,839",
                "end": "00:09:04,640",
                "text": "content there's also rumors that apple"
            },
            {
                "start": "00:09:02,800",
                "end": "00:09:06,480",
                "text": "and Sony are working together to support"
            },
            {
                "start": "00:09:04,640",
                "end": "00:09:08,120",
                "text": "PlayStation VR2 controllers with the"
            },
            {
                "start": "00:09:06,480",
                "end": "00:09:10,640",
                "text": "Vision Pro which could help it function"
            },
            {
                "start": "00:09:08,120",
                "end": "00:09:12,720",
                "text": "better as both a gaming machine because"
            },
            {
                "start": "00:09:10,640",
                "end": "00:09:14,480",
                "text": "the M series processors in there are"
            },
            {
                "start": "00:09:12,720",
                "end": "00:09:16,480",
                "text": "already pretty good at that and to just"
            },
            {
                "start": "00:09:14,480",
                "end": "00:09:18,040",
                "text": "navigate with VR controls because doing"
            },
            {
                "start": "00:09:16,480",
                "end": "00:09:19,680",
                "text": "everything with hand gestures for an"
            },
            {
                "start": "00:09:18,040",
                "end": "00:09:22,320",
                "text": "extended period of time kind of just"
            },
            {
                "start": "00:09:19,680",
                "end": "00:09:25,320",
                "text": "drains you so was the hype around the"
            },
            {
                "start": "00:09:22,320",
                "end": "00:09:26,600",
                "text": "Apple Vision Pro unwarranted sort of"
            },
            {
                "start": "00:09:25,320",
                "end": "00:09:28,800",
                "text": "there's a reason why people were so"
            },
            {
                "start": "00:09:26,600",
                "end": "00:09:30,839",
                "text": "interested in this product it was and"
            },
            {
                "start": "00:09:28,800",
                "end": "00:09:33,240",
                "text": "still is a really interesting piece of"
            },
            {
                "start": "00:09:30,839",
                "end": "00:09:35,120",
                "text": "technology like this proves that it can"
            },
            {
                "start": "00:09:33,240",
                "end": "00:09:37,040",
                "text": "be done with the tech that we have today"
            },
            {
                "start": "00:09:35,120",
                "end": "00:09:39,839",
                "text": "but it also shows us how far away we are"
            },
            {
                "start": "00:09:37,040",
                "end": "00:09:41,800",
                "text": "from this actually being useful to the"
            },
            {
                "start": "00:09:39,839",
                "end": "00:09:43,920",
                "text": "average person it'll be years before"
            },
            {
                "start": "00:09:41,800",
                "end": "00:09:45,800",
                "text": "this type of Technology becomes small"
            },
            {
                "start": "00:09:43,920",
                "end": "00:09:48,160",
                "text": "enough comfortable enough powerful"
            },
            {
                "start": "00:09:45,800",
                "end": "00:09:50,519",
                "text": "enough and cheap enough to actually be"
            },
            {
                "start": "00:09:48,160",
                "end": "00:09:53,760",
                "text": "accessible to everyone because let's be"
            },
            {
                "start": "00:09:50,519",
                "end": "00:09:55,399",
                "text": "real if this thing was like $1,500"
            },
            {
                "start": "00:09:53,760",
                "end": "00:09:57,640",
                "text": "comfortable to wear for long periods of"
            },
            {
                "start": "00:09:55,399",
                "end": "00:09:59,839",
                "text": "time less bulky and had a much more"
            },
            {
                "start": "00:09:57,640",
                "end": "00:10:01,800",
                "text": "robust app ecosystem this thing would"
            },
            {
                "start": "00:09:59,839",
                "end": "00:10:04,360",
                "text": "sell a lot better but until then"
            },
            {
                "start": "00:10:01,800",
                "end": "00:10:06,959",
                "text": "headsets like the Apple Vision Pro will"
            },
            {
                "start": "00:10:04,360",
                "end": "00:10:09,000",
                "text": "probably remain pretty Niche for a while"
            },
            {
                "start": "00:10:06,959",
                "end": "00:10:11,640",
                "text": "but hopefully a device like this spurred"
            },
            {
                "start": "00:10:09,000",
                "end": "00:10:14,120",
                "text": "up the competition a bit so that we as"
            },
            {
                "start": "00:10:11,640",
                "end": "00:10:15,839",
                "text": "consumers get way more competition maybe"
            },
            {
                "start": "00:10:14,120",
                "end": "00:10:17,839",
                "text": "meta will make a successor to The Meta"
            },
            {
                "start": "00:10:15,839",
                "end": "00:10:19,800",
                "text": "Quest Pro or Samsung makes a retail"
            },
            {
                "start": "00:10:17,839",
                "end": "00:10:22,000",
                "text": "version of their project muhan headset"
            },
            {
                "start": "00:10:19,800",
                "end": "00:10:24,920",
                "text": "who knows either way this isn't the"
            },
            {
                "start": "00:10:22,000",
                "end": "00:10:26,720",
                "text": "first time that we've seen an AR VR XR"
            },
            {
                "start": "00:10:24,920",
                "end": "00:10:28,240",
                "text": "spatial Computing headset it won't be"
            },
            {
                "start": "00:10:26,720",
                "end": "00:10:30,399",
                "text": "the last time we see something like this"
            },
            {
                "start": "00:10:28,240",
                "end": "00:10:31,519",
                "text": "either so for me personally today in"
            },
            {
                "start": "00:10:30,399",
                "end": "00:10:35,360",
                "text": "February"
            },
            {
                "start": "00:10:31,519",
                "end": "00:10:38,720",
                "text": "2025 would I rather own this or save"
            },
            {
                "start": "00:10:35,360",
                "end": "00:10:40,200",
                "text": "$3,500 I'd rather save $3500 anyway what"
            },
            {
                "start": "00:10:38,720",
                "end": "00:10:42,120",
                "text": "do you personally think did you consider"
            },
            {
                "start": "00:10:40,200",
                "end": "00:10:44,680",
                "text": "the Apple Vision Pro has your opinion on"
            },
            {
                "start": "00:10:42,120",
                "end": "00:10:47,279",
                "text": "it changed honestly I had some hope for"
            },
            {
                "start": "00:10:44,680",
                "end": "00:10:49,760",
                "text": "it but it feels largely the same a year"
            },
            {
                "start": "00:10:47,279",
                "end": "00:10:51,760",
                "text": "later despite some of the main software"
            },
            {
                "start": "00:10:49,760",
                "end": "00:10:53,320",
                "text": "updates the app ecosystems just still"
            },
            {
                "start": "00:10:51,760",
                "end": "00:10:54,720",
                "text": "isn't there for me leave all that down"
            },
            {
                "start": "00:10:53,320",
                "end": "00:10:59,079",
                "text": "in the comment section below and I'll"
            },
            {
                "start": "00:10:54,720",
                "end": "00:10:59,079",
                "text": "see you all next time bye"
            }
        ]
    }
}